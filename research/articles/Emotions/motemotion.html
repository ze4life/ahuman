<HTML><HEAD>
<!-- This document was created from RTF source by rtftohtml version 3.0.1 -->
<TITLE>Motivation and Emotion: An Interactive Process Model - Title</TITLE></HEAD>
<BODY BACKGROUND="../images/r2harch.gif" TEXT=#1809BB>
<H1>
Motivation and Emotion: An Interactive Process Model</H1>
<UL>
<LI><A HREF="#Heading2">Motivation and Emotion: An Interactive Process Model</A>
<LI><A HREF="#Heading3">Representation</A>
<LI><A HREF="#Heading4">Motivation</A>
<LI><A HREF="#Heading5">Learning</A>
<LI><A HREF="#Heading6">Emotion</A>
<LI><A HREF="#Heading7">Conclusions</A>
<LI><A HREF="#Heading8">References</A>
<LI><A HREF="#Heading9">Endnotes</A>
</UL>
<hr size=4>
<p>
<p>
<p>
<p>
<p>
<p>
<p>
<p>
<p>
<p>
<p>
<p>
<p>
<p>

<h1><center>
<A NAME="Heading1">Motivation and Emotion: An Interactive Process Model</A></h1></center>

<b></b><p>
<b></b><p>
<center>Mark H. Bickhard<p>
</center><p>
<p>
<p>
<p>
<p>
<p>
<p>
<p>
<p>
<p>
<p>
Key words: interactivism, encodingism, action selection, emergent motivation,
conditioning, uncertainty, adaptivity of emotion, mood<p>
<p>
<p>
Mark H. Bickhard<br>
Cognitive Science<br>
17 Memorial Drive East<br>
Lehigh University<br>
Bethlehem, PA  18015<br>
610-758-3633<br>
mhb0@lehigh.edu<br>
mark.bickhard@lehigh.edu<br>
http://www.lehigh.edu/~mhb0/mhb0.html<p>
<h1><center>
<A NAME="Heading2">Motivation and Emotion: An Interactive Process Model</A></h1></center>

<b></b><p>
<b></b><p>
<center>Mark H. Bickhard<p>
</center><p>
In this chapter, I outline dynamic models of motivation and emotion.  These
turn out not to be autonomous subsystems, but, instead, are deeply integrated
in the basic interactive dynamic character of living systems.  Motivation is a
crucial aspect of particular kinds of interactive systems -- systems for which
representation is a sister aspect.  Emotion is a special kind of partially
reflective interaction process, and yields its own emergent motivational
aspects.  In addition, the overall model accounts for some of the crucial
properties of consciousness.
<h1>
<A NAME="Heading3">Representation</A></h1>

<b></b><p>
<b></b>I begin with representation, and outline a model of
representation as a fundamental solution to the biological problem of action
selection.<p>
<b>Interaction Selection in a Complex Interactive System</b>.  Any
complex organism must solve the problem of action selection -- what to do next.
In sufficiently simple systems, a triggering relationship may suffice, in which
environmental inputs directly trigger particular actions.  In some bacteria,
for example, if they find themselves swimming up a sugar gradient, they
continue swimming, but if the inputs correspond to their swimming down a sugar
gradient, they stop swimming and tumble for a moment (D. Campbell, 1974,
1990).<p>
In more complex circumstances, however, simple triggering cannot suffice.  The
action and interaction potentialities for the organism are too numerous, and
the reliability of those actions and interactions is too weak.  A frog, for
example, may see a fly, and, therefore, have the potentiality of flicking its
tongue in a certain way followed by eating.  But it may simultaneously see the
shadow of a hawk overhead, in which case it also has the selection option of
jumping into the water.  Both potentialities must be somehow indicated to or
for the frog so that a selection between them can occur.<p>
Furthermore, if the hawk shadow is not present and the frog misses the fly, it
may be advantageous to detect that failure of the tongue flicking action and,
on the basis of that detection, to make a further selection of interaction.
That further selection might be to try again, or might be to move to a
different location where flies are perhaps more numerous or slower.  It can be
advantageous, in other words, to be able to detect failures of actions, as well
as to be able to select among potential actions.<p>
A slight addition to the ability to indicate potential interactions suffices to
allow such error detection.  In particular, if interaction potentialities can
be indicated, then so also might the internal outcomes of those interactions be
indicated in association with them.  That is, it is not only the interactions
per se that are indicated as potentialities to select among, but also the
internal outcomes that can generally be expected if they are in fact
selected.<p>
Furthermore, such an indication of outcomes provides the basis for making such
interaction selections in the first place: if the outcomes are related to
current goals, then select the associated interactions.  Then, if the indicated
outcomes are not attained, that constitutes the detection of error, and can
influence further processing, including further selections of interactive
processes.<p>
A simple digital architecture that would permit such indications is that of
pointers, as in a standard computer.  A more biologically realistic process
would involve a more continuous process of preparation for further interactive
processes together with the ability to detect when those preparations fail to
be prepared for the actual course of interactive flow.  The preparations
themselves constitute the indications of potentiality, while the failure of
preparation to be in fact prepared constitutes the failure of the interactions
to yield the outcomes, the interactive flow, for which they were selected.
Elsewhere I discuss details of such a continuous preparation process, called
microgenesis (Bickhard and Campbell, 1996).  The possibility of such continuity
is important for some later issues in this discussion, but I will not elaborate
the architectural and dynamic specifics here.<p>
An important question at this point is: how are indications of interactive
potentiality set up?  What determines what is potential at any particular point
in time?  The answer is relatively simple: the outcomes of prior interactions
serve as the basis for indicating what will be the next interactive
potentialities.  Conversely, the indication of an interactive potentiality will
in general be conditional on the outcomes of particular prior interactions.
The logic of such indications is based on the fact that interactions with an
environment can serve to differentiate that environment.  The internal course
of an interaction will depend both on the organization of the subsystem engaged
in the interaction and on the environment being interacted with.  If a
subsystem is capable of, say, two possible final internal outcome states (two
for simplicity of discussion), A and B, then actually arriving at A will
differentiate the current environment as of the type that yields outcome A, and
as different from the environmental type that yields outcome B.  Outcomes of
interactions, then, differentiate the environments with which the interactions
have taken place.  Environments of type A, in turn, may also be environments in
which further interactions Q, R, and S, are possible, each with its own
associated set of indicated outcome states.  Each of those outcome states, for
one further step, may indicate -- if arrived at -- some further set of
interactive potentialities.<p>
That is, indications of interactive potentialities may branch, with multiple
possibilities being indicated, and can iterate, with each potential outcome
serving to indicate still further potentialities.  These branching and iterated
indications (not to mention the possibilities if continuous outcome spaces are
taken into account) can link into vast and complex webs of conditionalized
indications of interactive potentiality.<p>
In general, then, an interactive system will be continuously interacting, and
continuously preparing for further interaction on the basis of prior
interactive flow.  Those preparations constitute indications of potentiality,
among which further selections of the course of interactive processes are made
in accordance with any relevant goals.<p>
<b>Representation</b>.  The discussion of interactive systems and the selection
of the course of interaction has made no mention of representation.
Nevertheless, I claim that an outline of the emergence of representation has
already been given.  That is, representation emerged naturally in the evolution
of interactive systems as a solution to the problem of interaction selection.<p>
In particular, the indication of potential interactions is the point of
emergence of the crucial properties of aboutness, truth value, and content.
First, the indication of the potentiality of particular interactive processes
in an environment is an indication <i>about</i> that environment -- an
indication that it is appropriate for those interactions.  It is an implicit
predication that this environment is appropriate for these interactions.
Similarly, conditionalized indications constitute general predications -- type
A environments are subsystem Q type environments.<p>
Second, that indication might be false.  The environment might not in fact
support reaching one of the indicated internal outcomes.  Furthermore, if none
of the indicated outcomes is reached, that indication is thereby falsified for
the system itself.  There is system detectable error -- system detectable
<i>representational</i> error.<p>
Third, there is the emergence of content.  Some patterns of environmental
properties will support an interactive indication and some will not.  Such an
indication, then, predicates some one of those sufficient patterns of
properties to the environment, and those properties constitute the content of
the representation.  Content in this form is implicit, not explicit as in most
models of representation, a difference that I argue elsewhere has powerful
consequences, such as resolving the frame problems (Bickhard and Terveen,
1995).<p>
<b>Challenges</b>.  This is a very primitive form of representation --
appropriate perhaps to flatworms and maybe frogs -- and it is subject to its
own challenges.  Such challenges have been addressed in detail previously, but
there are two that I will respond to here.<p>
The first is a potential circularity: representation has been modeled making
use of a notion of goal, and if goals, in turn, are themselves necessarily
representational, then representation will have been modeled in terms of
representation.  The goals needed here, however, are not necessarily
representational.  They need only have the character of internal set points
that regulate the internal flow of control in an interactive system.  Such set
points may, or may not, correspond to something -- blood sugar level, for
example -- but need not represent it.  Once representation is emergently
available, of course, then goals might themselves make use of them.<p>
The second challenge is to the adequacy of this interactive model of
representation: can it account for more familiar forms of representation in
addition to these primitive action potentiality indications.  One such familiar
kind of representation is that of small physically manipulable objects, such as
a child's toy block.  The complex webs of interactive indications can form
representations of such objects.  A toy block, for example, offers the
potentialities of multiple visual scans, multiple manual manipulations,
chewing, dropping, and so on.  Furthermore, every one of these potentialities
indicates the potentiality of all the rest, perhaps with intermediate
interactions along the way, as if a visual scan indicates the potentiality of
another visual scan so long as the appropriate turn of the block has occurred.
Such a subweb, then, is internally completely reachable.<p>
It has one additional critical property.  The entire web of potentialities will
remain invariant under a large class of additional interactions.  The toy block
will continue to offer its interactive possibilities -- will remain invariant
-- under putting the block away in the toy box, moving to another room, hiding
it, and so on, though it will not remain invariant under crushing or burning.
Such reachable invariances among interactive webs constitute the representation
of small objects.  Clearly, this is basically a Piagetian model of object
representation.<a name="fnB0" href="#fn0">[1]</a><p>
The interactive model of representation captures several characteristics of
phenomenological awareness that should be mentioned.  The model is of a
continuous flow of interactive process that is inherently contentful -- that
exhibits aboutness and intentionality.  It is necessarily from a point of view,
and is correspondingly deictic and indexical.  It is inherently embodied:
disembodiment renders interaction impossible.  It is inherently temporal:
successful interaction is as much a matter of coordinated timing of
interactions as it is of sequence of actions.  Even this relatively simple
elaboration of the model, then, captures important properties of consciousness
(Bickhard, 1998a, in press-a).<a name="fnB1" href="#fn1">[2]</a><p>
<b>Encoding Models of Representation</b>.  Standard models of representation do
not look much like the interactive model.  Standard models, in fact, do not
require any interaction at all.  Most focus only on one aspect of the overall
interactive process, the differentiations that, in the interactive model,
ground the representational indications.<p>
In particular, a simple form of interaction is one with no outputs -- a passive
processing of inputs.  Such a passive process will differentiate environments
according to which internal states are produced, just as will full
interactions, though in general with less overall differentiating power.
Furthermore, it is clear that the sensory systems of complex organisms engage,
at least in part, in precisely such passive input processing.<p>
But, whereas the interactive model gives such processes the function of
differentiating environments, of providing ongoing sensitivity to the
environment, so that appropriate indications of interactive potentialities can
be set up, standard models ignore that output aspect of interaction and
construe the differentiations themselves as being representational.  The
differentiating internal outcomes are deemed to represent, to encode, whatever
it is that they have differentiated (Bickhard, 1993; Bickhard and Terveen,
1995).<p>
In the interactive model, differentiations are not assumed to have any content,
are not assumed to be representational themselves at all.  A differentiating
outcome of an interaction does not announce what it is that it has
differentiated, nor, for that matter, that it is a differentiation at all.  All
that the interactive model requires is that it has <i>in fact</i>
differentiated environments in a way that is <i>in fact</i> useful for the
indications of further interactive potentialities.  There is no need that what
has been so differentiated be known or represented.<p>
But these factual differentiations also constitute, in any particular case,
factual correspondences between the internal states and whatever has been
differentiated, and these correspondences are typically offered as models of
representation.  Such correspondences may be postulated in differing forms --
as causal, as lawful, as informational, and so on -- but some such type of
correspondence is supposed to constitute representation.<p>
There are myriad multifarious failures of logic and of naturalism in such
models.  I will briefly mention only two: emergence and error.  The central
characteristic of representation is content.  Content is what determines what a
representation is <i>supposed</i> to represent, and, therefore, it is what
determines whether a particular application of a representation to a particular
situation or target (Bickhard, 1993; Cummins, 1996) is true or false.  Content
is the normative aspect of representation.  Accounting for the nature and
emergence of content is, thus, the central problem.<p>
Unfortunately, current correspondence or encodingist models make little
progress in accounting for content in any naturalistic way.  They attempt to
capture the specifications of content in a strictly externalist manner, with
little or no attention to how content, especially its normative character,
could be dynamically realized.  If some element is in a favored kind of
correspondence -- causal, informational, lawful, etc. -- with something else,
then that something else is proposed as the content.  But there is no model of
how content could exist, could emerge -- of how the crucial information about
the correspondence could be available -- in the processes of the supposed
epistemic system itself.<p>
But representation did not exist at the moment of the Big Bang, and it does
exist now, therefore it has to have emerged.  Therefore, any model that cannot
account for such emergence is falsified.<p>
It is often acknowledged that we have no model for content, for mental
representation, e.g., "we haven't got a ghost of a Naturalistic theory about
[encoding]"  (Fodor, 1987, pg. 81).  Instead of taking this as a refutation of
current models, however, the failure to account for representational emergence
is taken as a premise in arguments for the necessary innatism of all content.
If content can't emerge in learning in development, then it must be innate
(Fodor, 1981; Bickhard, 1991).  But if it can't emerge, then it can't emerge in
evolution either, and Fodor's argument begs the question -- "What I think it
[the <i>Language of Thought</i> argument] shows is really not so much an a
priori argument for nativism as that <i>there must be some notion of learning
that is so incredibly different from the one we have imagined</i> that we don't
even know what it would be like as things now stand."  (Fodor in
Piattelli-Palmarini, 1980, pg. 269).<p>
The general failure to account for content has many manifestations.  One of
them is a failure to account for the normativity of representation, in
particular, to account for the possibility of representational error.  In
encoding models, there are only two possibilities: either the favored
correspondence exists or it does not exist.  But, if it exists, then the
representation (supposedly) exists, and it is correct, while if it does not
exist, then the representation does not exist, and <i>it cannot be
incorrect</i>.  There are three representational possibilities that must be
accounted for -- exists and correct, exists and incorrect, and does not exist
-- but there are only the resources of two kinds of cases to do the job.  It's
impossible.<p>
Much effort has been devoted to finding a way out of this dilemma, but they all
fail to naturalize content and error.  To determine what a representation is
supposed to represent requires, in current models, the assessment of complex
evolutionary or learning histories (Dretske, 1988; Millikan, 1984, 1993) or the
equally complex assessment of complex relations among counterfactuals (Fodor,
1990; Loewer and Rey, 1991).  None of these are remotely reasonable as a model
of content in a simple epistemic system.  Then to assess whether the
representational instance is true or false requires comparing those
inaccessible contents to what is actually currently being represented.  But
representing what is currently being represented is the original problem all
over again.<p>
These models are realizable, if at all, only by an external observer to the
epistemic system at issue, an observer who can, at least in principle, make the
complex assessments of history and counterfactuals to determine the "content"
and who has, again at least in principle, independent representational access
to the environment so that he or she can compare the deployed content with what
is actually out there in the world -- who can determine that the COW
representation is being used for what is in fact a horse on a dark night, and,
therefore, is false.  Such a dependence on an external observer fails to
naturalize representation.  Among other problems, it fails to account for the
representations of the observer, except by initiating a vicious regress.<p>
Some models attempt to make a virtue out of this necessity for an observer by
construing the problem of representation as one of accounting for how it is
useful to use the language of representation.  That is, they construe
representation as a manner of speaking, having no further ontological nature,
and address issues of when it is explanatorily useful to make use of such a
manner of speaking or writing (Bogdan, 1988; Clark, 1997; Dretske, 1988).
Clearly there are some phenomena, including normative phenomena, that are
emergent only in the realm of social practice: marriage and money come to mind.
But the relationship of the individual to the realm of social practice is
already a normative, a representational, relationship, so representation cannot
be subsumed <i>into</i> social practice without committing to a full social
idealism.  That is not only a failure of naturalism, it is internally
incoherent.<p>
There are many more failures of such models (Bickhard, 1993; Bickhard and
Terveen, 1995), but, although they are frequently acknowledged, the usual
assumption is that some form of encodingism is the only possibility and that
the problems will be overcome eventually.  I argue that the failures are
inevitable so long as representation is not understood as a dynamic phenomena
of pragmatic action and interaction, not just a spectator phenomena of input
processing (Bickhard, 1993, 1996, 1998a, 1998b, 1999; Bickhard and Terveen,
1995).
<h1>
<A NAME="Heading4">Motivation</A></h1>

<b></b><p>
<b></b>Representation has been modeled above as an aspect of an
underlying interactive system ontology.  Representation is the aspect of
indicating further interactive processing potentialities; the aspect of
anticipating the flow of interaction.  My claim is that, just as representation
is an aspect of such a system ontology, so also is motivation a different
aspect of the same ontology.<p>
Before elaborating on that claim, I first need to address what is
taken as the problem of motivation.  A classical construal of motivation has
been as that which induces a system to do something rather than nothing.  The
organism is assumed to be inert unless motivated to do something, thus
motivational metaphors such as various kinds of pushes and pulls, drives and
"motivations" (such as competency motivation).  That is, the organism is
assumed to be inert unless some sort of "energy" is provided to make it move.<p>
But organisms are alive, and living beings cannot stop, cannot be inert,
without simply ceasing to exist as living beings.  Living beings <i>cannot</i>
do nothing.  So the problem of motivation cannot be that of what makes an
organism do something rather than nothing.  The problem of motivation must be
what makes an organism do one thing rather than another -- what are the
processes of the selection of the course of further activity, of further
interactive activity (Mook, 1996).<p>
Rather clearly, that is precisely the interactive system function that
representation was proposed to subserve.  That is, anticipation of what's
possible -- representation -- serves the function of selecting what among those
possibilities to select next -- motivation.  Motivation is the aspect of
selection of processes, and representation is the aspect of anticipation in the
service of such selection (Bickhard, 1997).<p>
This is a minimal model of motivation, as is the initial model of
representation, and requires similar attention to more complex and more
familiar kinds of motivation.  Not all motivation is simple selection or goal
directed selection.  As for representation, this minimal model holds perhaps
for flatworms and maybe frogs.  Some more subtle versions of process selection
-- of motivation -- will be outlined later as emergents of more complex
processes.
<h1>
<A NAME="Heading5">Learning</A></h1>

<b></b><p>
<b></b>I will not focus on learning in this chapter, but I do need one
property of learning for the model of emotion to follow.  Learning requires a
monitoring of ongoing interactive processes.  Learning introduces variation
when things are not going well, and stability when they are proceeding
according to plan.  In this case, "plan" is the anticipations of the
microgenesis process.  If microgenesis, the set up for the next interactive
processing, is destabilized when failure to anticipate occurs, and is
stabilized so long as the anticipations are successful, then we have a minimal
model of learning: such a system will tend to stabilize on interactive
processes that proceed successfully according to the anticipations and goals of
the system.<p>
Note that even with this minimal model, we can account for several
phenomena.  If an input path into the central nervous system is neurally wired
so that inhibitory interactions with the inputs are possible, and if an actual
input stream is restricted to such a pathway, then it is possible for the
system to learn to interact with such an input stream strictly via such neural
inhibitory anticipations of the flow of that input stream.  This is classical
habituation (Staddon, 1983).  A well habituated simple tone doesn't progress
higher than the first cochlear nucleus -- the anticipatory interactive
processes can be completed at that level.  A more complex tone, however, may
require a small participation of the temporal lobe in order for the interactive
anticipations to succeed.  That these are anticipations rather than crude
pathway inhibitions is evidenced by the fact that reducing the volume of the
tone, for example, produces arousal -- the volume anticipations fail.<p>
Suppose now that the input flow does not remain in one modality.  Suppose, in
fact, that it crosses from sound, a tone of some sort, into pain -- a foot
shock, say -- where pain is, among other things, a form of input for which no
successful interactions are possible (to a first approximation: Douglas, 1998;
Eccleston and Crombez, 1999).  Now to successfully anticipatorily interact with
this flow, something must be done about the shock.  The only way to
successfully interact with the shock is to avoid it, so the proper response to
the tone is to remove oneself from the grid at the bottom of the cage.  The
full interaction now involves skeletal muscles.  Classical conditioning is a
direct result of the ongoing stabilization only on successful anticipatory
interaction.<p>
For one further elaboration, consider an input that originates from low blood
sugar, perhaps in the hypothalamus.<a name="fnB2" href="#fn2">[3]</a>  Again,
to a first approximation, there is no direct inhibitory interaction possible,
but, nevertheless, some form of successful interaction is possible.  In
particular, interaction that results in raising blood sugar will successfully
interact with this input.  What will succeed in raising blood sugar will, in
general, depend on multiple additional differentiations and representations
about the environment.  Refrigerators usually work fine, if available.  Hunting
may be involved if in the wild.  In any case, we have a model of instrumental
conditioning.<p>
Most learning is more complex than these examples, at least in mammals.  Most
learning is heuristic.  Accounting for heuristic learning requires a more
complex model than has been outlined here (Bickhard and Campbell, 1996), but
these points suffice for my current purposes.
<h1>
<A NAME="Heading6">Emotion</A></h1>

<b></b><p>
<b></b>A creature that had available only interaction and learning
would, if in a sufficiently variable environment, suffer a potentially serious
limitation.  In an encounter with a novel situation, the only possible
responses would be direct interaction or learning trials.  Microgenesis would,
by assumption, be not fully defined -- would not set up clear and dynamically
well organized anticipations of interactive potentiality.  That is the dynamic
side of the assumption of novelty.  But the only monitoring of such uncertainty
of microgenesis is by the learning process.  Such interactive uncertainty is
what learning is supposed to correct.<p>
But learning, even heuristic learning, is at best a trail and error process, a
process engaged in evolutionary epistemology.  A first encounter with a tiger
on a jungle trail might evoke interactions of foot wiggling, or an attempt at a
handshake, or various other learning and interactive trials, but there is, in
an organism limited to interaction and learning, no other possibility.  In
particular, there is no way for such an organism to develop general modes of
interactive response to situations of interactive (microgenesis) uncertainty --
it is only the learning process that has access to any information or signal of
such uncertainty.<p>
Nevertheless, the learning process does involve the generation of some
version of such a signal, and if (a copy of) that signal could be fed back into
the interactive system as an input, then the interactive system would be in a
position to potentially be able to interact with its own conditions of
uncertainty similarly to interacting with environmental conditions.  The
interactive system would learn, would stabilize, on forms of interaction that
tended to be successful in interacting with internal uncertainty in the same
sense in which it would learn to interact with tones and shocks and hunger.
With such a capability, the organism could develop general ways of dealing with
kinds of uncertainty situations, such as running whenever strange and large
animals are encountered.<p>
The modeling proposal is that emotions <i>are</i> such interactions with
internal dynamic uncertainty.  As is by now familiar, this is a minimalist
model, appropriate perhaps to reptiles, and elaboration is required to account
for familiar cases.<p>
<b>Negative and Positive</b>.  First, I address the distinction between
negative and positive emotions.  A simple mode of successful interaction with
uncertainty would be an interaction that succeeded in eliminating the
uncertainty, perhaps by leaving or by altering the situation.  Notice, however,
that the situation that produces the uncertainty is not identical to the
situation that the organism interacts with -- the organism is interacting with
its own uncertainty in addition to the external environment per se.  If the
response to that uncertainty is more uncertainty -- uncertainty about how to
deal with the uncertain situation -- then the overall uncertainty increases.
Uncertainty can create anticipations of more uncertainty.  A runaway feedback
of uncertainty creating more uncertainty is a kind of panic attack, and is a
paradigm for a negative emotion.<p>
On the other hand, suppose that the situation is uncertain in the sense that no
particular interactions are already known to succeed in this kind of situation,
but that the general <i>kind</i> of uncertain situation is well known in the
sense that procedures are known that tend to reduce or eliminate <i>this</i>
kind of uncertainty.  I don't know how to solve this math problem, but I do
know how to go about figuring out how to solve it.  If successful interactions
tend to be stabilized, and if resolution of uncertainty is a successful
interaction (which it is by the model as developed so far), then uncertainty
situations in which there is anticipation of resolution of that uncertainty
should be stabilized in learning.  Uncertainty for which there is strong
anticipation of resolution is the model for positive emotions.<p>
The distinction between negative and positive emotion, then, turns on the
anticipations involved about the potentialities for resolving the uncertainty.
Situations of interactive uncertainty are of strong adaptive importance, and
anticipations of success or failure in resolving such uncertainty are
constitutive of the positive or negative character of that importance.  Further
differentiations of kinds of emotions will occur depending on what sorts of
categorizations of uncertain situations are learned and what kinds of
interactive styles come to be associated with them.<p>
<b>Biological, Developmental, and Social Aspects of Emotions</b>.  It would
make adaptive sense, in this view, for evolution to have created innate
supports for some basic uncertainty response styles, for some basic emotions
(Ekman and Davidson, 1994), but it does not follow in this view that all
emotions would be blends of such basic emotions.  Learning has full power to
develop further differentiations of emotion situations and emotion interactive
processes associated with them, including some that will be largely culturally
specific (Harr&eacute;, 1986).  It would also make adaptive sense, in this
view, for emotional expression and emotion recognition, at least in complex
social species, to be strongly involved in social interaction and social
cognition (Ekman, 1984; Ekman and Davidson, 1994), though, again, it does not
follow that these functions would constitute the most fundamental ontology of,
or adaptive reason for, emotions.<p>
Modeling the typical developmental differentiations of emotions should, in this
view, capture the development of more and more refined forms of uncertainty
situation categorization, response styles, and regulation skills (Gross, 1998),
beginning with a relatively undifferentiated arousal (Scherer, 1984; Thayer,
1989).  After an initial differentiation of positive and negative, negative
arousal seems to differentiate into fear and anger, and so on (Harlow &amp;
Mears, 1983; Saarni, Mumme, &amp; Campos, 1998; Sroufe, 1984, 1995).  Later
emotional possibilities emerge with the capability for reflexive consciousness
at about age four.  Reflexivity is possibly involved in such emotions as guilt
(Taylor, 1987).<p>
<b>The Space of Affectivity</b>.  Emotions are interactive processes with
anticipations of uncertainty about successful interaction with regard to some
particular situation.  That is, there is generally a cognitive focus for
emotions (Nissenbaum, 1985).  There is no constraint in the model, however, to
prevent uncertainty about successful interaction, and anticipations or lack
thereof concerning the resolution of uncertainty, to occur more globally,
without any particular focus.  Such unfocused "emotional" processes provide a
potential model for moods (Rosenberg, 1998).<p>
Emotions as designated in English are occurrent phenomena.  A readiness or
propensity to experience some particular emotion might be characterized as a
personality style if it is generic to multiple kinds of situations, and a mood
if it is relatively continuously ongoing, but, if it is tied to specific
cognitive foci, we tend to describe it as an attitude -- a propensity to have
particular emotional reactions to particular kinds of objects or situations.
The emotions model, then, yields rather readily candidate models of moods and
attitudes.<p>
The space of processes and dispositions that is differentiated by the occurrent
and non-occurrent distinction and by the focus and unfocused distinction is a
relatively continuous space, not a pair of dichotomies.  Depression, for
example, is relatively ambiguous between mood and emotion, while we at times
refer to emotional dispositions -- non-occurrent -- as personality
characteristics or styles: an angry person, for example, or an angry mood, even
if not at all angry at this moment.<p>
<b>Some Emergent Motivations</b>.  Successful forms of interaction will be
learned and will be sought.  This includes successful forms of emotional
interaction.  Positive emotions, then -- interactions with forms of uncertainty
situations for which there is strong anticipation of resolution -- will be
sought, and, therefore, situations that are expected to yield positive emotions
will be sought.<p>
The expectations of resolution of uncertainty, or the lack thereof, are learned
just as much as the uncertainty categorizations and response styles per se.
Positive and negative emotional stances toward particular objects, then, are
not necessarily responses to intrinsic characteristics of phenomena. One
person, for example, may learn that mathematics problems pose an interesting
challenge that is fun to address, while another may learn that the same
problems offer only further frustration and failure.  Similarly, new learning
may allow bringing new forms of exploration to an object -- new forms that
offer new resolvable uncertainty:  Toddlers sometimes like to play with grass,
picking it and tossing it, and so on, but the novelty soon wears off.  Later,
however, that same toddler might become a botanist and discover many new ways
in which grass can be fascinating.<p>
Intrinsic characteristics of an object or phenomenon, however, can limit the
novelty that it can offer.  Nursery rhymes relatively quickly lose their
interest to an adult.  But others can offer essentially unlimited novelty --
there is always something new to hear and experience in Beethoven's Ninth or
avant-garde jazz.<p>
Learning to seek such experiences constitutes learning a kind of process
selection, and, thus, a kind of motivation.  We name these variously as
competence motivation, mastery motivation, or esthetic motivation.  These are
emergent kinds of motivation, emergent from the inherent dynamics among
interaction, learning, and emotions.<p>
Some other motivational phenomena are also emergent in these dynamics.  For
example, as mentioned above, the living system is always active, always doing
something.  If sufficiently driven by inputs that require full resources for
successful interaction, such as pain or hunger, those forms of interaction will
dominate.  If such "external" driving of the central nervous system processes
is minimal or absent, the processes do not simply cease.  They continue, and
continue to seek forms of successful interaction, including uncertainty
interaction.  The individual will seek situations and objects that offer
resolvable uncertainty.  Exploration, curiosity, and esthetics are examples of
the kind of motivational phenomena that emerge if not displaced by more
demanding forms of process (Maslow, 1962).<p>
Furthermore, such explorations of what is most satisfying will tend to discover
and emphasize not only what provides the greatest opportunity externally, but
also what fits best with prior kinds of talents and experience in the
individual.  That is, such explorations will <i>tend</i> to develop the
potentialities of the person, so long as they are not precluded or blocked by
more demanding forms of process.  Such a tendency to actualize the
potentialities of the person is sometimes referred to as a motivational process
itself (Csikszentmihalyi, 1990; Holdstock &amp; Rogers, 1977; Maddi, 1996;
Mook, 1996), but it is not so much a direct matter of selection of further
activity as it is an emergent tendency of consequences of such selections.<p>
<b>A Few Comparisons</b>.  The model outlined here is a dynamic model, based on
a recognition of the necessarily open dynamics of any living system.  Emotions
are a particular kind of dynamics -- forms of interaction with the system's own
internal dynamical uncertainty about how to proceed and how to anticipate the
interactive flow.  Emotions are, in this view, an adaptation to a basic
informational property of the organism-environment relationship -- uncertainty
-- and, as such, manifest their own adaptive rationality (de Sousa, 1987;
Lazarus, 1991).  The effects of emotional processes are, of course, not always
beneficial, but representation and motivation too can be in maladaptive
error.<p>
The uncertainty that gives rise to emotion processes is a kind of evaluation
(Frijda, 1986; Oatley, 1992), but it is not an evaluative process that is
independent of, or follows on, the interactive representational processes.
Instead, it is an aspect of the flow of representational and motivational
interaction.  The differences between this model of evaluation and notions of
evaluation in alternative models turn largely on the difference between
interactive and encodingist models of the nature of cognition and
representation.  If representation is constituted as encoding elements, then
setting up or activating such elements in perception and cognition will
necessarily be distinct from evaluating and judging the situation thus
represented.  In particular, this model is in stark contrast to models of
emotion as particular kinds of propositional attitudes (see Griffiths, 1997,
for a discussion).<p>
The model is consistent with strong biological supports for some basic kinds of
emotions -- evolution is likely to have scaffolded the development some of the
most important general forms of uncertainty interaction -- but it is also
consistent with a ubiquitous involvement of social and cultural learning in
emotions, and even the social and cultural ontology of some of them in which
the basic categorizations of situations are themselves inherently socially
constituted.  In this, the model is closer to the dynamic and developmental
framework endorsed by Griffiths (1999), for example, than the emotional
programs notion in Griffiths (1997).  Emotional expressivity in social species
should, in this view, be expected to be of basic importance to the character
and regulation of social interaction, but, again, constitutes neither the basic
ontology of emotions nor their most basic adaptive function.
<h1>
<A NAME="Heading7">Conclusions</A></h1>

<b></b><p>
<b></b>The model of emotions outlined here makes sense only on the
foundation of the interactive model of representation and motivation.  It is
not possible to develop the intrinsic notions of evaluation of uncertainty with
the same properties in an encodingist cognitive framework.  A primary moral of
the model, then, is that such phenomena cannot be approached independently of
one another: in this case, assumptions about cognition have major implications
and impose major constraints on models of emotion.<p>
Within the model, representation, motivation, and emotion are all
aspects or kinds of interaction.  They are integrated in an intimate way that
is necessarily fragmented in encodingist models.  In this integration, the
model makes contact with multiple facets of emotions research and theory, such
as biological bases for "basic" emotions, developmental aspects of emotions,
the social construction of emotions, and the importance of emotional
expressivity and recognition, without reifying any particular such facets into
the ontology of emotion.<p>
The larger framework of the model is a dynamic systems model of living beings
as far from thermodynamic equilibrium systems (Bickhard, 1993; 1998b).  As
such, the model makes contact with other dynamic systems approaches (Port and
van Gelder, 1995; Thelen and Smith, 1996), but without ignoring representation
(Bickhard, in press-b).  Persons are complex dynamic open systems with multiple
emergent properties, such as representation, motivation, learning, emotions,
consciousness, language, and so on, and will not be understood without honoring
that fundamental dynamic nature.
<h1>
<A NAME="Heading8">References</A></h1>

<b></b><p>
<b></b>Bickhard, M. H.  (1980).  A Model of Developmental and
Psychological Processes.  <i>Genetic Psychology Monographs</i>, 102, 61-116.<p>
Bickhard, M. H.  (1991).  The Import of Fodor's Anti-Constructivist
Argument.  In Les Steffe (Ed.)  <i>Epistemological Foundations of Mathematical
Experience.  </i>New York: Springer-Verlag, 14-25.<p>
Bickhard, M. H.  (1993).  Representational Content in Humans and Machines.
<i>Journal of Experimental and Theoretical Artificial Intelligence</i>,
<i>5</i>, 285-333.<p>
Bickhard, M. H.  (1996).  Troubles with Computationalism.  In W. O'Donohue, R.
F. Kitchener  (Eds.)  <i>The Philosophy of Psychology</i>.  (173-183).  London:
Sage.<p>
Bickhard, M. H.  (1997).  Is Cognition an Autonomous Subsystem?  In S.
O'Nuallain, P. McKevitt, E. MacAogain  (Eds.).  <i>Two Sciences of Mind</i>.
(115-131).  Amsterdam: John Benjamins.<p>
Bickhard, M. H.  (1998a).  Levels of Representationality.  <i>Journal of
Experimental and Theoretical Artificial Intelligence</i>, <i>10</i>(2),
179-215.<p>
Bickhard, M. H.  (1998b).  A Process Model of the Emergence of Representation.
In G. L. Farre, T. Oksala  (Eds.)  <i>Emergence, Complexity, Hierarchy,
Organization</i>, Selected and Edited Papers from the <i>ECHO III
Conference</i>.  <i>Acta Polytechnica Scandinavica</i>, Mathematics, Computing
and Management in Engineering Series No. 91, Espoo, Finland, August 3 - 7,
1998, 263-270.<p>
Bickhard, M. H.  (1999).  Interaction and Representation.  <i>Theory &amp;
Psychology, 9</i>(4), 435-459.<p>
Bickhard, M. H.  (in press-a).  The Emergence of Contentful Experience.  In T.
Kitamura  (Ed.). <i>What Should be Computed to Model Brain Functioning?</i>
Singapore: World Scientific.<p>
Bickhard, M. H.  (in press-b).  Dynamic Representing and Representational
Dynamics.  In E. Dietrich, A. Markman  (Eds.)  <i>Cognitive Dynamics:
Conceptual and Representational Change in Humans and Machines</i>.  Mahwah, NJ:
Erlbaum.<p>
Bickhard, M. H., Campbell, R. L.  (1996).  Topologies of Learning and
Development.  <i>New Ideas in Psychology</i>, <i>14</i>(2), 111-156.<p>
Bickhard, M. H., Terveen, L.  (1995).  <i>Foundational Issues in Artificial
Intelligence and Cognitive Science: Impasse and Solution.</i>  Amsterdam:
Elsevier Scientific.<p>
Bogdan, R.  (1988).  Information and Semantic Cognition: An Ontological
Account.  <i>Mind and Language, 3</i>(2), 81-122.<p>
Brown, T.  (1990).  The Biological Significance of Affectivity.  In N. L.
Stein, B. Leventhal, T. Trabasso  (Eds.) <i> Psychological and Biological
Approaches to Emotion</i>.  (405-434).  Hillsdale, NJ: Erlbaum.<p>
Campbell, D. T.  (1974).  Evolutionary Epistemology.  In P. A. Schilpp  (Ed.)
<i>The Philosophy of Karl Popper</i>.  (413-463).  LaSalle, IL: Open Court.<p>
Campbell, D. T.  (1990).  Levels of Organization, Downward Causation, and the
Selection-Theory Approach to Evolutionary Epistemology.  In Greenberg, G.,
&amp; Tobach, E.  (Eds.)  <i>Theories of the Evolution of Knowing</i>.  (1-17).
Hillsdale, NJ: Erlbaum.<p>
Campbell, R. L., Bickhard, M. H.  (1986). <i> Knowing Levels and Developmental
Stages. </i> Contributions to Human Development.  Basel, Switzerland: Karger.<p>
Christensen, W. D.  (1996).  A complex systems theory of teleology.  <i>Biology
and Philosophy,</i> <b>11</b>, 301-320.<p>
Christensen, W. D., Collier, J. D., Hooker, C. A.  (in preparation).  Autonomy,
Adaptiveness, Anticipation: Towards autonomy-theoretic foundations for life and
intelligence in complex adaptive self-organising systems.<p>
Clark, A.  (1997).  <i>Being There</i>.  Cambridge, MA: MIT/Bradford.<p>
Csikszentmihalyi, M.  (1990).  <i>Flow: The Psychology of Optimal
Experience</i>.  New York: Harper.<p>
Cummins, R.  (1996).  <i>Representations, Targets, and Attitudes</i>.
Cambridge, MA: MIT.<p>
de Sousa, R.  (1987).  <i>The Rationality of Emotion</i>. Cambridge, MA: MIT.<p>
Douglas, G.  (1998).  Why Pains are not Mental Objects.  <i>Philosophical
Studies, 91</i>, 127-148.<p>
Dretske, F. I.  (1988).  <i>Explaining Behavior</i>.  Cambridge, MA: MIT
Press.<p>
Eccleston, C., Crombez, G.  (1999).  Pain Demands Attention: A
Cognitive-Affective Model of the Interruptive Function of Pain.
<i>Psychological Bulletin, 125</i>(3), 356-366.<p>
Ekman, P.  (1984).  Expression and the Nature of Emotion.  In K. R. Scherer, P.
Ekman  (Eds.)  <i>Approaches to Emotion</i>.  (319-343).  Hillsdale, NJ:
Erlbaum.<p>
Ekman, P., Davidson, R. J.  (1994).  <i>The Nature of Emotion</i>.  Oxford:
Oxford University Press.<p>
Fodor, J. A.  (1981).  The present status of the innateness controversy.  In J.
Fodor  <i>RePresentations</i>  (257-316).  Cambridge: MIT Press.<p>
Fodor, J. A.  (1987).  A Situated Grandmother?  <i>Mind and Language, 2</i>,
64-81.<p>
Fodor, J. A.  (1990).  <i>A Theory of Content</i>.  Cambridge, MA: MIT Press.<p>
Frijda, N. H.  (1986).  <i>The Emotions</i>.  Cambridge: Cambridge University
Press.<p>
Griffiths, P.  (1997).  <i>What Emotions Really Are: The Problem of
Psychological Categories</i>.  Chicago: U. of Chicago.<p>
Griffiths, P.  (1999).  Author's Response.  <i>Metascience, 8</i>(1), 49-62.<p>
Gross, J. J.  (1998).  The Emerging Field of Emotion Regulation.  <i>Review
of</i> <i>General Psychology, 2</i>(3), 271-299.<p>
Harlow, H. F., Mears, C. E.  (1983).  Emotional Sequences and Consequences.  In
R. Plutchik, H. Kellerman  (Eds.)  <i>Emotion: Theory, Research, and
Experience</i>.  (171-197).  New York: Academic.<p>
Harr&eacute;, R.  (1986).  <i>The Social Construction of Emotions</i>.  Oxford:
Basil Blackwell.<p>
Holdstock, T. L., Rogers, C. R.  (1977).  Person-Centered Theory.  In R. J.
Corsini  (Ed.)  <i>Current Personality Theories</i>.  (125-151).  Itasca, IL:
Peacock.<p>
Lazarus, R. S.  (1991).  <i>Emotion &amp; Adaptation</i>.  Oxford: Oxford
University Press.<p>
Loewer, B., Rey, G.  (1991).  <i>Meaning in Mind: Fodor and his critics</i>.
Oxford: Blackwell.<p>
Maddi, S. R.  (1996).  <i>Personality Theories: A Comparative Analysis. 6th
Ed</i>.  Pacific Grove, CA:  Brooks/Cole Pub. Co.<p>
Maslow, A. H.  (1962).  <i>Toward a Psychology of Being</i>.  Princeton, NJ: D.
Van Nostrand.<p>
Millikan, R. G.  (1984).  <i>Language, Thought, and Other Biological
Categories</i>.  Cambridge, MA: MIT Press.<p>
Millikan, R. G.  (1993).  <i>White Queen Psychology and Other Essays for
Alice</i>.  Cambridge, MA: MIT Press.<p>
Mook, D. G.  (1996).  <i>Motivation: the organization of action</i>. 2nd ed.
New York: W. W. Norton.<p>
Nissenbaum, H. F.  (1985).  <i>Emotion and Focus</i>.  Stanford: CSLI.<p>
Oatley, K.  (1992).  <i>Best Laid Schemes: The Psychology of Emotions</i>.
Cambridge: Cambridge University Press.<p>
Piattelli-Palmarini, M.  (1980).  <i>Language and Learning</i>.  Cambridge, MA:
Harvard.<p>
Port, R., van Gelder, T. J.  (1995).  <i>Mind as Motion: Dynamics, Behavior,
and Cognition</i>.  Cambridge, MA: MIT Press.<p>
Rosenberg, E. L.  (1998).  Levels of Analysis and the Organization of Affect.
<i>Review of</i> <i>General Psychology, 2</i>(3), 247-270.<p>
Saarni, C., Mumme, D. L., Campos, J. J.  (1998).  Emotional Development:
Action, Communication, and Understanding.  In W. Damon, N. Eisenberg (Eds.)
<i>Handbook of Child Psychology.  5th ed.  Vol. 3: Social, Emotional, and
Personality Development</i>.  (237-309).  New York: Wiley.<p>
Scherer, K. R.  (1984).  On the Nature and Function of Emotion.  In K. R.
Scherer, P. Ekman  (Eds.)  <i>Approaches to Emotion</i>.  (293-317).
Hillsdale, NJ: Erlbaum.<p>
Sroufe, L. A.  (1984).  The Organization of Emotional Development.  In K. R.
Scherer, P. Ekman  (Eds.)  <i>Approaches to Emotion</i>.  (pp. 109-128).
Hillsdale, NJ: Erlbaum.<p>
Sroufe, L. A.  (1995).  <i>Emotional Development</i>.  Cambridge: Cambridge
University Press.<p>
Staddon, J. E. R.  (1983).  <i>Adaptive Behavior and Learning</i>.  Cambridge:
Cambridge University Press.<p>
Taylor, G.  (1987).  <i>Pride, Shame, and Guilt</i>.  Oxford: Oxford University
Press.<p>
Thayer, R. E.  (1989).  <i>The Biopsychology of Mood and Arousal</i>.  Oxford:
Oxford University Press.<p>
Thelen, E., Smith, L. B.  (1996).  <i>A Dynamic Systems Approach to the
Development of Cognition and Action</i>.  Cambridge, MA: MIT.
<h1>
<A NAME="Heading9">Endnotes</A></h1>

<b></b><p>
<a name="fn0" href="#fnB0">[1]</a>   Another representational challenge
concerns representations of abstractions, such as of numbers.  A similarly
Piagetian model accounts for such kinds of representations, but requires
additional elaborations of the model that I will not pursue in this chapter
(Campbell and Bickhard, 1986).<p>
<a name="fn1" href="#fnB1">[2]</a>  A number of additional properties, such as
those of qualia, require (I argue) a model of reflexive consciousness, in
addition to simple conscious awareness.  I will not address those issues here
(Bickhard, 1980, 1998a; Campbell and Bickhard, 1986).<p>
<a name="fn2" href="#fnB2">[3]</a>  Hunger signals are a form of vicariant or
surrogate for the maintenance of the biological integrity of the organism
(Brown, 1990; Campbell, 1974; Christensen, 1996; Christensen, Collier, Hooker,
in preparation).  Such vicariants -- e.g., hunger, thirst, pain, and so on --
are fundamental to successful interacting: no organism can calculate, even
heuristically, back to the basic criterion of biological integrity, and must,
therefore, depend on such surrogates.  I will not focus on these points in this
chapter, though the general nature of the functioning of a few of them are
indicated in passing.

<b></b></body></html>

<!DOCTYPE html 
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
  <title>AITopics / Interfaces </title>
<!--  <title>AI Topics / AI Videos | AITopics / Interfaces </title> -->
  <meta http-equiv='Content-Style-Type' content='text/css' />
<!--HTMLHeader--><style type='text/css'><!--
  ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }
  code.escaped { white-space: nowrap; }
  .vspace { margin-top:1.33em; }
  .indent { margin-left:40px; }
  .outdent { margin-left:40px; text-indent:-40px; }
  a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }
  a.createlink { text-decoration:none; position:relative; top:-0.5em;
    font-weight:bold; font-size:smaller; border-bottom:none; }
  img { border:0px; }
  .editconflict { color:green; 
  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }

  table.markup { border:2px dotted #ccf; width:90%; }
  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }
  table.vert td.markup1 { border-bottom:1px solid #ccf; }
  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }
  table.markup caption { text-align:left; }
  div.faq p, div.faq pre { margin-left:2em; }
  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }
  div.faqtoc div.faq * { display:none; }
  div.faqtoc div.faq p.question 
    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }
  div.faqtoc div.faq p.question * { display:inline; }
   
    .frame 
      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }
    .lfloat { float:left; margin-right:0.5em; }
    .rfloat { float:right; margin-left:0.5em; }
a.varlink { text-decoration:none; }

--></style>  <meta name='robots' content='index,follow' />

  <link rel='stylesheet' href='http://www.aaai.org/AITopics/pmwiki/pub/skins/aaaiblue/aaaiblue.css' type='text/css' />
  <style type="text/css">
  <!--
	@import url("http://www.aaai.org/AITopics/pmwiki/pub/skins/aaaiblue/layout.css");
	-->
  </style>
	<script src="http://www.aaai.org/AITopics/pmwiki/track.js" type="text/JavaScript"></script>
</head>
<body class="backgrnd2" onLoad="addLinkerEvents()">
<!--PageHeaderFmt-->
	<div id="header" class="backgrnd1">
		<div id='wikihead'>
			<form action='http://www.aaai.org/AITopics/pmwiki/pmwiki.php' id="cse-search-box">
				<input type='hidden' name='n' value='AITopics.Interfaces' />
				<input type='hidden' name='action' value='search' />
				<!--    <a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Site/Search'>Search</a>: -->
				<input type='text' name='q' value='' size="25" class='inputbox searchbox' />
				<!-- Include Google Search parameters --> 
				<input type="hidden" name="cof" value="FORID:11" /><input type='submit' name="sa" class='inputbutton searchbutton' value='Search AI Topics' />
				<input type="hidden" name="cx" value="005943697473805803765:wzeb22stvpm" />
			</form>
			<script type="text/javascript">(function() {
var f = document.getElementById('cse-search-box');
if (!f) {
f = document.getElementById('searchbox_demo');
}
if (f && f.q) {
var q = f.q;
var n = navigator;
var l = location;
if (n.platform == 'Win32') {
q.style.cssText = 'border: 1px solid #7e9db9; padding: 2px;';
}
var b = function() {

};
var f = function() {
//q.style.background = '#ffffff';
};
//q.onfocus = f;
//q.onblur = b;
if (!/[&?]q=[^&]/.test(l.search)) {
b();
}
}
})();
</script>
		</div>
		
		<div id='wikilogo'><a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php'><img src='http://www.aaai.org/AITopics/pmwiki/pub/images/aaai-logo-t7.png' alt='AI Topics / AI Videos' border='0' /></a>	
		</div>
	</div>
<!--/PageHeaderFmt-->
	
	<div id="menu" class="backgrnd3">
		<ul>
			<li class="first"><a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics' accesskey="1" class="link1">AITopics</a></li>
			<li class="link2" style="padding-left:0px; padding-right:0px; font-size: 15px">/</li>
			<li class="link2" style="font-size: 15px;">Interfaces</li>
		</ul>
		
		<div id='wikicmds' ><ul><li><a accesskey='c'  rel='nofollow'  class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/RecentChanges'>Recent Changes</a>
</li><li><a accesskey='e'  rel='nofollow'  class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interfaces?action=edit'>Edit</a>
</li><li><a accesskey='h'  rel='nofollow'  class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interfaces?action=diff'>History</a>
</li><li><a accesskey=''  rel='nofollow'  class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interfaces?action=print'>Print</a>
</li><li><a class='urllink' href='mailto:videos08@aaai.org?subject=AI%20Topics%20Contact' rel='nofollow'>Contact Us</a>
</li></ul>
</div>
	</div>
	
	
	<div id="content" class="backgrnd4">
	<table width='100%' cellspacing='0' cellpadding='0'>
  <tr>
<!--PageLeftFmt-->
      <td id='wikileft' valign='top'>
        <div class='vspace'></div><h2><strong>TOOLBOX</strong></h2>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interfaces?action=edit'>Log In / Edit</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/SubmitNewContent'>Submit Content</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Tags/Tags'>Popular Tags</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AIVideos/HomePage'>Videos</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/A-ZIndex'>A-Z Index</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/SiteMap'>Site Map</a>
</li></ul><div class='vspace'></div><h2><strong>BROWSE TOPICS</strong></h2>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/AINews'>AI <em>in the news</em></a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/AIOverview'>AI Overview</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Agents'>Agents</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Applications'>Applications</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/CognitiveScience'>Cognitive Science</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Education'>Education</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Ethics'>Ethical &amp; Social</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/ExpertSystems'>Expert Systems</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Games'>Games &amp; Puzzles</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/History'>History</a>
</li><li><a class='selflink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interfaces'>Interfaces</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/MachineLearning'>Machine Learning</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/NaturalLanguage'>Natural Language</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Philosophy'>Philosophy</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Reasoning'>Reasoning</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Representation'>Representation</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Robots'>Robots</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/ScienceFiction'>Science Fiction</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Speech'>Speech</a>
</li><li><nobr><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Systems'>Systems &amp; Languages</a></nobr>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/TuringTest'>Turing Test</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Vision'>Vision</a>
</li></ul><div class='vspace'></div><h2><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Resources'><strong>RESOURCES</strong></a></h2>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/InteractiveResources'>Interactive</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/EducatorResources'>for Educators</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/StudentResources'>for Students</a>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Report'>Reports &amp; Projects</a>
</li></ul></li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/JournalistResources'>for Journalists</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/FAQs'>FAQs</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Reference'>Reference Shelf</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Main/EditPage'>Editing Pages</a>
</li></ul><div class='vspace'></div><h2><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/AboutUs'><strong>ABOUT THIS SITE</strong></a></h2>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Policies/HomePage'>Policies</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Project/HomePage'>Project Notes</a>
<div class='vspace'></div></li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/RecentChanges'>Changes</a>&nbsp;<img src='http://www.aaai.org/AITopics/pmwiki/pub/images/rss.gif' alt='RSS' title='RSS' />
</li></ul><div class='vspace'></div><div class='backgrnd6'>
<p  style='text-align: center;'><span style='font-size:83%'><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Notices#fairuse'>Fair Use Notice</a></span><br /><span style='font-size:83%'>&#169; <a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Notices#copy'>AAAI 2000-2008</a></span>
</p></div>
<p class='vspace'  style='text-align: center;'><a target='pmwiki'  class='urllink' href='http://www.pmwiki.org' rel='nofollow'>pmwiki.org</a> <br /><span style='font-size:83%'>pmwiki-2.2.0-beta65</span>
</p>
<p class='vspace'  style='text-align: center;'><span style='font-size:83%'><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/SideBar?action=edit'>edit SideBar</a></span>
</p>
</td>
<!--/PageLeftFmt-->
      <td id='wikibody' valign='top'>
<!--PageActionFmt-->
        
<!--PageTitleFmt-->
<!--        <div id='wikititle'>
          <div class='pagegroup'><a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics'>AITopics</a> /</div>
          <h1 class='pagetitle'>Interfaces</h1></div>   -->
<!--PageText-->
<div id='wikitext'>
<div  style='display: none;' > 
<h2  style='text-align: center;'> <strong>Interfaces</strong></h2>
</div>
<div class='vspace'></div><div style="float:left;padding: 0px 20px 10px 0px;">
<div id='topicContentBox' class='backgrnd9'><div class='backgrnd8' >
<div style="width:180px;font-size: 14px;text-align: center;margin-bottom: 5px;" ><strong><a class='selflink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interfaces'>Interfaces</a></strong>
</div>
<ul><li>Readings:
<ul><li><a href='#good'>Introductory</a>
</li><li><a href='#readon'>General</a>
</li></ul></li><li>Subtopics:
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/AssistiveTechnologies'>Assistive Technologies</a> 
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Filtering'>Filtering</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/IntelligentTutoringSystems'>Tutoring Systems</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Marketing'>Marketing, E-Commerce</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/SmartHouses'>Smart Rooms</a>
</li></ul></li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/VideoTags/Interfaces'>Videos</a>
</li><li><a href='#web'>Related Resources</a>
</li><li><a class='urllink' href='http://www.aaai.org/AITopics/xml/rss/interf.xml' rel='nofollow'>News Feed</a>&nbsp;<img src='http://www.aaai.org/AITopics/pmwiki/pub/images/rss.gif' alt='RSS' title='RSS' />
</li></ul></div><div class='backgrnd10' style='height:20px;'></div></div>
</div>
<div class='vspace'></div>
<table ><tr><td align='center'  valign='top'> 
<p>&quot;The use of techniques from the field of autonomous agents provides a new complementary style of human-computer interaction, where the computer becomes an intelligent, active and personalized collaborator. Interface agents are computer programs that employ Artificial Intelligence methods to provide active assistance to a user of a particular computer application. The metaphor used is that of a personal assistant who is collaborating with the user in the same work environment. The assistant becomes gradually more effective as it learns the user's interests, habits and preferences.&quot;
</p>
<p class='vspace'>- <a target='_blank'  href='#fluids'>FLUIDS</a> (Intelligent User Interfaces - <a target='_blank'  class='urllink' href='http://www.dfki.de/fluids/Intelligent_User_Interfaces_New_Achievements_in_Research.html#SECTION00421000000000000000' rel='nofollow'>New Achievements in Research</a>)
</p></td><td width='170' align='center'  valign='top'> <img src='http://www.aaai.org/AITopics/assets/Page%20Art/interface.gif' alt='computer monitor with assistant&#39;s hand' title='computer monitor with assistant&#39;s hand' />
</td></tr></table>
<p class='vspace'>Even the most sophisticated and powerful system will be next to useless without an effective user interface. If struggling with the operation of a video player is not your idea of fun, you can well understand why a part of the artificial intelligence community is devoted to scientifically developing interfaces that are easy and pleasant to use, and that form an effective, and possibly seamless, link between the intelligent machine(s) and the human user(s).
</p>
<p class='vspace'><a name='good' id='good'></a>
</p>
<table ><tr><td width='200'  valign='top'>
<h2 class='backgrnd5'><span class='text1'>Introductory Readings</span></h2>
</td></tr></table>
<div class='vspace'></div><div><span class='rfloat'><a class='urllink' href='http://www.aaai.org/ojs/index.php/aimagazine/issue/view/144/showToc' rel='nofollow'><img src='http://www.aaai.org/AITopics/assets/Page%20Art/aimag22-04.gif' alt='AI Magazine cover:  Intelligent User Interfaces' title='AI Magazine cover:  Intelligent User Interfaces' /></a> </span></div>
<p><a class='urllink' href='http://www.aaai.org/ojs/index.php/aimagazine/article/view/1588/1487' rel='nofollow'>Introduction to the Special Issue on Intelligent User Interfaces</a> [Winter 2001]. By James Lester. AI Magazine 22(4): 13-14. &quot;Recent years have witnessed significant progress in intelligent user interfaces. Emerging from the intersection of AI and human-computer interaction, research on intelligent user interfaces is experiencing a renaissance, both in the overall level of activity and in raw research achievements. Research on intelligent user interfaces exploits developments in a broad range of foundational AI work, ranging from knowledge representation and computational linguistics to planning and vision. Because intelligent user interfaces are designed to facilitate problem-solving activities where reasoning is shared between users and the machine, they are currently transitioning from the laboratory to applications in the workplace, home, and classroom.&quot; 
</p>
<div class='vspace'></div><ul><li>See <a class='urllink' href='http://www.aaai.org/ojs/index.php/aimagazine/issue/view/144/showToc' rel='nofollow'>all of the articles in the special issue</a>.
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.informationweek.com/news/showArticle.jhtml?articleID=196902178' rel='nofollow'>Microsoft Predicts The Future With Vista's SuperFetch</a> - SuperFetch, a feature within Vista, predicts which applications are used when, then pre-loads them so that they're instantly available. By Gregg Keizer. InformationWeek (January 19, 2007). &quot;Microsoft Research contributed to the SuperFetch effort, a feature within Vista that predicts which applications are used when, then pre-loads them so that they're instantly available. 'As part of a long term set of projects, we want to teach the computer to learn from users to make the machine more proactive,' says Eric Horvitz, a principal researcher with Microsoft's R&amp;D as well as the president-elect of the American Association for Artificial Intelligence. 'We want to use the system's idle time to make things punchier.' Horvitz and his colleagues developed the core algorithms that make up the predictive part of SuperFetch, the technology that plays Nostradamus for the operating system. ... Long-range, says Horvitz, he'd like to extend SuperFetch-like predicting to actions within individual applications&quot;
</p>
<div class='vspace'></div><ul><li>Also watch this <span  style='color: #ff00ff;'>video</span>: <a target='_blank'  class='urllink' href='http://channel9.msdn.com/ShowPost.aspx?PostID=213112#213112' rel='nofollow'>Eric Horvitz - Better communication productivity</a>. A Microsoft Channel 9 Forum Video (July 7, 2006). &quot;In this video, Robert and Charles drop in on Eric Horvitz at Microsoft Research.  It’s always great to get an update on things he’s been up to. This time, we focus on technologies aimed at making it easier for people to communicate with each other, but we have a freewheeling discussion. We hear about research on the Bestcom project. Bestcom is short for 'best-means communication'. With Bestcom, smart computer agents try to figure out the context of people and decide how best to hook them up… based their own preferences and situations. Eric shows us a prototype named Bestcom-ET which has been used by many people inside Microsoft. This prototype led to the Communicator product. Eric also talks about Bayesphone, a really smart smartphone --and he also shows us some of the output of the Coordinate prototype. Coordinate does 'presence and availability forecasting'. Coordinate uses machine learning to make forecasts about things like when someone will next be in their office, when they will next read email, and next be free for some time to chat. Sounds eerie…but not to worry -- people have nice privacy controls to decide which people (or agents) they want to share these kinds of forecasts with. Fun stuff!&quot;
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.nytimes.com/2005/10/16/magazine/16guru.html' rel='nofollow'>Meet the Life Hackers</a>. By Clive Thompson. The New York Times Magazine (October 16, 2005). &quot; ... When you work next to other people, they can sense whether you're deeply immersed, panicking or relatively free and ready to talk - and they interrupt you accordingly. So why don't computers work this way? Instead of pinging us with e-mail and instant messages the second they arrive, our machines could store them up - to be delivered only at an optimum moment, when our brains are mostly relaxed. One afternoon I drove across the Microsoft campus to visit a man who is trying to achieve precisely that: a computer that can read your mind. His name is Eric Horvitz, and he is one of [Mary] Czerwinski's closest colleagues in the lab. For the last eight years, he has been building networks equipped with artificial intelligence (A.I.) that carefully observes a computer user's behavior and then tries to predict that sweet spot - the moment when the user will be mentally free and ready to be interrupted. Horvitz booted the system up to show me how it works. ... &quot; 
</p>
<div class='vspace'></div><ul><li>Also see/<em>hear</em> <a target='_blank'  class='urllink' href='http://www.npr.org/templates/story/story.php?storyId=4958831' rel='nofollow'>'Interruption Science' - Costly Distractions at Work</a> (<span  style='color: #ff00ff;'>radio broadcast</span>). NPR's Day to Day (October 14, 2005) &quot;Technology forces us to juggle competing demands on our attention over the course of our workdays. Alex Chadwick speaks with New York Times Magazine contributor Clive Thompson about 'interruption science,' the study of the effect of disruptions on job performance.&quot; Excerpt: &quot;<em>Clive Thompson</em>: But another, perhaps more ambitious attempt is to work on artificial intelligence that observes you and knows when you're busy so that when an e-mail comes, it doesn't just automatically set off a ding saying 'Hey, there's e-mail.' It actually waits five or 10 minutes until you're finished with whatever you're doing and then gives you the message at the moment when you are, you know, unencumbered and ready to receive it.' [<em>audio available</em>] 
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.fastcompany.com/magazine/110/head-for-detail.html' rel='nofollow'>A Head For Detail</a> - Gordon Bell feeds every piece of his life into a surrogate brain, and soon the rest of us will be able to do the same. But does perfect memory make you smarter, or just drive you nuts? By Clive Thompson. FastCompany.com (November 2006; Issue 110: Page 72). &quot;Gordon Bell will never forget what I look like. He'll never forget what I sound like, either. Actually, he'll never forget a single detail about me. That's because when I first met the affable 72-year-old computer scientist at the offices of Microsoft Research Labs, in Redmond, Washington, he was carefully recording my every move. He had a tiny bug-eyed camera around his neck, and a small audio recorder at his elbow. As we chatted about various topics--Australian jazz musicians, his futuristic cell phone, the Seattle area's gorgeous weather--Bell's gear quietly logged my every gesture and all my blathering small talk, snapping a picture every 60 seconds. Back at his office, his computer had carefully archived every document related to me: all the email I'd sent him, copies of my articles he'd read, pages he'd surfed on my blog. ... For the past seven years, Bell has been conducting an audacious experiment in 'lifelogging'--creating a near-total digital record of his experience. His custom-designed software, 'MyLifeBits,' saves everything it can get its hands on. ... You could trace the notion of perfect recall back to 1945, when presidential science adviser Vannevar Bush published a provocative essay in The Atlantic Monthly entitled 'As We May Think.' ... Consider for a second how, precisely, we think. We use our memories all the time, of course, often by "active" remembering--scrolling through our minds to locate a tidbit. But much mental labor is passive. We think about something in the background, subconsciously letting a problem brew. Then we suddenly hit upon an interesting combination of things, a new way of thinking about a problem: the elusive, all-important epiphany. What if our computers had their own intelligence, and could do that background work for us? ... One of Bell's Microsoft allies is also investigating whether artificial intelligence could be used to find hidden patterns in memory. One day last summer, I visited Eric Horvitz, an expert in machine intelligence at the Research Labs, to see his 'Lifebrowser.' The Lifebrowser's goal is to automatically identify the most significant events in your life, so that when you scroll back through your history, it shows you only the most important highlights.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.informationweek.com/story/showArticle.jhtml?articleID=161501161&amp;tid=5979' rel='nofollow'>AI's Next Brain Wave</a>. New research in artificial intelligence could lay the groundwork for computer systems that learn from their users and the world around them. Part four in The Future Of Software series. By Aaron Ricadela. InformationWeek (April 25, 2005). &quot;Computer scientists at the Palo Alto Research Center also are trying to bring user interfaces to life by replacing raw information with material that selects itself based on what the computer thinks the user wants to know. PARC's user-interface group published a paper in January describing new software called ScentHighlights that helps users skim information by extracting key sentences from an electronic book, relevant to keywords a user types in or clicks on in the text. The system, based on a PARC theory called information scent, is part of an emerging class of user interfaces that react to what gets a user's attention, says Stuart Card, manager for user-interface research and a senior research fellow at PARC.&quot;
</p>
<div class='vspace'></div><ul><li>PARC &amp; ACM have made the referenced paper, &quot;ScentHighlights: highlighting conceptually-related sentences during reading,&quot; by Chi, E. H.; Hong, L.; Gumbrecht, M.; and Card, S. K. (Proceedings of the 10th International Conference on Intelligent User Interfaces; 2005 January 10-13; San Diego; CA)  available for your personal use via a link from <a target='_blank'  class='urllink' href='http://www.parc.xerox.com/research/publications/details.php?id=5444' rel='nofollow'>this page</a>.
<div class='vspace'></div><ul><li><a target='_blank'  class='urllink' href='http://www.pbs.org/saf/1502/index.html' rel='nofollow'>Cars that Think</a>. PBS television broadcast of <em>Scientific American Frontiers</em> (January 26, 2005). &quot;The fully automatic car may be down the road a ways, but cars that do your thinking for you are just around the corner -- they watch out for hazards, they listen to you, they read your lips, they even know when you're distracted.&quot;
</li><li><a class='urllink' href='http://www.aaai.org/AITopics/html/archvF3.html#mar7b' rel='nofollow'>Intelligent software aims to give users peace of mind</a>. Microsoft Notebook feature by Todd Bishop. Seattle Post-Intelligencer (March 7, 2005).
</li></ul></li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://trnmag.com/Stories/2005/082205/View_Brad_Myers_082205.html' rel='nofollow'>CMU's Brad Myers</a>. Technology Research News Editor Eric Smalley carried out an email conversation with Carnegie Mellon University professor Brad Myers. (August 22, 2005). &quot;<em>Myers</em>:  Another area that I think is going to take off is intelligent interfaces, where the system actively tries to be helpful and learns from the user.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.eecs.harvard.edu/grosz/papers/APSfinal.pdf' rel='nofollow'>Beyond Mice and Menus</a>. By <a target='_blank'  class='urllink' href='http://www.eecs.harvard.edu/grosz/' rel='nofollow'>Barbara J. Grosz</a>, Higgins Professor of Natural Sciences, Harvard University. To appear in Proceedings of the American Philosophical Society (2004). &quot;Most computer systems today are interactive, making it important to highlight the often-overlooked differences between interaction and collaboration. These differences are starkly illustrated by a contrast between two types of driving activity: driving in Boston and driving in a convoy. Driving in Boston is highly interactive, as anyone who has attempted this activity knows. It is not, however, collaborative, even if drivers follow certain traffic laws and act simultaneously in seeming coordination. Although Boston drivers may have a goal in common --- namely, filling any empty space in front of their vehicles --- they do not share commitment to a common goal toward which they work together nor any commitment to the success of other drivers. Although there may be communication between drivers, it is not in service of a common goal. In contrast, driving in a convoy is a paradigmatic team activity (Levesque et al., 1990). Convoy drivers have a goal in common; they agree on where they are going, and each has a commitment to everyone reaching that destination. They also come to agreement, perhaps incrementally, about the route to follow to their destination; they have a 'shared recipe' for performing their group activity (Grosz and Kraus, 1996). Furthermore, they have some means of communicating with one another so that they can all remain apprised (or, more formally, 'maintain mutual belief') of the status of their joint activity. Before the advent of cell phones, check points and hand signals served to ensure this updating of status. The commitments of drivers in a convoy to one another's successfully reaching their goal leads to their being willing to help one another, should anyone get in trouble. Thus, convoy driving has three main characteristics of collaboration: commitment to a joint activity, an agreed upon recipe, and commitment to the success of others on the team. Requirements for communication and inclinations toward helpful behavior may be derived from these fundamental characteristics. A collaborative computer system is a problem-solving partner rather than a simple-minded servant. &quot; This excerpt can be found on pages 4 - 5. 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.businessweek.com/technology/content/aug2003/tc20030825_4912_tc121.htm' rel='nofollow'>The Ghost in Your Machine</a> - Computers may soon monitor your work, notice when fatigue sets in, and fix mistakes. BusinessWeek Online Reporter Olga Kharif interviews Chris Forsythe (August 25, 2003). &quot;At their most benign, smart computers seem like executive secretaries for those of us who can't afford one -- offering tremendous advances in productivity. Yet some fear that the concept suggests an ominous encroachment out of a sci-fi movie. Cognitive psychologist Chris Forsythe, who leads the Sandia team, insists that the machines are designed to augment -- not replace -- human activity. 'We don't want to take the human out of the loop,' he says. ... Q: How would you characterize the current state of human-machine interaction? A: The biggest problem is that if you're the user, for the most part the technology doesn't know anything about you. The onus is on the user to learn and understand how the technology works. What we would like to do is reverse that equation so that it becomes the responsibility of the computer to learn about the user. The computer would have to learn what the user knows, what the user doesn't know, how the user performs everyday, common functions. It would also recognize when the user makes a mistake or doesn't understand something.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://pattie.www.media.mit.edu/people/pattie/CACM-94/CACM-94.p1.html' rel='nofollow'>Agents that Reduce Work and Information Overload.</a> By Pattie Maes (1994). A very clear and crisp introduction to "interface agents [that] are computer programs that employ Artificial Intelligence techniques to provide active assistance to a user with computer-based tasks." 
</p>
<p class='vspace'><a class='urllink' href='http://www.aaai.org/ojs/index.php/aimagazine/issue/view/144/showToc' rel='nofollow'>Designing for Human-Agent Interaction</a>. By Michael Lewis. AI Magazine 19(2): Summer 1998, 1998, 67-78. &quot;Interacting with a computer requires adopting some metaphor to guide our actions and expectations. Most human-computer interfaces can be classified according to two dominant metaphors: (1) agent and (2) environment. Interactions based on an agent metaphor treat the computer as an intermediary that responds to user requests. In the environment metaphor, a model of the task domain is presented for the user to interact with directly. The term agent has come to refer to the automation of aspects of human-computer interaction (HCI), such as anticipating commands or autonomously performing actions. Norman's 1984 model of HCI is introduced as reference to organize and evaluate research in human-agent interaction (HAI). A wide variety of heterogeneous research involving HAI is shown to reflect automation of one of the stages of action or evaluation within Norman's model. Improvements in HAI are expected to result from a more heterogeneous use of methods that target multiple stages simultaneously.&quot;
</p>
<p class='vspace'><a name='readon' id='readon'></a>
</p>
<table ><tr><td width='200'  valign='top'>
<h2 class='backgrnd5'><span class='text1'>General Readings</span></h2>
</td></tr></table>
<p class='vspace'><a target='_blank'  class='urllink' href='http://news.bbc.co.uk/1/hi/technology/4749507.stm' rel='nofollow'>Squirrel helps with mobile calls</a>. By Luke Alexander. BBC News (August 26, 2005). &quot;There are few things more intrusive than a mobile phone ringtone. ... MIT research student Stefan Marti may have the answer: ditch your mobile phone, and get a squirrel. Specifically, an animatronic desktop squirrel which deals with your calls for you. The squirrel answers phone calls, works out if you are busy or asleep, evaluates how important the incoming call is and takes messages. When it wants to alert its owner to a call, it waves and moves about rather than making a sound. And, it is ridiculously cute. ... The key principle behind the Autonomous Interactive Intermediary (AII), or 'cellular squirrel', is that machines should display what psychologists call social or emotional intelligence. In other words, a computer should be able to communicate information in a way which is responsive to the social situations around it.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.isi.edu/expect/papers/blythe-kim-rama-gil-iui01.pdf' rel='nofollow'>An Integrated Environment for Knowledge Acquisition</a>. By Jim Blythe, Jihie Kim, Surya Ramachandran, Yolanda Gil. <a target='_blank'  class='urllink' href='http://www.isi.edu/' rel='nofollow'>Information Sciences Institute</a>, University of Southern California. Best Paper, International Conference on Intelligent User Interfaces, 2001. Abstract: &quot;This paper describes an integrated acquisition interface that includes several techniques previously developed to support users in various ways as they add new knowledge to an intelligent system. As a result of this integration, the individual techniques can take better advantage of the context in which they are invoked and provide stronger guidance to users. We describe the current implementation using examples from a travel planning domain, and demonstrate how users can add complex knowledge to the system.&quot;
</p>
<div class='vspace'></div><ul><li>Also see their Quicktime <a target='_blank'  class='urllink' href='http://www.isi.edu/expect/expect-movie.mov' rel='nofollow'>movie</a> about the <a target='_blank'  class='urllink' href='http://www.isi.edu/expect/' rel='nofollow'>EXPECT project</a>. 
</li></ul><p class='vspace'><a class='urllink' href='http://www.aaai.org/Library/Symposia/Spring/ss00-04.php' rel='nofollow'>Smart Graphics: Papers from the 2000 Spring Symposium</a>, ed. Andreas Butz, Antonio Krüger, and Patrick Olivier. <a class='urllink' href='http://www.aaai.org/Press/Reports/Symposia/Spring/ss-00-04.php' rel='nofollow'>Technical Report SS-00-04</a>. American Association for Artificial Intelligence, Menlo Park, California. &quot;Advances in the field of computer graphics have made visual media a major ingredient of the modern interface and it is certain that graphics will play an increasingly important role in the way people communicate and interact with computers in the future. Smart Graphics is the interdisciplinary approach to the design, generation, presentation and interaction with 2D and 3D graphical interfaces in a manner that is sensitive to technological, computational and cognitive constraints. As an enterprise it relies on the synthesis of insights from graphic design, cognitive science, human-computer interaction, graphics and artificial intelligence, and the symposium aims to broker a multidisciplinary dialogue between these communities.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.cis.udel.edu/~mccoy/publications/1992/DemaMcCo92.txt' rel='nofollow'>Generating Text from Compressed Input: An Intelligent Interface for People with Severe Motor Impairments.</a> By Patrick W. Demasco and Kathleen F. McCoy. Appears in Communications of the ACM, May 1992, Vol. 35, No.5 (1992) and made available by one of the authors. 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.sciam.com/article.cfm?articleID=000C07AA-99F2-1C72-9EB7809EC588F2D7&amp;catID=2' rel='nofollow'>The Future of Computing</a>. By Michael L. Dertouzos. Scientific American (August 1999). "To date, computer vendors have abused the phrase ease of use.' When they call a system user-friendly, it is tantamount to dressing a chimp in scrubs and earnestly parading it around as a surgeon. When I say "ease of use," I do not mean incorporating more colors and floating animals into our systems. I mean true ease of use, even if the interaction is only via text." 
</p>
<div class='vspace'></div><div><span class='rfloat'><img src='http://www.aaai.org/AITopics/assets/Page%20Art/highfive.gif' alt='high-fiving with computer' title='high-fiving with computer' /> </span></div>
<p><a target='_blank'  class='urllink' href='http://www.wired.com/wired/archive/11.12/love.html' rel='nofollow'>The Love Machine</a> - Building computers that care. By David Diamond. Wired Magazine (December 2003). &quot;'I want computers to have emotions only to help them survive in the world, not as a way of responding to me,' says Don Norman, a professor of computer science at Northwestern and a computer interface expert. 'I'd rather have a machine that knows its place. Otherwise, you feel like it's a used-car salesman.'&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.microsoft.com/billgates/speeches/2001/04-02chi.asp' rel='nofollow'>Remarks by Bill Gates</a>. CHI 2001 Conference on Human Factors in Computing Systems (Seattle; April 2, 2001). &quot;What I wanted to do today is share some of the projects that Microsoft is involved in that we hope will create new frontiers for human/computer interfaces. I also thought I could take some of my favorite Microsoft error messages and get your feedback, this is one I just got recently. I think it's fair to say that Microsoft has done good things in computer/human interface, and also done its fair share of bad things as well. And so we look forward to participating in the conference, and seeing what new things we can do.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.mitre.org/news/the_edge/december_99/index.html' rel='nofollow'>Intelligent Human-Computer Interfaces</a>. Lynette Hirschman, Guest Editor. The Edge (The MITRE Advanced Technology Newsletter, December 1999) Volume 3 Number 4. &quot;This issue is devoted to intelligent human-computer interfaces -- interfaces that raise the computer to the human level, rather than requiring that the human adapt to the computer. An interface may be intelligent because it can communicate using human language, or because it performs intelligent functions, or because it adapts to a specific task and user. In all these cases, an intelligent interface makes interaction with the computer easier, more intuitive, and more flexible. The area of intelligent interfaces is just one facet of the broad area of human-computer interaction. Other important areas include graphical user interface design, usability, human factors, visualization, immersive environments, and intelligent tutoring systems.&quot; 
</p>
<div class='vspace'></div><ul><li> The five articles in this issue are: Spoken Language Interfaces Gaining Acceptance as Technology Matures; Command Post of the Future Interactive Visualization to Increase Speed and Quality of Decision Making; DARPA Communicator Program Tackles Conversational Interface Challenges; IMPs Enhance Virtual Collaboration Environments; X-Technologies Ease Customization of Web Interfaces.'''
</li></ul><div class='vspace'></div><div><span class='rfloat'><img src='http://www.aaai.org/AITopics/assets/Page%20Art/news2.gif' alt='newspaper with link to news index' title='newspaper with link to news index' /></span></div>
<p><a target='_blank'  class='urllink' href='http://istresults.cordis.lu/index.cfm/section/news/tpl/article/BrowsingType/features/ID/76593' rel='nofollow'>Electronic butlers to facilitate human-to-human interaction</a>. IST Results (May 19, 2005). &quot;Need information, a translation, a conference recording? Let the butler handle it. The FAME [Facilitating Agents in Multicultural Exchange] butler, however, is no ordinary Jeeves; it is an intelligent agent integrating several key technologies that bridges linguistic, cultural, communication and information barriers. Developed under the European Commission&rsquo;s IST programme, the FAME information butler breaks new ground in the application of pervasive technologies, creating a system that works alongside users without the need for conscious human-machine interaction. ... Several of the partners are continuing to develop the technology in the follow-on IST project CHIL [Computers In the Human Interaction Loop] amid plans to commercialise components of the system over the coming years.&quot; 
</p>
<div class='vspace'></div><ul><li>Visit the <a target='_blank'  class='urllink' href='http://isl.ira.uka.de/fame/' rel='nofollow'>FAME</a> and <a target='_blank'  class='urllink' href='http://chil.server.de/servlet/is/101/' rel='nofollow'>CHIL</a> project sites. 
</li></ul><p class='vspace'><a class='urllink' href='http://www.aaai.org/AITopics/html/archvE9.html#sep2d' rel='nofollow'>When E-Mail Points the Way Down the Rabbit Hole</a>. Essay by Kirk Johnson. The New York Times (September 2, 2004; no fee reg. req'd.). &quot;The very basis of the spam wars is a search for better analysis of the way human beings think. ... Some theorists, like Professor [Sherry] Turkle at M.I.T., say the first real flash points of spam and human identity might come when our ever more sophisticated anti-spam programs start to understand us a little too well. ... 'As spam becomes more and more sophisticated, most people think your filter will be developed by a smart agent observing you carefully, so the question becomes, what kinds of information do people want their software agent to know?' Professor Turkle said.&quot; 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.acm.org/ubiquity/views/v6i17_tripathi.html' rel='nofollow'>Reflections on Challenges to the Goal of Invisible Computing</a>. By Arun Kumar, Department of Philosophy of Technololgy,Institute for Philosophy, Dresden University of Technology, Germany. ACM Ubiquity (May 17 - 24, 2005; Volume 6, Issue 17). &quot;We know that computers are complex beasts in their own right, but for all of their internal complexity computers are just as complicated in their embedding in the outside world, even though the complexity of this embedding is largely invisible to the people who design computers, and to people who make a living promoting their use. And it is possible that computers [fn] might have the power to change us even when we engage with them unconsciously, as when we relate to a tool through the performance of a skill like driving or typing.&quot;
</p>
<p class='vspace'><a class='urllink' href='http://www.aaai.org/AITopics/html/archvE2.html#feb5c' rel='nofollow'>Robots get friendly</a> - Robots are acting more like people. Will our attachments eventually become too strong? By Gregory M. Lamb. The Christian Science Monitor (February 5, 2003). &quot;Studies have shown that expectations are higher for such virtual people than, say, a faceless search engine like Google.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.computerworld.com/softwaretopics/os/story/0,10801,73729,00.html' rel='nofollow'>See Me, Hear Me . . . New computer interfaces may respond to gestures and speech</a>. By Sharon Machlis. Computerworld (August 26, 2002). &quot;Researchers working on new generations of interfaces are taking a pragmatic approach to how we'll interact with machines, adding support for text, speech, gaze, gesture and more, depending on circumstances and what seems to make sense. Ideally, tomorrow's computers will be better at anticipating what users want, without needing typed commands. This will involve 'context-aware' interfaces, according to Ted Selker, head of the context-aware computing research group at MIT's Media Lab. That might mean a Web application will be able to sense both your mouse and eye movements to determine whether you've visited a site before and what items most interest you -- and then dynamically generate a page based on those interests. By 2006, Selker says, 'the computer will know more about why you're doing what you're doing and what it can do to help you.' Speech-recognition software is already making inroads in telephone-based customer service applications.&quot; 
</p>
<div class='vspace'></div><dl><dd><ul><li>Check out <a target='_blank'  class='urllink' href='http://www.media.mit.edu/research/group.php?type=researchGroup%9d%9d1%9d%9did=13' rel='nofollow'>other Media Lab research group projects</a>.
</li></ul></dd></dl><p class='vspace'><a target='_blank'  class='urllink' href='http://wwwis.win.tue.nl/asum99/marinilli/marinilli.html' rel='nofollow'>A Case-Based Approach to Adaptive Information Filtering for the WWW</a>. By Mauro Marinilli, Alessandro Micarelli and Filippo Sciarrone; Dipartimento di Informatica e Automazione Universita di Roma. &quot;The system is based on a user modeling component, designed for building and maintaining long term models of individual Internet users. Presently the system acts as an intelligent interface for the Web search engines.&quot; 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.acm.org/crossroads/xrds3-1/emotware.html' rel='nofollow'>Emotionware</a>. By Lynellen D.S. Perry (1996). ACM Crossroads Student Magazine. "The capability of displaying emotion seems to be a critical component of creating intelligent agents with whom humans can comfortably relate and communicate. The emotional aspect distinguishes a dead machine from an agent who is believable, alive, and trustworthy." 
</p>
<p class='vspace'><a class='urllink' href='http://www.aaai.org/Library/Symposia/Spring/ss05-05.php' rel='nofollow'>Persistent Assistants: Living and Working with AI</a>: Papers from the 2005 Spring Symposium, ed. Daniel Shapiro, Pauline Berry, John Gersh,and Nathan Schurr. Technical Report SS-05-05. American Association for Artificial Intelligence, Menlo Park, California.
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.trnmag.com/Stories/2005/011205/Conversations_control_computers_011205.html' rel='nofollow'>Conversations control computers</a>. By Eric Smalley. Technology Research News (January 12/19, 2005). &quot;Because information from spoken conversations is fleeting, people tend to record schedules and assignments as they discuss them. Entering notes into a computer, however, can be tedious -- especially when the act interrupts a conversation. Researchers from the Georgia Institute of Technology are aiming to decrease day-to-day data entry and to augment users' memories with a method that allows handheld computers to harvest keywords from conversations and make use of relevant information without interrupting the personal interactions. ... The researchers' system protects privacy by only using speech from the user's side of the conversation, said [Kent] Lyons.&quot; 
</p>
<div class='vspace'></div><ul><li>After reading the article, you might want to visit the <a target='_blank'  class='urllink' href='http://www.cc.gatech.edu/ccg/projects/conversation/' rel='nofollow'>project web site</a>.
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www-2.cs.cmu.edu/~citrine/#Paper' rel='nofollow'>Citrine: Providing Intelligent Copy-and-Paste</a>. By Jeffrey Stylos, Brad A. Myers and Andrew Faulring. ACM Symposium on User Interface Software and Technology, UIST'04; pages 185-188. Abstract: &quot;We present Citrine, a system that extends the widespread copy-and-paste interaction technique with intelligent transformations, making it useful in more situations. Citrine uses text parsing to find the structure in copied text and allows users to paste the structured information, which might have many pieces, in a single paste operation. ...&quot;
</p>
<div class='vspace'></div><ul><li>Also from the <a target='_blank'  class='urllink' href='http://www-2.cs.cmu.edu/~citrine/' rel='nofollow'>Citrine project site</a>: &quot;the <a target='_blank'  class='urllink' href='http://www-2.cs.cmu.edu/~citrine/#Citrine_Phone_Dialer' rel='nofollow'>Citrine Phone Dialer</a>, allows the dialing of copied phone numbers. Its novelty --- and usefulness --- comes from automatically learning and applying dialing rules.&quot;
</li></ul><div class='vspace'></div><div><span class='rfloat'><a class='urllink' href='http://www.aaai.org/Library/Magazine/vol28.php#Summer' rel='nofollow'><img src='http://www.aaai.org/AITopics/assets/Page%20Art/aimag28-02.jpg' alt='AI Magazine cover' title='AI Magazine cover' /></a> </span></div>
<p><a class='urllink' href='http://www.aaai.org/AITopics/assets/PDF/AIMag28-02-002-1.pdf' rel='nofollow'>Seven Aspects of Mixed-Initiative Reasoning: An Introduction to this Special Issue on Mixed-Initiative Assistants</a>. By Gheorghe Tecuci, Mihai Boicu, and Michael T. Cox. <a class='urllink' href='http://www.aaai.org/Library/Magazine/vol28.php#Summer' rel='nofollow'>AI Magazine 28(2)</a>: Summer 2007, 11-18. &quot;Mixed-initiative assistants are agents that interact seamlessly with humans to extend their problem-solving capabilities or provide new capabilities. Developing such agents requires the synergistic integration of many areas of AI, including knowledge representation, problem solving and planning, knowledge acquisition and learning, multiagent systems, discourse theory, and human-computer interaction. This paper introduces seven aspects of mixed-initiative reasoning (task, control, awareness, communication, personalization, architecture, and evaluation) and discusses them in the context of several state-of-the-art mixed-initiative assistants. The goal is to provide a framework for understanding and comparing existing mixed-initiative assistants and for developing general design principles and methods.&quot; 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.sics.se/~annika/papers/intint.html' rel='nofollow'>What is an Intelligent Interface?</a> Notes from an introduction seminar, March 1997. By Annika Waern, groupleader of, and researcher in, the Human - Computer Interaction and Language Engineering (HUMLE) Group at the Sweedish Institute of Computer Science. &quot;The main application areas for intelligent interfaces are thus such where the knowledge about how to solve a task partially resides with the computer system. Since the user does not know exactly what should be done, he or she cannot manipulate the computer as a tool, but must ask the system to do something for him or her. This request may be incomplete, vague or even incorrect given the user's real needs. Some typical application areas that can be characterised this way are Intelligent tutoring, intelligent help and information filtering.&quot; 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://researchchannel.org/program/displayevent.asp?rid=2486' rel='nofollow'>Reflective Interfaces</a>: a video of Dan Weld's talk at <a target='_blank'  class='urllink' href='http://researchchannel.org/program/displayseries.asp?collid=485' rel='nofollow'>CSE Colloquia - 2005</a>, The University of Washington Computer Science &amp; Engineering Colloquium Series, available from the ResearchChannel (&quot;a non-profit organization founded in 1996 by a consortium of leading research universities, institutions and corporate research centers dedicated to creating a widely accessible voice for research through video and Internet channels&quot;).
</p>
<p class='vspace'><a class='urllink' href='http://www.aaai.org/Library/Reports/nii.php' rel='nofollow'>The Role of Intelligent Systems in the National Information Infrastructure</a>. An American Association for Artificial Intelligence <a class='urllink' href='http://www.aaai.org/Library/Reports/reports-library.php' rel='nofollow'>Policy Report</a>. Edited by Daniel S. Weld, University of Washington. Excerpt from (2.1) <a class='urllink' href='http://www.aaai.org/Library/Reports/nii.php#RTFToC17' rel='nofollow'>Intelligent Interfaces</a>: &quot;The gap between current tools and the NII's human-computer communication demands leads to a crucial challenge: providing intelligent interfaces to resources so that people can use the NII without difficulty. ... To be called 'intelligent,' it must satisfy several interrelated criteria: Integrated ... Expressive ... Goal oriented ... Cooperative ... Customized.
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://hci.stanford.edu/bds/' rel='nofollow'>Bringing Design to Software</a>. Edited by Terry Winograd. (Addison-Wesley. 1996) "The book contains essays contributed by prominent software and design professionals, interviews with experts, and profiles of successful projects and products. These elements are woven together to illuminate what design is, to identify the common core of practices in every design field, and to show how software builders can apply these common practices to produce software that is more effective, more appropriate, and more satisfying for users." Many sections of the book are available online, including Winograd's <a target='_blank'  class='urllink' href='http://hci.stanford.edu/bds/bds-intro.html' rel='nofollow'>Introduction</a>. 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.acm.org/sigchi/cdg/' rel='nofollow'>Curricula for Human-Computer Interaction</a>. From the ACM Special Interest Group on Computer-Human Interaction, Curriculum Development Group. Don't miss Chapter 2 which covers topics such as: Definition of HCI, Historical Roots, and The Nature of Human-Computer Interaction. 
</p>
<p class='vspace'><a name='web' id='web'></a>
</p>
<table ><tr><td width='200'  valign='top'>
<h2 class='backgrnd5'><span class='text1'>Related Resources</span></h2>
</td></tr></table>
<p class='vspace'><a target='_blank'  class='urllink' href='http://research.microsoft.com/adapt/' rel='nofollow'>Adaptive Systems &amp; Interaction Group</a> (ASI) at Microsoft Research. Areas of Focus include User Modeling and Intelligent User Interfaces (&quot;We pursue methods for enhancing human-computer interaction via architectures that mesh models of a users' context-sensitive interests, needs, and goals with expressive event systems that sense activity and related information.&quot;), Information Access, Filtering, and Management (&quot;We are pursuing principles and applications of technologies that allow information retrieval, filtering, and management. In this realm, we have refined collaborative filtering (CF) algorithms methods for recommending content or services to a user based on the analysis of the behavior of a large number of users.&quot;), and Conversational Systems.
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.merl.com/projects/collagen/' rel='nofollow'>COLLAGEN</a> (COLLaborative AGENt) is Java middleware for building collaborative agents. From MERL (the North American arm of the central R&amp;D organization of Mitsubishi Electric Company). &quot;A collaborative agent is a software program that helps users solve problems, especially in complex or unfamiliar domains, by correcting errors, suggesting what to do next, and taking care of low-level details. A collaborative agent can be added to an existing graphical user interface, such as a software simulator, or integrated into the design of a new hardware device, such as a personal video recorder. COLLAGEN is currently being used to build prototype systems for a range of applications, including power plant operator training, car navigation, and spoken-language web form filling.&quot; 
</p>
<div class='vspace'></div><ul><li>Also check out this other project from MERL: <a target='_blank'  class='urllink' href='http://www.merl.com/projects/hosting/' rel='nofollow'>Human-Robot Interaction for Hosting Activities</a>. 
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.hcrc.ed.ac.uk/comic/' rel='nofollow'>COMIC</a>. <strong>CO</strong>nversational <strong>M</strong>ultimodal <strong>I</strong>nteraction with <strong>C</strong>omputers. Max Planck Institute for Psycholinguistics, coordinating partner.
</p>
<div class='vspace'></div><ul><li><a target='_blank'  class='urllink' href='http://istresults.cordis.lu/index.cfm/section/news/tpl/article/BrowsingType/Features/ID/69179' rel='nofollow'>Facing the future of intuitive interfaces</a>. IST Results (July 23, 2004). &quot;A prototype intuitive computer interface for bathroom design, developed by IST project COMIC that enables multimodal user interaction, is making computer programming more accessible. 'We need services that are able to actively assist and support users in solving their problems, rather than passively wait for the users to express their intentions in a language that is reminiscent of programming,' explains Dr Els den Os, project coordinator of COMIC at the German and Dutch Max-Planck Institute for Psycholinguistics. To achieve this, computers need to combine a number of input and output modules such as speech, gestures, text and pictures.&quot;
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://gn.www.media.mit.edu/groups/gn/projects/humanoid/index.html' rel='nofollow'>Conversational Humanoid</a>. From the Gesture &amp; Narrative Language research group at the MIT Media Lab. &quot;We are developing autonomous agents that are capable of having a real-time face-to-face conversation with a human. These agents are human in form and communicate using both verbal and non-verbal modalities. We believe that such agents provide a new form of human-computer interface which users can interact with naturally, without training, since they already know how to engage in face-to-face conversation with other people.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.cl.cam.ac.uk/users/re227/' rel='nofollow'>Emotionally Intelligent Interfaces</a>. From the Rainbow Research Group at the University of Cambridge Computer Laboratory. &quot;Facial displays are an important channel for the expression of emotions and are often thought of as projections or 'read out' of a person’s mental state. Our research objective is to develop emotionally intelligent interfaces that make use of this readily available input modality to adapt and respond to its user.&quot;
</p>
<p class='vspace'><a name='fluids' id='fluids'></a>&quot;<a target='_blank'  class='urllink' href='http://www.dfki.de/fluids/' rel='nofollow'>FLUIDS</a> [Future Lines of User Interface Decision Support] is a project in the Telematics Engineering sector of the Telematics Applications Programme managed by the European Commission (DG XIII). The project aims to provide a software environment for building intelligent interfaces for decision support systems by using reusable building blocks (adaptable to the requirements of different systems and users) and a methodology for designing and developing interface models.&quot; Be sure to read their introduction to <a target='_blank'  class='urllink' href='http://www.dfki.de/fluids/Intelligent_User_Interfaces.html' rel='nofollow'>Intelligent User Interfaces</a> and then follow the links to New Achievements in Research, Latest Commercial Developments, Research and Market Trends in Europe, Research and Market Trends in Japan and USA, and Related Information Sources.
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.hcibib.org/' rel='nofollow'>HCI Bibliography</a>. Provided by the <a target='_blank'  class='urllink' href='http://www.hcibib.org/about.html' rel='nofollow'>HCI Bibliography Project</a>. Over 33,500 records (as of January 2006) including a definition of HCI, the history of HCI, recommended readings, conferences, and much more. 
</p>
<div class='vspace'></div><ul><li>Also available from HCIBIB is the  <a target='_blank'  class='urllink' href='http://www.hcibib.org/hci-sites/' rel='nofollow'>HCI Sites page</a>: &quot;a collection of resources on Human-Computer Interaction. It replaced Keith Instone's HCI Virtual Library (originally the HCI Launch Pad).&quot; 
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://hci.stanford.edu/research' rel='nofollow'>HCI Research at Stanford</a>. Explore the amazing diversity of contexts in which the science of HCI is being applied. 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.hcii.cmu.edu/Research/projects.html' rel='nofollow'>Human Computer Interaction Institute</a>. Carnegie Mellon University. Among the many, and diverse, research projects that you'll find on this page are &quot;Demonstrational Interfaces ... the user gives an example of how the system should operate, and the system automatically generalizes from the example to produce a parameterized procedure.&quot; and &quot;GM/CMU Project: Driver-Vehicle Interface - The goal is to improve security and driver-vehicle interfaces, by building a car that can analyze the driver's intention and watch the driver's physical and mental status for any impairments or information overload. The application combines a smart car environment and monitoring of driver state, with a wide range of input-output modalities.&quot; 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.hml.queensu.ca/' rel='nofollow'>Human Media Lab</a>. Queen's University. &quot;HML researchers at Queen's University's School of Computing are addressing the problem of the barrage of messages people receive from large numbers of digital appliances. Their Attentive User Interface (AUI) is a new paradigm for interacting with groups of computers that moves beyond the traditional desktop interface. Current computers are generally designed to act in isolation, without considering what the user is doing before producing distracting interruptions. As a result, today’s user has trouble keeping up with volumes of e-mail, instant messages, phone calls and appointment notifications. 'Today’s digital lifestyle has the unfortunate side effect of bombarding people with messages from many devices all the time, regardless of whether they’re willing, or able to respond,' says HML director Dr. Roel Vertegaal. 'Like spam [unsolicited e-mail], this problem needs to be addressed.' The HML team is designing devices that determine the level of user attention and the importance of each message relative to what the user is doing. Then the computer decides whether to 'take a turn' to deliver the message.&quot; - from <a target='_blank'  class='urllink' href='http://qnc.queensu.ca/story_loader.php?id=3e89a0eed6e29' rel='nofollow'>Researchers invent computers that “pay attention” to users</a>. Queen's News Centre (April 1, 2003).
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.cs.washington.edu/research/projects/ai/www/projects/Intelligent_User_Interfaces/index.html' rel='nofollow'>Intelligent User Interfaces</a>. University of Washington. "Macro systems are a form of programming by demonstration (PBD), in which users demonstrate their task to the system, which then learns a program that accomplishes the task. The benefits of PBD are that the user doesn't need to learn an arcane programming language in order to automate repetitive tasks, and she demonstrates her programs using an interface with she is already familiar. However, existing macro recorder systems have many drawbacks. ... This research aims to address these three drawbacks by combining a simple macro recording interface with AI machine learning techniques. Our goal is to apply algorithms from AI to construct a robust, domain-independent programming by demonstration system.&quot; 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.iuiconf.org/index.html' rel='nofollow'>International Conferences on Intelligent User Interfaces</a> (IUI). &quot;Since 1997, the annual conferences on Intelligent User Interfaces (IUI) have been the principal international forums for the presentation and discussion of outstanding research and applications involving intelligent user interfaces, a field that intersects Human Computer Interaction and Artificial Intelligence. In 2007, we will be celebrating the 10th anniversary of the first IUI conference.&quot; 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://iswc.tinmith.net/home.htm' rel='nofollow'>International Symposium on Wearable Computers</a>. Topics addressed at the 6th International Symposium on Wearable Computers (October 2002) included: &quot;Human Interface, including hands-free user speech recognition, sensory augmentation, human-centered robotics, user modeling, user evaluations, and health issues.&quot; 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.ccs.neu.edu/home/bickmore/agents/' rel='nofollow'>Relational Agents</a>. From Timothy Bickmore, Assistant Professor College of Computer and Information Science, Northeastern University. &quot;Relational Agents are computational artifacts designed to build and maintain long-term, social-emotional relationships with their users. Central to the notion of relationship is that it is a persistent construct, spanning multiple interactions, thus Relational Agents are explicitly designed to remember past history and manage future expectations in their interactions with users.&quot;
</p>
<div class='vspace'></div><ul><li>Also see this news article: <a class='urllink' href='http://www.aaai.org/AITopics/html/archvH5.html#may21f' rel='nofollow'>'Laura' makes digital health coaching personal</a>. 
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.nsf.gov/od/lpa/news/press/00/pr0051.htm' rel='nofollow'>STIMULATE</a>. Rutgers University. &quot;[R]esearchers in a project called STIMULATE are developing systems that mimic other forms of communication that humans use to interact with each other, including eye contact, touch and voice. The experimental hardware and software may find uses in medicine, the military and other fields that could benefit from more natural forms of human-computer interaction across distributed networks." 
</p>
<p class='vspace'><a name='more' id='more'></a>
</p><h2>Other References Offline</h2>
<p>Ehrlich, K., and A. Henderson. (Inter)facing the Millennium: Where Are We (Going)? Interactions (January-February 2000) pages 19 - 30. A timely and exciting collection of thoughts and viewpoints about HCI - past, present and future. 
</p>
<p class='vspace'>Mittal, Vibhu O., Holly A Yanko, John Aronis, and Richard Simpson, Editors. 1998. <a target='_blank'  class='urllink' href='http://link.springer.de/link/service/series/0558/tocs/t1458.htm' rel='nofollow'>Assistive Technology and Artificial Intelligence: Applications in Robotics, User Interfaces and Natural Language Processing</a>. Berlin: Springer-Verlag. Lecture Notes in Artificial Intelligence #1458. 
</p>
<p class='vspace'>Vertegaal, Roel, Editor. March 2003. <a target='_blank'  class='urllink' href='http://portal.acm.org/citation.cfm?id=636772.636793&amp;coll=GUIDE&amp;dl=ACM&amp;type=issue&amp;idx=636772&amp;part=periodical&amp;WantType=periodical&amp;title=Communications%20of%20the%20ACM&amp;CFID=33845227&amp;CFTOKEN=56015883' rel='nofollow'>Attentive user interfaces</a>, a Special Issues of the Communications of the ACM (Volume 46 , Issue 3). The <a target='_blank'  class='urllink' href='http://portal.acm.org/toc.cfm?id=636772&amp;type=issue&amp;coll=GUIDE&amp;dl=ACM&amp;CFID=33845227&amp;CFTOKEN=56015883#636793' rel='nofollow'>table of contents and abstracts</a> are available to non-subscribers.
</p>
</div>

      </td>
    </tr></table>
	</div>

<!--PageFooterFmt-->
  <div id='wikifoot' class='backgrnd11'>
    <div class='footnav'>
			<a href='http://www.aaai.org/'>AAAI Home</a>&nbsp;&nbsp;
			<a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/RecentChanges' accesskey='c'>Recent Changes</a></span>&nbsp;&nbsp;
			<a rel="nofollow" href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interfaces?action=edit'>Edit</a>&nbsp;&nbsp;
      <a rel="nofollow" href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interfaces?action=diff'>History</a>&nbsp;&nbsp;
      <a rel="nofollow" href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interfaces?action=print' target='_blank'>Print</a>&nbsp;&nbsp;
<!--      <a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/RecentChanges'>Recent Changes</a>&nbsp;&nbsp;
      <a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Site/Search'>Search</a> - -->
			<a href='mailto:videos08@aaai.org?subject=AI Topics Contact'>Contact Us</a></div>
    <div class='lastmod'>Page last modified on December 13, 2008, at 08:16 PM</div></div>
<!--HTMLFooter-->
</body>
</html>

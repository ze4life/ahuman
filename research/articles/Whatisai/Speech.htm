<!DOCTYPE html 
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
  <title>AITopics / Speech </title>
<!--  <title>AI Topics / AI Videos | AITopics / Speech </title> -->
  <meta http-equiv='Content-Style-Type' content='text/css' />
<!--HTMLHeader--><style type='text/css'><!--
  ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }
  code.escaped { white-space: nowrap; }
  .vspace { margin-top:1.33em; }
  .indent { margin-left:40px; }
  .outdent { margin-left:40px; text-indent:-40px; }
  a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }
  a.createlink { text-decoration:none; position:relative; top:-0.5em;
    font-weight:bold; font-size:smaller; border-bottom:none; }
  img { border:0px; }
  .editconflict { color:green; 
  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }

  table.markup { border:2px dotted #ccf; width:90%; }
  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }
  table.vert td.markup1 { border-bottom:1px solid #ccf; }
  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }
  table.markup caption { text-align:left; }
  div.faq p, div.faq pre { margin-left:2em; }
  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }
  div.faqtoc div.faq * { display:none; }
  div.faqtoc div.faq p.question 
    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }
  div.faqtoc div.faq p.question * { display:inline; }
   
    .frame 
      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }
    .lfloat { float:left; margin-right:0.5em; }
    .rfloat { float:right; margin-left:0.5em; }
a.varlink { text-decoration:none; }

--></style>  <meta name='robots' content='index,follow' />

  <link rel='stylesheet' href='http://www.aaai.org/AITopics/pmwiki/pub/skins/aaaiblue/aaaiblue.css' type='text/css' />
  <style type="text/css">
  <!--
	@import url("http://www.aaai.org/AITopics/pmwiki/pub/skins/aaaiblue/layout.css");
	-->
  </style>
	<script src="http://www.aaai.org/AITopics/pmwiki/track.js" type="text/JavaScript"></script>
</head>
<body class="backgrnd2" onLoad="addLinkerEvents()">
<!--PageHeaderFmt-->
	<div id="header" class="backgrnd1">
		<div id='wikihead'>
			<form action='http://www.aaai.org/AITopics/pmwiki/pmwiki.php' id="cse-search-box">
				<input type='hidden' name='n' value='AITopics.Speech' />
				<input type='hidden' name='action' value='search' />
				<!--    <a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Site/Search'>Search</a>: -->
				<input type='text' name='q' value='' size="25" class='inputbox searchbox' />
				<!-- Include Google Search parameters --> 
				<input type="hidden" name="cof" value="FORID:11" /><input type='submit' name="sa" class='inputbutton searchbutton' value='Search AI Topics' />
				<input type="hidden" name="cx" value="005943697473805803765:wzeb22stvpm" />
			</form>
			<script type="text/javascript">(function() {
var f = document.getElementById('cse-search-box');
if (!f) {
f = document.getElementById('searchbox_demo');
}
if (f && f.q) {
var q = f.q;
var n = navigator;
var l = location;
if (n.platform == 'Win32') {
q.style.cssText = 'border: 1px solid #7e9db9; padding: 2px;';
}
var b = function() {

};
var f = function() {
//q.style.background = '#ffffff';
};
//q.onfocus = f;
//q.onblur = b;
if (!/[&?]q=[^&]/.test(l.search)) {
b();
}
}
})();
</script>
		</div>
		
		<div id='wikilogo'><a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php'><img src='http://www.aaai.org/AITopics/pmwiki/pub/images/aaai-logo-t7.png' alt='AI Topics / AI Videos' border='0' /></a>	
		</div>
	</div>
<!--/PageHeaderFmt-->
	
	<div id="menu" class="backgrnd3">
		<ul>
			<li class="first"><a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics' accesskey="1" class="link1">AITopics</a></li>
			<li class="link2" style="padding-left:0px; padding-right:0px; font-size: 15px">/</li>
			<li class="link2" style="font-size: 15px;">Speech</li>
		</ul>
		
		<div id='wikicmds' ><ul><li><a accesskey='c'  rel='nofollow'  class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/RecentChanges'>Recent Changes</a>
</li><li><a accesskey='e'  rel='nofollow'  class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Speech?action=edit'>Edit</a>
</li><li><a accesskey='h'  rel='nofollow'  class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Speech?action=diff'>History</a>
</li><li><a accesskey=''  rel='nofollow'  class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Speech?action=print'>Print</a>
</li><li><a class='urllink' href='mailto:videos08@aaai.org?subject=AI%20Topics%20Contact' rel='nofollow'>Contact Us</a>
</li></ul>
</div>
	</div>
	
	
	<div id="content" class="backgrnd4">
	<table width='100%' cellspacing='0' cellpadding='0'>
  <tr>
<!--PageLeftFmt-->
      <td id='wikileft' valign='top'>
        <div class='vspace'></div><h2><strong>TOOLBOX</strong></h2>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Speech?action=edit'>Log In / Edit</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/SubmitNewContent'>Submit Content</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Tags/Tags'>Popular Tags</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AIVideos/HomePage'>Videos</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/A-ZIndex'>A-Z Index</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/SiteMap'>Site Map</a>
</li></ul><div class='vspace'></div><h2><strong>BROWSE TOPICS</strong></h2>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/AINews'>AI <em>in the news</em></a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/AIOverview'>AI Overview</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Agents'>Agents</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Applications'>Applications</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/CognitiveScience'>Cognitive Science</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Education'>Education</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Ethics'>Ethical &amp; Social</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/ExpertSystems'>Expert Systems</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Games'>Games &amp; Puzzles</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/History'>History</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interfaces'>Interfaces</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/MachineLearning'>Machine Learning</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/NaturalLanguage'>Natural Language</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Philosophy'>Philosophy</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Reasoning'>Reasoning</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Representation'>Representation</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Robots'>Robots</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/ScienceFiction'>Science Fiction</a>
</li><li><a class='selflink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Speech'>Speech</a>
</li><li><nobr><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Systems'>Systems &amp; Languages</a></nobr>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/TuringTest'>Turing Test</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Vision'>Vision</a>
</li></ul><div class='vspace'></div><h2><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Resources'><strong>RESOURCES</strong></a></h2>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/InteractiveResources'>Interactive</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/EducatorResources'>for Educators</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/StudentResources'>for Students</a>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Report'>Reports &amp; Projects</a>
</li></ul></li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/JournalistResources'>for Journalists</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/FAQs'>FAQs</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Reference'>Reference Shelf</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Main/EditPage'>Editing Pages</a>
</li></ul><div class='vspace'></div><h2><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/AboutUs'><strong>ABOUT THIS SITE</strong></a></h2>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Policies/HomePage'>Policies</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Project/HomePage'>Project Notes</a>
<div class='vspace'></div></li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/RecentChanges'>Changes</a>&nbsp;<img src='http://www.aaai.org/AITopics/pmwiki/pub/images/rss.gif' alt='RSS' title='RSS' />
</li></ul><div class='vspace'></div><div class='backgrnd6'>
<p  style='text-align: center;'><span style='font-size:83%'><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Notices#fairuse'>Fair Use Notice</a></span><br /><span style='font-size:83%'>&#169; <a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Notices#copy'>AAAI 2000-2008</a></span>
</p></div>
<p class='vspace'  style='text-align: center;'><a target='pmwiki'  class='urllink' href='http://www.pmwiki.org' rel='nofollow'>pmwiki.org</a> <br /><span style='font-size:83%'>pmwiki-2.2.0-beta65</span>
</p>
<p class='vspace'  style='text-align: center;'><span style='font-size:83%'><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/SideBar?action=edit'>edit SideBar</a></span>
</p>
</td>
<!--/PageLeftFmt-->
      <td id='wikibody' valign='top'>
<!--PageActionFmt-->
        
<!--PageTitleFmt-->
<!--        <div id='wikititle'>
          <div class='pagegroup'><a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics'>AITopics</a> /</div>
          <h1 class='pagetitle'>Speech</h1></div>   -->
<!--PageText-->
<div id='wikitext'>
<div  style='display: none;' > 
<h2  style='text-align: center;'> <strong>Speech</strong></h2>
</div>
<div class='vspace'></div><div style="float:left;padding: 0px 20px 10px 0px;">
<div id='topicContentBox' class='backgrnd9'><div class='backgrnd8' >
<div style="width:180px;font-size: 14px;text-align: center;margin-bottom: 5px;" ><strong><a class='selflink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Speech'>Speech</a></strong>
</div>
<ul><li>Readings:
<ul><li><a href='#good'>Introductory</a>
</li><li><a href='#readon'>General</a>
</li></ul></li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/VideoTags/Speech'>Videos</a>
</li><li><a href='#web'>Related Resources</a>
</li><li><a class='urllink' href='http://www.aaai.org/AITopics/xml/rss/speech.xml' rel='nofollow'>News Feed</a>&nbsp;<img src='http://www.aaai.org/AITopics/pmwiki/pub/images/rss.gif' alt='RSS' title='RSS' />
</li></ul></div><div class='backgrnd10' style='height:20px;'></div></div>
</div>
<div class='vspace'></div><div style="width:180px; float:right;padding: 0px 0px 0px 15px;text-align:center;">
<div><img src='http://www.aaai.org/AITopics/assets/Page%20Art/speech.gif' alt='sketch of person talking' title='sketch of person talking' /></div>
<div style="font-size:small; text-align:center;" >Did you say:<br />&quot;How to <a href='#beach'>recognize speech</a>&quot;,<br />&quot;How to <a href='#beach'>wreck a nice beach</a>&quot;, or<br />"How to <a href='#lieberman'>Wreck a Nice Beach You Sing Calm Incense</a>"
</div>
</div>
<p class='vspace'>...Simple inquiries about bank balance, movie schedules, and phone call transfers can already be handled by telephone-speech recognizers.<br />Voice activated data entry is particulary useful in medical or darkroom applications, where hands and eyes are unavailable, or in hands-busy or eyes-busy command and control applications. Speech could be used to provide more accessibility for the handicapped (wheelchairs, robotic aids, etc.) and to create high-tech amenities (intelligent houses, cars, etc.)
</p>
<p class='vspace'>- Alex Waibel and Kai-Fu Lee, from Readings in Speech Recognition
</p>
<p class='vspace'>The 1990s saw the first commercialization of spoken language understanding systems. Computers can now understand and react to humans speaking in a natural manner in ordinary languages within a limited domain. Basic and applied research in signal processing, computational linguistics and artificial intelligence have been combined to open up new possibilities in human-computer interfaces.
</p>
<p class='vspace'><a name='good' id='good'></a>
</p>
<table ><tr><td width='200'  valign='top'>
<h2 class='backgrnd5'><span class='text1'>Introductory Readings</span></h2>
</td></tr></table>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.sciam.com/article.cfm?id=making-computers-talk' rel='nofollow'>Making Computers Talk</a> - Say good-bye to stilted electronic chatter: new synthetic-speech systems sound authentically human, and they can respond in real time. By Andy Aaron, Ellen Eide and John F. Pitrelli. Scientific American Explore (March 17, 2003). &quot;Scientists have attempted to simulate human speech since the late 1700s, when Wolfgang von Kempelen built a 'Speaking Machine' that used an elaborate series of bellows, reeds, whistles and resonant chambers to produce rudimentary words.&quot;  Excellent overview.
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://news.zdnet.co.uk/software/0,1000000121,39274587,00.htm' rel='nofollow'>Talking PCs? Talk to the hand</a>. By Nick Hampshire. ZDNet UK (June 12, 2006). &quot;Voice recognition and speech synthesis technologies may not have developed to the degree some science fiction writers hoped, but have nevertheless seen some startling successes. ... Voice synthesis has been around for a long time. Bell Labs demonstrated a computer-based speech synthesis system running on an IBM704 in 1961, a demonstration seen by the author Arthur C. Clarke, giving him the inspiration for the talking computer HAL9000 in his book and film '2001: A Space Odyssey'. Forty-five years later, voice synthesis technology can be found in products as diverse as talking dolls, car information systems and various text-to-speech conversion services such as the one recently launched by BT. Many of these modern systems can convert text into a computer synthesised voice of quite respectable quality. ... Voice recognition has turned out to be a much harder task than researchers realised when work began on the problem over forty years ago. However, limited voice recognition applications are starting to creep into everyday use, voice input telephone menu systems are now commonplace, speech-to-text dictaphones are increasingly used for note-taking by doctors and lawyers, and voice input has started to appear in computer games systems. The success of some of these limited-application voice recognition systems has recently prompted the big software heavyweights, Microsoft and IBM, to make further investments. ... However, there are still a lot of technological hurdles to overcome; to understand what these are, we need to delve further into the technology. ... <em>Speech recognition</em> - Speech recognition, on the other hand, is a much harder task, and commercial off-the-shelf systems have only been available since the 1990s. Because every person's voice is different, and words can be spoken in a range of different nuances, tones and emotions, the computational task of successfully recognising spoken words is considerable, and has been the subject of many years of continuing research work around the world. A variety of different approaches are used, dynamic algorithms, neural networks, and knowledge bases, with the most widely used underlying technology being the Hidden Markov Model. These techniques all attempt to search for the most likely word sequence given the fact that the acoustic signal will also contain a lot of background noise.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.economist.com/science/tq/displaystory.cfm?story_id=9249338' rel='nofollow'>Are you talking to me?</a> Speech recognition: Technology that understands human speech could be about to enter the mainstream. The Economist Technology Quarterly (June 7, 2007). &quot;Speech recognition has taken a long time to move from the laboratory to the marketplace. Researchers at Bell Labs first developed a system that recognised numbers spoken over a telephone in 1952, but in the ensuing decades the technology has generally offered more promise than product, more science fiction than function. ... Optimistic forecasts from market-research firms also suggest that the technology is on the rise. ... An area of great interest at the moment is in that of voice-driven 'mobile search' technology, in which search terms are spoken into a mobile device rather than typed in using a tiny keyboard. ... The resulting lower cost and greater reliability mean that speech-based systems can even save companies money. Last August, for example, Lloyds TSB, a British bank, switched all of its 70m annual incoming calls over to a speech-recognition system based on technology from Nuance and Nortel, a Canadian telecoms-equipment firm. ... Another promising area is in-car use. ... There are military uses, too. ...&quot; 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.acm.org/crossroads/xrds13-4/' rel='nofollow'>Computer Vision and Speech</a>. Crossroads, The ACM Student Magazine. Fall 2007; Issue 13.4. As stated in the <a target='_blank'  class='urllink' href='http://www.acm.org/crossroads/xrds13-4/intro.html' rel='nofollow'>Introduction</a>, by Niels Ole Bernsen: &quot;If you are interested in computers with human capabilities, vision and speech open an entirely new world of computers that can see and talk like we do. Computer vision is the moody input cousin of computer graphics-in graphics, you have all the time you can afford to program the rendering, but visual input is an unpredictable and messy reality. Computer speech is both input and output, like in systems capable of spoken dialogue. Viewed as enabling technologies, computer speech arguably holds the lead over computer vision. Even though a speech signal is enormously rich in information and we are still far from mastering important aspects of it like online recognition and generation of speech prosody, it is still much easier to shut up the people in a room in order to get a clear speech signal than it is to control the room's lighting conditions and to identify and track all of its 3-D contents independently of the viewing angle. Given the state of the art, it makes good sense that the papers in this issue of Crossroads are about speech or vision. Two articles address different stages of the process of making computers understand what is commonly called the speaker's communicative intention, i.e., what the speaker really wishes to say by uttering a sequence of words. Deepti Singh and Frank Boland [<a target='_blank'  class='urllink' href='http://www.acm.org/crossroads/xrds13-4/voice_detection.html' rel='nofollow'>Voice Activity Detection</a>] discuss approaches to the important pre-(speech)-recognition problem of detecting if and when the acoustic signal includes speech in the first place. ... Nitin Madnani's introduction [<a target='_blank'  class='urllink' href='http://www.acm.org/crossroads/xrds13-4/natural_language.html' rel='nofollow'>Getting Started on Natural Language Processing with Python</a>] to natural language processing, or NLP, is likely to tempt computer scientists to try out NLP for themselves.&quot;
</p><ul><li>Also be sure to see: <a target='_blank'  class='urllink' href='http://www.acm.org/crossroads/xrds13-4/jennifer_lai.html' rel='nofollow'>Superhuman Speech by 2010: An Interview with Jennifer Lai</a>. By Paula Bach. Crossroads, The ACM Student Magazine. Fall 2007; Issue 13.4. &quot;At IBM Research, Jennifer Lai has been a key player in speech technology research, holding thirteen patents, publishing chapters for several books, and having over thirty papers appear in peer-reviewed journals and conferences. Jennifer took time out of her busy schedule to answer some questions about speech technologies for Crossroads. In the interview, Jennifer shares her expertise on designing speech interfaces, her history at IBM, and advice for undergraduate and graduate students who are interested in working with speech technologies.&quot;
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.trnmag.com/Stories/2005/032305/Common_sense_boosts_speech_software_032305.html' rel='nofollow'>Common sense boosts speech software</a>. By Eric Smalley. Technology Research News (March 23 / 30, 2005). &quot;Speech recognition software matches strings of phonemes -- the sounds that make up words -- to words in a vocabulary database. The software finds close matches and presents the best one. The software does not understand word meaning, however. This makes it difficult to distinguish among words that sound the same or similar. The Open Mind Common Sense Project database contains more than 700,000 facts that MIT Media Lab researchers have been collecting from the public since the fall of 2000. These are based on common sense like the knowledge that a dog is a type of pet rather than the knowledge that a dog is a type of mammal. The researchers used the phrase database to reorder the close matches returned by speech recognition software. ... 'One surprising thing about testing interfaces like this is that sometimes, even if they don't get the absolutely correct answer, users like them a lot better,' said [Henry] Lieberman. 'This is because they make plausible mistakes, for example 'tennis clay court' for 'tennis player', rather than completely arbitrary mistakes that a statistical recognizer might make, for example 'tennis slayer',' he said. &quot;
</p>
<div class='vspace'></div><ul><li><a name='lieberman' id='lieberman'></a>Also noted in the article is the related technical paper: "How to Wreck a Nice Beach You Sing Calm Incense," Intelligent User Interfaces Conference (IUI 2005), San Diego, January 9-12, 2005.  
<ul><li>If you'd like to learn more about &quot;<em>wreck a nice beach</em>,&quot; the classic acoustic ambiguity, see this <a href='#whenwill'>article</a> below. 
</li></ul></li></ul><p class='vspace'><a name='sls' id='sls'></a>
<a target='_blank'  class='urllink' href='http://groups.csail.mit.edu/sls//sls-blue-noflash.shtml' rel='nofollow'>Spoken Language Systems Group</a>, MIT Computer Science and Artificial Intelligence Laboratory.  
</p>
<div class='vspace'></div><ul><li><a target='_blank'  class='urllink' href='http://groups.csail.mit.edu/sls//about/' rel='nofollow'>About SLS</a>: &quot;User: <em>Yes, I would like the weather forecast for London, England, please</em>. JUPITER: <em>In London in England Wednesday, partly cloudy skies with periods of sunshine. High 82 and low 63. Is there something else?</em> ... SLS researchers make this kind of dialogue look easy by empowering the computer to perform five main functions in real time: speech recognition-- converting the user's speech to a text sentence of distinct words, language understanding -- breaking down the recognized sentence grammatically, and systematically representing its meaning, information retrieval -- obtaining targeted data, based on that meaning representation, from the appropriate online source, language generation -- building a text sentence that presents the retrieved data in the user's preferred language, and speech synthesis -- converting that text sentence into computer-generated speech. Throughout the conversation, the computer also remembers previous exchanges.&quot;
</li><li><a target='_blank'  class='urllink' href='http://groups.csail.mit.edu/sls//research/' rel='nofollow'>Core Technology Development</a>: &quot;To support its research on spoken language systems for human/computer interaction, the SLS group has developed its own suite of core speech technologies. These technologies include: * speech recognition (SUMMIT) * natural language understanding (TINA) * dialogue modeling * language generation (GENESIS) * speech synthesis (ENVOICE).&quot;
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.trnmag.com/Stories/2005/011205/Conversations_control_computers_011205.html' rel='nofollow'>Conversations control computers</a>. By Eric Smalley. Technology Research News (January 12/19, 2005). &quot;Because information from spoken conversations is fleeting, people tend to record schedules and assignments as they discuss them. Entering notes into a computer, however, can be tedious -- especially when the act interrupts a conversation. Researchers from the Georgia Institute of Technology are aiming to decrease day-to-day data entry and to augment users' memories with a method that allows handheld computers to harvest keywords from conversations and make use of relevant information without interrupting the personal interactions. ... The researchers' system protects privacy by only using speech from the user's side of the conversation, said [Kent] Lyons.&quot; 
</p>
<div class='vspace'></div><ul><li>After reading the article, you might want to visit the <a target='_blank'  class='urllink' href='http://www.cc.gatech.edu/ccg/projects/conversation/' rel='nofollow'>project web site</a>.
</li></ul><p class='vspace'><span  style='color: #ff00ff;'><em>Listen</em></span> to Wade Roush's <a target='_blank'  class='urllink' href='http://www.technologyreview.com/TR35/media/parissmaragdis.mp3' rel='nofollow'>podcast</a> profile of Paris Smaragdis and his work. From <a target='_blank'  class='urllink' href='http://www.technologyreview.com/TR35/' rel='nofollow'>2006 Young Innovators Under 35</a>. Technology Review (September 8, 2006). &quot;Since 1999, the editors of Technology Review have honored the young innovators whose inventions and research we find most exciting; today that collection is the TR35, a list of technologists and scientists, all under the age of 35. Their work --spanning medicine, computing, communications, electronics, nanotechnology, and more -- is changing our world. ... <a target='_blank'  class='urllink' href='http://www.technologyreview.com/TR35/Profile.aspx?Cand=T&amp;TRID=428' rel='nofollow'>Paris Smaragdis</a>, 32, Mitsubishi Electric Research Lab. Computer scientist Paris Smaragdis is building some of the world's most advanced 'machine listening' systems -- software that uses sound to locate people moving through rooms, monitor machinery for impending breakdowns, or activate traffic cameras to record accidents.&quot;
</p>
<div class='vspace'></div><ul><li>Also <em>see</em> this <span  style='color: #ff00ff;'>video clip</span>: <a target='_blank'  class='urllink' href='http://www.technologyreview.com/blog/VideoPosts.aspx?id=17438' rel='nofollow'>Computer scientist Paris Smaragdis on "machine listening."</a> Technology Review (October 11, 2006). &quot;As a music student in college, Paris Smaragdis taught computers how to play more life-like music. Today, the 2006 TR35 winner teaches them how to listen better. We recently talked with him about how--and why--he made that transition. For Smaragdis, machine listening could provide solutions to all sorts of unexpected problems, from security and building engineering to accident investigation.&quot;
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.research.ibm.com/tts/' rel='nofollow'>IBM's Interactive U.S. English Demo</a>: &quot;This demonstration of our work in unconstrained text-to-speech research allows users to submit text to be synthesized into speech.&quot; 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.cfo.com/article.cfm/3515798/c_3516777?f=magazine_alsoinside' rel='nofollow'>Ernestine, Meet Julie</a> - Natural language speech recognition is markedly improving voice-activated self-service. By Karen Bannan. CFO Magazine (January 1, 2005). &quot;A new technology, called natural language speech recognition, is markedly improving voice-activated self-service. Powered by artificial intelligence, these speech-recognition systems are altering consumer perceptions about phone self-service, as calls for help no longer elicit calls for help. That, in turn, is spurring renewed corporate interest in the concept of phone self-service. In 2004, sales of voice self-service systems topped $1.2 billion. 'We've seen voice systems move from emerging technology to applied technology over the last few years,' says Steve Cramoysan, principal analyst at Stamford, Connecticut-based research firm Gartner. 'It's still fairly immature. But it's proven and moving toward the mainstream.'"
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.gcn.com/vol1_no1/daily-updates/26338-1.html' rel='nofollow'>The Futurist - The Intelligent Internet</a>. The Promise of Smart Computers and E-Commerce. By William E. Halal. Government Computer News Daily News (June 23, 2004). &quot;Scientific advances are making it possible for people to talk to smart computers, while more enterprises are exploiting the commercial potential of the Internet. ... [F]orecasts conducted under the TechCast Project at George Washington University indicate that 20 commercial aspects of Internet use should reach 30% 'take-off' adoption levels during the second half of this decade to rejuvenate the economy. Meanwhile, the project's technology scanning finds that advances in speech recognition, artificial intelligence, powerful computers, virtual environments, and flat wall monitors are producing a 'conversational' human-machine interface. These powerful trends will drive the next generation of information technology into the mainstream by about 2010. ... The following are a few of the advances in speech recognition, artificial intelligence, powerful chips, virtual environments, and flat-screen wall monitors that are likely to produce this intelligent interface. ... IBM has a Super Human Speech Recognition Program to greatly improve accuracy, and in the next decade Microsoft's program is expected to reduce the error rate of speech recognition, matching human capabilities. ... MIT is planning to demonstrate their Project Oxygen, which features a voice-machine interface. ... Amtrak, Wells Fargo, Land's End, and many other organizations are replacing keypad-menu call centers with speech-recognition systems because they improve customer service and recover investment in a year or two. ... General Motors OnStar driver assistance system relies primarily on voice commands, with live staff for backup; the number of subscribers has grown from 200,000 to 2 million and is expected to increase by 1 million per year. The Lexus DVD Navigation System responds to over 100 commands and guides the driver with voice and visual directions.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.theatlantic.com/issues/2000/12/fallows.htm' rel='nofollow'>From Your Lips to Your Printer</a>. By James Fallows. The Atlantic (December 2000). &quot;First, the computer captures the sound waves the speaker generates, tries to filter them from coughs, hmmmms, and meaningless background noise, and looks for the best match with the phonemes available. (A phoneme is the basic unit of the spoken word.)&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.cs.colorado.edu/~martin/slp.html' rel='nofollow'>Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition</a>. By Daniel Jurafsky and James H. Martin. Prentice-Hall, 2000. Both the Preface and Chapter 1 are available online as are the resources for all of the chapters.
</p>
<p class='vspace'><a name='faq' id='faq'></a><a target='_blank'  class='urllink' href='http://www.speech.cs.cmu.edu/comp.speech/' rel='nofollow'>FAQs</a>. 
Topics covered include: general information, signal processing, speech coding and compression, natural language processing, speech synthesis, and speech recognition. 
</p>
<div class='vspace'></div><ul><li>Don't miss &quot;<a target='_blank'  class='urllink' href='http://www.speech.cs.cmu.edu/comp.speech/SpeechLinks.html' rel='nofollow'>the list of all the hyperlinks</a> from the comp.speech FAQ. This is probably the biggest list of speech technology links available. The links are provided to WWW references, ftp sites, and newsgroups. Cross-references to the comp.speech WWW pages are also provided.&quot; 
</li></ul><p class='vspace'>The online version of <a target='_blank'  class='urllink' href='http://mitpress.mit.edu/e-books/Hal/index.html' rel='nofollow'>Hal's Legacy: 2001's Computer as Dream and Reality</a>. Edited by David G. Stork.
</p>
<div class='vspace'></div><ul><li><a target='_blank'  class='urllink' href='http://mitpress.mit.edu/e-books/Hal/chap6/six1.html' rel='nofollow'>The Talking Computer: Text to Speech Synthesis.</a> By Joseph S. Olive. Be sure to check out the Further Reading and Exploration links.
</li><li><a name='whenwill' id='whenwill'></a><a target='_blank'  class='urllink' href='http://mitpress.mit.edu/e-books/Hal/chap7/seven1.html' rel='nofollow'>When Will HAL Understand What We Are Saying? Computer Speech Recognition and Understanding.</a> By Raymond Kurzweil. "[Bell's] insights into separating the speech signal into different frequency components and rendering those components as visible traces were not successfully implemented until Potter, Kopp, and Green designed the spectrogram and Dreyfus-Graf developed the steno-sonograph in the late 1940s. These devices generated interest in the possibility of automatically recognizing speech because they made the invariant features of speech visible for all to see." The quotation can be found on page 8. 
<ul><li><a name='beach' id='beach'></a>This article also explores the classic example of acoustic ambiguity: &quot;recognize speech / wreck a nice beach&quot; 
<ul><li>Also see <a href='#lieberman'>How to Wreck a Nice Beach You Sing Calm Incense.</a>
</li></ul></li></ul></li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://cslu.cse.ogi.edu/tutordemos/nnet_recog/recog.html' rel='nofollow'>Speech Recognition Using Neural Networks</a>. By John-Paul Hosom, Ron Cole, and Mark Fanty at the Center for Spoken Language Understanding, Oregon Graduate Institute of Science and Technology. &quot;There are four basic steps to performing recognition. ... First, we digitize the speech that we want to recognize; for telephone speech the sampling rate is 8000 samples per second. Second, we compute features that represent the spectral-domain content of the speech (regions of strong energy at particular frequencies). ... Third, a neural network (also called an ANN, multi-layer perceptron, or MLP) is used to classify a set of these features into phonetic-based categories at each frame. Fourth, a Viterbi search is used to match the neural-network output scores to the target words (the words that are assumed to be in the input speech), in order to determine the word that was most likely uttered.&quot; This tutorial also includes several diagrams that clarify the many of the concepts.   
</p>
<div class='vspace'></div><ul><li>Also see their response to the question &quot;<a target='_blank'  class='urllink' href='http://cslu.cse.ogi.edu/asr/#ASR' rel='nofollow'>What is Automatic Speech Recognition</a>?&quot; in which you'll be introduced to the Hidden Markov Model ... and then scroll down the page to learn about their current projects.
</li></ul><p class='vspace'>Experts Use AI to Help GIs Learn Arabic. By Eric Mankin. USC News (June 21, 2004). &quot; To teach soldiers basic Arabic quickly, USC computer scientists are developing a system that merges artificial intelligence with computer game techniques. The Rapid Tactical Language Training System, created by the USC Viterbi School of Engineering's Center for Research in Technology for Education (CARTE) and partners, tests soldier students with videogame missions in animated virtual environments where, to pass, the students must successfully phrase questions and understand answers in Arabic.&quot; <a target='_blank'  class='urllink' href='http://www.usc.edu/uscnews/story.php?id=10321' rel='nofollow'>Read the story</a> and then <a target='_blank'  class='urllink' href='http://www.isi.edu/~jmoore/Mankin/MankinTLWeb.mov' rel='nofollow'><strong>watch the video</strong></a><strong>!</strong>
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://acmqueue.com/modules.php?name=Queuecasts' rel='nofollow'>ACM Queuecasts</a>. <em>Listen</em> to discussions such as:
</p>
<div class='vspace'></div><ul><li>Can You Hear Me Now? &quot;In an interview with ACM Queuecast host Mike Vizard, Roberto Sicconi, manager for mobile conversational computing at IBM, explains how and why speech technologies will become a standard element of most mainstream applications.&quot;
</li><li>Google Talk. &quot;Although Google remains relatively mum about its ambitions in the area of speech recognition, Mike Cohen, head of the company's efforts in this area and a co-founder of Nuance Communications, says that speech recognition will increasingly play a bigger role in all Web-based applications going forward.&quot;
</li></ul><p class='vspace'><a name='readon' id='readon'></a>
</p>
<table ><tr><td width='200'  valign='top'>
<h2 class='backgrnd5'><span class='text1'>General Readings</span></h2>
</td></tr></table>
<p class='vspace'><a target='_blank'  class='urllink' href='http://ocw.mit.edu/OcwWeb/Electrical-Engineering-and-Computer-Science/6-345Automatic-Speech-RecognitionSpring2003/CourseHome/index.htm' rel='nofollow'>Automatic Speech Recognition, Spring 2003</a>. Staff Instructors: Dr. James Glass and Professor Victor Zue. Available from MIT OpenCourseWare. &quot;6.345 is a course in the department's 'Bioelectrical Engineering' concentration. This course offers a full set of lecture slides with accompanying speech samples, as well as homework assignments and other materials used in the course. 6.345 introduces students to the rapidly developing field of automatic speech recognition. Its content is divided into three parts. Part I deals with background material in the acoustic theory of speech production, acoustic-phonetics, and signal representation. Part II describes algorithmic aspects of speech recognition systems including pattern classification, search algorithms, stochastic modelling, and language modelling techniques. Part III compares and contrasts the various approaches to speech recognition, and describes advanced techniques used for acoustic-phonetic modelling, robust speech recognition, speaker adaptation, processing paralinguistic information, speech understanding, and multimodal processing.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://online.wsj.com/public/article/SB116839144214572104-6WxRYddk_9n95lxrqvESQgmhfDo_20080110.html' rel='nofollow'>After Years of Effort, Voice Recognition Is Starting to Work</a>. By Lee Gomes. The Wall Street Journal (January 10, 2007: page B1). &quot;So maybe you won't be talking to your car anytime soon, the way Microsoft and Ford would like you to be. Odds are, though, that you are already on speaking terms with silicon, probably more than you realize. And you can expect to be chatting it up more and more. Almost since computers were invented, computer scientists have been working to get the machines to understand what people are saying to them. Until the past few years, they hadn't been successful enough to offer anything but lab demos. Now, though, computer speech recognition is sufficiently advanced that it is showing up in a surprising variety of places. Like automobiles. ... While voice-controlled computers are sci-fi staples, in practice most people find a keyboard and a mouse are fine for telling a PC what to do. Bill Meisel, a veteran observer of the speech-recognition market, says the main use of speech recognition at the moment is in specialized applications like law and medicine. Radiologists, for example, are increasingly dictating their diagnoses and observations into a speech-recognition program rather than into a tape recorder that must later be transcribed. At its core, speech recognition takes advantage of extraordinarily complex statistical methods to match the sounds you say with the right words. ... One of the biggest applications of the technology is in call centers. ... David Nahamoo, who oversees IBM's speech research, says that some other new applications are already at hand. One is a system that produces automatic translations of foreign-language broadcasts, such as those in Arabic, first by performing speech recognition of the spoken words and then by using translation software to render things in English.&quot; 
</p>
<div class='vspace'></div><ul><li>Visit <a target='_blank'  class='urllink' href='http://www.nue.org/~okuno/' rel='nofollow'>Hiroshi G. Okuno's homepage</a>. 
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.cs.colorado.edu/~martin/slp.html' rel='nofollow'>Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition</a>. By Daniel Jurafsky and James H. Martin. Prentice-Hall, 2000. The Preface and Chapter 1 are available online. 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://researchweb.watson.ibm.com/thinkresearch/pages/2001/20010629_ai.shtml' rel='nofollow'>IBM gets smart about Artificial Intelligence</a>. By Pamela Kramer. <a target='_blank'  class='urllink' href='http://researchweb.watson.ibm.com/thinkresearch/index.shtml' rel='nofollow'>IBM Think Research</a> (June 2001). &quot;Computer vision is important to speech recognition, too. Visual cues help computers decipher speech sounds that are obscured by environmental noise. Chalapathy Neti, manager of IBM's audiovisual speech technologies (AVST) group at Watson, often cites HAL's lip-reading ability in 2001 in promoting the group's work.&quot;
</p>
<div class='vspace'></div><ul><li>Also see: <a target='_blank'  class='urllink' href='http://www.research.ibm.com/thinkresearch/pages/2002/20020918_speech.shtml' rel='nofollow'>You just don't understand!</a> IBM's Superhuman Speech initiative clears conversational confusion. By Sam Howard-Spink. IBM Think Research. (September 2002). &quot;It's a vision of the future that's been promised for decades — humans and machines interacting with each other by voice.&quot;
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://tamworth.yourguide.com.au/detail.asp?class=news&amp;subclass=local&amp;category=general%20news&amp;story_id=314358&amp;y=2004&amp;m=6' rel='nofollow'>Men all ears as health technology gets hearing</a>. The Northern Daily Leader &amp; tamworth.yourguide (June 16, 2004). &quot;A revolutionary hearing aid was just one of a number of new technological exhibits on show at the Men's Health Expo in Tamworth yesterday to coincide with Men's Health Week. The hearing aid allows the person wearing it to focus on a specific conversation more clearly while drowning out any other noises in the room. It has been designed to select the best speech over noise using parallel processing through a new concept called syncro. ... Spokesman James Battersby for Oticon, which manufactures the hearing aid, said ... 'It's design has been created by using artificial intelligence and allows the wearer to cancel out up to four different noises simultaneously.'&quot;
</p>
<div class='vspace'></div><ul><li>Also see: <a target='_blank'  class='urllink' href='http://www.audiologyonline.com/articles/arc_disp.asp?id=733' rel='nofollow'>Artificial Intelligence - The New Advanced Technology in Hearing Aids</a>. By Donald J. Schum. Audiology Online (June 7, 2004). &quot;The core benefit of using Artificial Intelligence in hearing aids is to handle the complexity of real situations, in real time, via rule-based, confirmed solutions -- not just predictions in isolation.&quot;
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.sciencemag.org/cgi/content/summary/301/5639/1494' rel='nofollow'>The Power of Speech</a>. By Lawrence Rabiner, Center for Advanced Information Processing, Rutgers University. Science (September 12, 2003; Volume 301, Number 5639: 1494-1495). &quot;In the multimedia world of future communications, speech will play an increasingly important role. From speaker verification to automatic speech recognition and the understanding of key phrases by computers, the spoken word will replace keyboards and pointing devices like the mouse. In his Perspective, Rabiner discusses recent advances and remaining challenges in the processing of speech by communication devices. The key challenge is to make the user interface for 21st-century services and devices as easy to learn and use as a telephone is today for voice conversations.&quot;
</p>
<div class='vspace'></div><ul><li>Also see: <a target='_blank'  class='urllink' href='http://www.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/tutorial%20on%20hmm%20and%20applications.pdf' rel='nofollow'>A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition</a>. By Lawrence Rabiner. Proceedings of the IEEE, 77(2): 257-286 (February 1989).
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.technologyreview.com/articles/03/06/roush0603.asp?p=1' rel='nofollow'>Computers That Speak Your Language</a>. By Wade Roush. Technology Review (June 2003). 
</p>
<p class='vspace'><a class='urllink' href='http://www.aaai.org/ojs/index.php/aimagazine/article/view/1319/1220' rel='nofollow'>Linguistic Knowledge and Empirical Methods in Speech Recognition</a>. By Andreas Stolcke. (1997). AI Magazine 18 (4): 25-32.
</p>
<p class='vspace'><a name='vid' id='vid'></a>
<strong>Related Videos</strong> from the <a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/VideoTags/Speech'>AAAI Video Archive : Speech</a>
</p>
<div class='vspace'></div><ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AIVideos/2007-0002'>"Hear Here" is about speech recognition</a>. Raj Reddy, et al. 1969.
</li></ul><p class='vspace'><a name='web' id='web'></a>
</p>
<table ><tr><td width='200'  valign='top'>
<h2 class='backgrnd5'><span class='text1'>Related Resources</span></h2>
</td></tr></table>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.cstr.ed.ac.uk/' rel='nofollow'>The Centre for Speech Technology Research at the University of Edinburgh</a> [CSTR]: &quot;Founded in 1984, CSTR is concerned with research in all areas of speech technology including speech recognition, speech synthesis, speech signal processing, information access, multimodal interfaces and dialogue systems. We have many collaborations with the wider community of researchers in language, cognition and machine learning for which Edinburgh is renowned.&quot; Be sure to see their collection of <a target='_blank'  class='urllink' href='http://www.cstr.ed.ac.uk/research/projects/' rel='nofollow'>current research projects</a> .
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.icsi.berkeley.edu/Speech/mr/' rel='nofollow'>The Meeting Recorder Project at ICSI</a> [The International Computer Science Institute]. &quot;Despite recent advances in speech recognition technology, successful recognition is limited to co-operative speakers using close-talking microphones. There are, however, many other situations in which speech recognition would be useful - for instance to provide transcripts of meetings or other archive audio. Speech researchers at ICSI, UW, SRI, and IBM are very interested in new application domains of this kind, and we have begun to work with recorded meeting data.&quot; - from the <a target='_blank'  class='urllink' href='http://www.icsi.berkeley.edu/Speech/mr/mtgrcdr.html' rel='nofollow'>Introduction</a>
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.asel.udel.edu/speech/ModelTalker.html' rel='nofollow'>ModelTalker</a>. From the <a target='_blank'  class='urllink' href='http://www.asel.udel.edu/speech/' rel='nofollow'>Speech Research Laboratory</a>, duPont Hospital for Children and University of Delaware. Not only can you pick a voice for the demo, but you can also pick an emotion! 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.novaspeech.com/company.htm' rel='nofollow'>NovaSpeech</a>: &quot;developing next-generation speech technologies and related educational materials. ... Our  research and development projects build on our team's extensive experience and expertise in multi-language and multi-voice speech synthesis, speech perception, linguistics, digital signal processing, acoustic phonetics, software development, and speech product development and marketing.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.acoustics.salford.ac.uk/research/arc_cox_ann.htm' rel='nofollow'>Quantifying Room Acoustic Quality Using Artificial Neural Networks Project</a>. Salford Acoustics Audio and Video at the University of Salford. &quot;This project was concerned with spaces where good acoustics are required for speech. Such spaces include shopping malls and railway stations where announcements need to be intelligible, and theatres where the quality of sound plays a crucial role in the enjoyment of a performance. The project researched a novel measurement technique intended to increase understanding of acoustics by enabling in-use, non-invasive evaluation of room acoustics to be made. ... The measurement system proposed derives the acoustic quality from a speech signal as received by a microphone in a room. Neural networks learn how to extract the determining characteristics from the speech signals that lead to the objective parameters. In this way, the neural networks predict the reverberation time, early decay time, STI (Speech Transmission Index) and RASTI (RApid Speech Transmission Index). In addition to enabling occupied measurements, the development of the neural network sensing system is of academic interest, as it is forming an artificial intelligence system to mimic the behaviour of human perception.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.speech.cs.cmu.edu/speech/' rel='nofollow'>Speech at CMU Web Page</a>. An extensive collection of speech resources from Carnegie Mellon University with links to many exciting projects (both at CMU and around the world).
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.cs.indiana.edu/rhythmsp/ASA/Contents.html' rel='nofollow'>Dennis Klatt's History of Speech Synthesis</a>. &quot;Audio clips of synthetic speech illustrating the history of the art and technology of synthetically produced human speech.&quot; 
</p>
<p class='vspace'><a name='more' id='more'></a>
</p><h2>Other References Offline</h2>
<p class='vspace'>Aaron, A., Eide, E., and Pitrelli, J.F.,  <a class='urllink' href='http://www.sciamdigital.com/index.cfm?fa=Products.ViewIssuePreview&amp;ARTICLEID_CHAR=B3AC0451-2B35-221B-6AE11FCB78B8C698' rel='nofollow'>Conversational Computers.</a>  Scientific American, v. 292, no. 6, June, 2005, pp. 64-69.  (subscription req'd) .    &quot;Call a large company these days, and you will probably start by having a conversation with a computer. Until recently, such automated telephone speech systems could string together only prerecorded phrases. ... Computer-generated speech has improved during the past decade, becoming significantly more intelligible and easier to listen to. But researchers now face a more formidable challenge: making synthesized speech closer to that of real humans--by giving it the ability to modulate tone and expression, for example--so that it can better communicate meaning. This elusive goal requires a deep understanding of the components of speech and of the subtle effects of a person's volume, pitch, timing and emphasis. That is the aim of our research group at IBM and those of other U.S. companies, such as AT&amp;T, Nuance, Cepstral and ScanSoft, as well as investigators at institutions including Carnegie Mellon University, the University of California at Los Angeles, the Massachusetts Institute of Technology and the Oregon Graduate Institute.&quot;
</p>
<p class='vspace'><a name='hearsay' id='hearsay'></a>Erman, Lee D. and Frederick Hayes-Roth, Victor R. Lesser, D. Raj Reddy. 1980. <a target='_blank'  class='urllink' href='http://portal.acm.org/citation.cfm?doid=356810.356816' rel='nofollow'>The Hearsay-II Speech-Understanding System: Integrating Knowledge to Resolve Uncertainty</a>. ACM Computing Surveys 12(2): 213 - 253. &quot;The Hearsay-II speech-understanding system ... recognizes connected speech in a 1000-word vocabulary with correct interpretations for 90 percent of test sentences. Its basic methodology involves the application of symbolic reasoning as an aid to signal processing. A marriage of general artificial intelligence techniques with special acoustic and linguistic knowledge was needed to accomplish satisfactory speech-understanding performance.&quot; 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.nap.edu/readingroom/books/far/ch9.html' rel='nofollow'>Developments in Artificial Intelligence</a>, Chapter 9 of <a target='_blank'  class='urllink' href='http://www.nap.edu/readingroom/books/far/notice.html' rel='nofollow'>Funding a Revolution: Government Support for Computing Research</a>. Committee on Innovations in Computing and Communications: Lessons from History, Computer Science and Telecommunications Board, Commission on Physical Sciences, Mathematics, and Applications, National Research Council. Washington, D.C.: National Academy Press, 1999. &quot;SUCCESS IN SPEECH RECOGNITION
</p>
<p class='vspace'>- The history of speech recognition systems illustrates several themes common to AI research more generally: the long time periods between the initial research and development of successful products, and the interactions between AI researchers and the broader community of researchers in machine intelligence. Many capabilities of today's speech-recognition systems derive from the early work of statisticians, electrical engineers, information theorists, and pattern-recognition researchers. Another key theme is the complementary nature of government and industry funding. Industry supported work in speech recognition at least as far back as the 1950s, when researchers at Bell Laboratories worked on systems for recognizing individual spoken digits 'zero' through 'nine.'&quot;
</p>
<div class='vspace'></div><div class='tags'>Tags: <a href="?action=tags&amp;tag=speech">speech</a> <a href="?action=tags&amp;tag=speechrecognition">SpeechRecognition</a> <a href="?action=tags&amp;tag=speechunderstanding">SpeechUnderstanding</a> </div>
<div class='vspace'></div>
</div>

      </td>
    </tr></table>
	</div>

<!--PageFooterFmt-->
  <div id='wikifoot' class='backgrnd11'>
    <div class='footnav'>
			<a href='http://www.aaai.org/'>AAAI Home</a>&nbsp;&nbsp;
			<a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/RecentChanges' accesskey='c'>Recent Changes</a></span>&nbsp;&nbsp;
			<a rel="nofollow" href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Speech?action=edit'>Edit</a>&nbsp;&nbsp;
      <a rel="nofollow" href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Speech?action=diff'>History</a>&nbsp;&nbsp;
      <a rel="nofollow" href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Speech?action=print' target='_blank'>Print</a>&nbsp;&nbsp;
<!--      <a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/RecentChanges'>Recent Changes</a>&nbsp;&nbsp;
      <a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Site/Search'>Search</a> - -->
			<a href='mailto:videos08@aaai.org?subject=AI Topics Contact'>Contact Us</a></div>
    <div class='lastmod'>Page last modified on December 13, 2008, at 03:45 PM</div></div>
<!--HTMLFooter-->
</body>
</html>

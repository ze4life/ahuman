<!DOCTYPE html 
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
  <title>AITopics / Philosophy </title>
<!--  <title>AI Topics / AI Videos | AITopics / Philosophy </title> -->
  <meta http-equiv='Content-Style-Type' content='text/css' />
<!--HTMLHeader--><style type='text/css'><!--
  ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }
  code.escaped { white-space: nowrap; }
  .vspace { margin-top:1.33em; }
  .indent { margin-left:40px; }
  .outdent { margin-left:40px; text-indent:-40px; }
  a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }
  a.createlink { text-decoration:none; position:relative; top:-0.5em;
    font-weight:bold; font-size:smaller; border-bottom:none; }
  img { border:0px; }
  .editconflict { color:green; 
  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }

  table.markup { border:2px dotted #ccf; width:90%; }
  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }
  table.vert td.markup1 { border-bottom:1px solid #ccf; }
  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }
  table.markup caption { text-align:left; }
  div.faq p, div.faq pre { margin-left:2em; }
  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }
  div.faqtoc div.faq * { display:none; }
  div.faqtoc div.faq p.question 
    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }
  div.faqtoc div.faq p.question * { display:inline; }
   
    .frame 
      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }
    .lfloat { float:left; margin-right:0.5em; }
    .rfloat { float:right; margin-left:0.5em; }
a.varlink { text-decoration:none; }

--></style>  <meta name='robots' content='index,follow' />

  <link rel='stylesheet' href='http://www.aaai.org/AITopics/pmwiki/pub/skins/aaaiblue/aaaiblue.css' type='text/css' />
  <style type="text/css">
  <!--
	@import url("http://www.aaai.org/AITopics/pmwiki/pub/skins/aaaiblue/layout.css");
	-->
  </style>
	<script src="http://www.aaai.org/AITopics/pmwiki/track.js" type="text/JavaScript"></script>
</head>
<body class="backgrnd2" onLoad="addLinkerEvents()">
<!--PageHeaderFmt-->
	<div id="header" class="backgrnd1">
		<div id='wikihead'>
			<form action='http://www.aaai.org/AITopics/pmwiki/pmwiki.php' id="cse-search-box">
				<input type='hidden' name='n' value='AITopics.Philosophy' />
				<input type='hidden' name='action' value='search' />
				<!--    <a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Site/Search'>Search</a>: -->
				<input type='text' name='q' value='' size="25" class='inputbox searchbox' />
				<!-- Include Google Search parameters --> 
				<input type="hidden" name="cof" value="FORID:11" /><input type='submit' name="sa" class='inputbutton searchbutton' value='Search AI Topics' />
				<input type="hidden" name="cx" value="005943697473805803765:wzeb22stvpm" />
			</form>
			<script type="text/javascript">(function() {
var f = document.getElementById('cse-search-box');
if (!f) {
f = document.getElementById('searchbox_demo');
}
if (f && f.q) {
var q = f.q;
var n = navigator;
var l = location;
if (n.platform == 'Win32') {
q.style.cssText = 'border: 1px solid #7e9db9; padding: 2px;';
}
var b = function() {

};
var f = function() {
//q.style.background = '#ffffff';
};
//q.onfocus = f;
//q.onblur = b;
if (!/[&?]q=[^&]/.test(l.search)) {
b();
}
}
})();
</script>
		</div>
		
		<div id='wikilogo'><a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php'><img src='http://www.aaai.org/AITopics/pmwiki/pub/images/aaai-logo-t7.png' alt='AI Topics / AI Videos' border='0' /></a>	
		</div>
	</div>
<!--/PageHeaderFmt-->
	
	<div id="menu" class="backgrnd3">
		<ul>
			<li class="first"><a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics' accesskey="1" class="link1">AITopics</a></li>
			<li class="link2" style="padding-left:0px; padding-right:0px; font-size: 15px">/</li>
			<li class="link2" style="font-size: 15px;">Philosophy</li>
		</ul>
		
		<div id='wikicmds' ><ul><li><a accesskey='c'  rel='nofollow'  class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/RecentChanges'>Recent Changes</a>
</li><li><a accesskey='e'  rel='nofollow'  class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Philosophy?action=edit'>Edit</a>
</li><li><a accesskey='h'  rel='nofollow'  class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Philosophy?action=diff'>History</a>
</li><li><a accesskey=''  rel='nofollow'  class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Philosophy?action=print'>Print</a>
</li><li><a class='urllink' href='mailto:videos08@aaai.org?subject=AI%20Topics%20Contact' rel='nofollow'>Contact Us</a>
</li></ul>
</div>
	</div>
	
	
	<div id="content" class="backgrnd4">
	<table width='100%' cellspacing='0' cellpadding='0'>
  <tr>
<!--PageLeftFmt-->
      <td id='wikileft' valign='top'>
        <div class='vspace'></div><h2><strong>TOOLBOX</strong></h2>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Philosophy?action=edit'>Log In / Edit</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/SubmitNewContent'>Submit Content</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Tags/Tags'>Popular Tags</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AIVideos/HomePage'>Videos</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/A-ZIndex'>A-Z Index</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/SiteMap'>Site Map</a>
</li></ul><div class='vspace'></div><h2><strong>BROWSE TOPICS</strong></h2>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/AINews'>AI <em>in the news</em></a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/AIOverview'>AI Overview</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Agents'>Agents</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Applications'>Applications</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/CognitiveScience'>Cognitive Science</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Education'>Education</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Ethics'>Ethical &amp; Social</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/ExpertSystems'>Expert Systems</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Games'>Games &amp; Puzzles</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/History'>History</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interfaces'>Interfaces</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/MachineLearning'>Machine Learning</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/NaturalLanguage'>Natural Language</a>
</li><li><a class='selflink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Philosophy'>Philosophy</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Reasoning'>Reasoning</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Representation'>Representation</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Robots'>Robots</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/ScienceFiction'>Science Fiction</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Speech'>Speech</a>
</li><li><nobr><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Systems'>Systems &amp; Languages</a></nobr>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/TuringTest'>Turing Test</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Vision'>Vision</a>
</li></ul><div class='vspace'></div><h2><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Resources'><strong>RESOURCES</strong></a></h2>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/InteractiveResources'>Interactive</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/EducatorResources'>for Educators</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/StudentResources'>for Students</a>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Report'>Reports &amp; Projects</a>
</li></ul></li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/JournalistResources'>for Journalists</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/FAQs'>FAQs</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Reference'>Reference Shelf</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Main/EditPage'>Editing Pages</a>
</li></ul><div class='vspace'></div><h2><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/AboutUs'><strong>ABOUT THIS SITE</strong></a></h2>
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Policies/HomePage'>Policies</a>
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Project/HomePage'>Project Notes</a>
<div class='vspace'></div></li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/RecentChanges'>Changes</a>&nbsp;<img src='http://www.aaai.org/AITopics/pmwiki/pub/images/rss.gif' alt='RSS' title='RSS' />
</li></ul><div class='vspace'></div><div class='backgrnd6'>
<p  style='text-align: center;'><span style='font-size:83%'><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Notices#fairuse'>Fair Use Notice</a></span><br /><span style='font-size:83%'>&#169; <a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Notices#copy'>AAAI 2000-2008</a></span>
</p></div>
<p class='vspace'  style='text-align: center;'><a target='pmwiki'  class='urllink' href='http://www.pmwiki.org' rel='nofollow'>pmwiki.org</a> <br /><span style='font-size:83%'>pmwiki-2.2.0-beta65</span>
</p>
<p class='vspace'  style='text-align: center;'><span style='font-size:83%'><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/SideBar?action=edit'>edit SideBar</a></span>
</p>
</td>
<!--/PageLeftFmt-->
      <td id='wikibody' valign='top'>
<!--PageActionFmt-->
        
<!--PageTitleFmt-->
<!--        <div id='wikititle'>
          <div class='pagegroup'><a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics'>AITopics</a> /</div>
          <h1 class='pagetitle'>Philosophy</h1></div>   -->
<!--PageText-->
<div id='wikitext'>
<div  style='display: none;' > 
<h2  style='text-align: center;'> <strong>Philosophy</strong></h2>
</div>
<div class='vspace'></div><div style="float:left;padding: 0px 20px 10px 0px;">
<div id='topicContentBox' class='backgrnd9'><div class='backgrnd8' >
<div style="width:180px;font-size: 14px;text-align: center;margin-bottom: 5px;" ><strong><a class='selflink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Philosophy'>Philosophy</a></strong>
</div>
<ul><li>Readings:
<ul><li><a href='#good'>Introductory</a>
</li><li><a href='#readon'>General</a>
</li></ul></li><li>Subtopics:
<ul><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/NatureOfIntelligence'>Nature of Intelligence</a>
</li></ul></li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/VideoTags/Agents'>Videos</a>
</li><li><a href='#web'>Related Resources</a>
</li><li><a class='urllink' href='http://www.aaai.org/AITopics/xml/rss/phil.xml' rel='nofollow'>News Feed</a>&nbsp;<img src='http://www.aaai.org/AITopics/pmwiki/pub/images/rss.gif' alt='RSS' title='RSS' />
</li></ul></div><div class='backgrnd10' style='height:20px;'></div></div>
</div>
<div class='vspace'></div>
<table ><tr><td align='center'  valign='top'> Artificial Intelligence cannot avoid philosophy.
<p class='vspace'>If a computer program is to behave intelligently in the real world, it must be provided with some kind of framework into which to fit particular facts it is told or discovers. This amounts to at least a fragment of some kind of philosophy, however naive.
</p>
<p class='vspace'>- John McCarthy<br />Mathematical Logic in Artificial Intelligence. Daedalus 117(1): 297-310, Winter 1988
</p></td><td width='160' align='center'  valign='top'> <img src='http://www.aaai.org/AITopics/assets/Page%20Art/jm.jpeg' alt='photo of John McCarthy' title='photo of John McCarthy' /><br /><strong>John McCarthy</strong>
</td><td width='20'  valign='top'> &nbsp;&nbsp;&nbsp;
</td></tr></table>
<p><br /><br />
</p>
<div class='vspace'></div><div><span class='lfloat'><img src='http://www.aaai.org/AITopics/assets/Page%20Art/skull.gif' alt='man pondering a skull' title='man pondering a skull' /> </span></div>
<p>Many traditional philosophical questions take new twists in the context of intelligent machines. For example: What is a mind? What is consciousness? Where do we draw the line on responsibility for actions when dealing with robots, computers, programming? Do human beings occupy a privileged place in the universe? <a name='aunt' id='aunt'></a>&quot;<a href='#tudge'>Is it reasonable to ascribe consciousness to a droll and well-mannered aunt, yet deny it in a robot that behaves like one?</a>&quot; &quot;How do we acquire knowledge of the world? What do our languages tell us about our minds or the world? What is knowledge? What is a proof? What is art? Most of the sources listed below discuss issues in the philosophy of mind, epistemology, and the philosophy of language. Social and ethical considerations are certainly related, but these are listed <strong> </strong>separately, on the <a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Ethics'>Social and Ethical Implications</a> page. Similarly, many works of science fiction deal with philosophical and social issues, and these are listed separately, on the <a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/ScienceFiction'>Science Fiction</a> page.
</p>
<p class='vspace'><a name='good' id='good'></a>
</p>
<table ><tr><td width='200'  valign='top'>
<h2 class='backgrnd5'><span class='text1'>Introductory Readings</span></h2>
</td></tr></table>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www-formal.stanford.edu/jmc/aiphil.pdf' rel='nofollow'>What has AI in Common with Philosophy?</a> John McCarthy, February 29, 1996.  &quot;AI needs many ideas that have hitherto been studied only by philosophers. This is because a robot, if it is to have human level intelligence 
and ability to learn from its experience, needs a general world view in 
which to organize facts. It turns out that many philosophical problems 
take new forms when thought about in terms of how to design a robot. 
Some approaches to philosophy are helpful and others are not. &quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://philosophytalk.org/pastShows/ArtificialIntelligence.html' rel='nofollow'>This Week on Philosophy Talk - Artificial Intelligence</a> (May 20, 2007 radio broadcast; audio available online). With Ken Taylor and John Perry of Stanford University. KALW, 91.7 FM, San Francisco. &quot;At least some versions of artificial intelligence are attempts not merely to model human intelligence, but to make computers and robots that exhibit it: that have thoughts, use language, and even have free will. Does this make sense? What would it show us about human thinking and consciousness? Join John and Ken [and guest, Marvin Minsky] as they uncover the philosophical issues raised by artificial intelligence.&quot; 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.nytimes.com/2007/07/29/magazine/29robots-t.html?ref=magazine' rel='nofollow'>The Real Transformers</a> - Researchers are programming robots to learn in humanlike ways and show humanlike traits. Could this be the beginning of robot consciousness -- and of a better understanding of ourselves? By Robin Marantz Henig. The New York Times Sunday Magazine (July 29, 2007; <a target='_blank'  class='urllink' href='http://www.nytimes.com/indexes/2007/07/29/magazine/index.html' rel='nofollow'>cover story</a>). &quot;Robot consciousness is a tricky thing, according to Daniel Dennett, a Tufts philosopher and author of 'Consciousness Explained,' who was part of a team of experts that Rodney Brooks assembled in the early 1990s to consult on the Cog project. In a 1994 article in The Philosophical Transactions of the Royal Society of London, Dennett posed questions about whether it would ever be possible to build a conscious robot. His conclusion: 'Unlikely,' at least as long as we are talking about a robot that is 'conscious in just the way we human beings are.' But Dennett was willing to credit Cog with one piece of consciousness: the ability to be aware of its own internal states. ... Robot consciousness, it would seem, is related to two areas: robot learning (the ability to think, to reason, to create, to generalize, to improvise) and robot emotion (the ability to feel). Robot learning has already occurred, with baby steps, in robots like Cog and Leonardo, able to learn new skills that go beyond their initial capabilities. But what of emotion? ... &quot; 
</p>
<p class='vspace'><a name='verjee' id='verjee'></a>
<a target='_blank'  class='urllink' href='http://www.cnn.com/TRANSCRIPTS/0202/04/i_qaa.01.html' rel='nofollow'>Q&amp;A</a> <a target='_blank'  class='urllink' href='http://www.cnn.com/TRANSCRIPTS/0202/04/i_qaa.01.html' rel='nofollow'>Wth Zain Verjee</a>. Transcript of show that aired February 4, 2002 on CNN International with participants Rodney Brooks, Rolf Pfeifer, John Searle, Doug Lenat, and Dick Stottler. &quot;Searle: ... And I have no objections to artificial intelligence technology. Where I draw the line is when they say, well, now we have created a thinking machine, or we've created a conscious machine. Now, I'm glad to see Rolf doesn't say that, but an awful lot of people in AI do.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://mitworld.mit.edu/video/422/' rel='nofollow'>Creativity: The Mind, Machines, and Mathematics: Public Debate</a> [video: approx. 1 hour]. Rodney Brooks moderates this November 30, 2006 debate between Ray Kurzweil and David Gelernter. From MIT World. &quot;About the lecture: : Two of the sharpest minds in the computing arena spar gamely, but neither scores a knockdown in one of the oldest debates around: whether machines may someday achieve consciousness. (NB: Viewers may wish to brush up on the work of computer pioneer Alan Turing and philosopher John Searle in preparation for this video.)&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.vega.org.uk/video/programme/16' rel='nofollow'>Machines with Minds</a> [video: approx. 30 minutes]. An episode of The Next Big Thing Series, available from The Vega Science Trust. First aired on BBC in March 2002. The panel [Professor Aaron Sloman (University of Birmingham), Dr Amanda Sharkey (University of Sheffield), and Professor Igor Aleksander (Imperial College)] addresses questions such as: <em>Can a machine be conscious? </em>
</p>
<div class='vspace'></div><ul><li>Also see the related  BBC &amp; The Open University Web site: <a target='_blank'  class='urllink' href='http://www.open2.net/nextbigthing/ai/ai_in_depth/in_depth.htm' rel='nofollow'>The Next Big Thing - Artificial Intelligence</a>. 
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.bbc.co.uk/sn/tvradio/programmes/horizon/broadband/broadband_only/greenfield/' rel='nofollow'>Baroness Greenfield on artificial intelligence</a>: Conscious Computers - Will computers ever be able to generate human consciousness? Video clip from <a target='_blank'  class='urllink' href='http://www.bbc.co.uk/sn/tvradio/programmes/horizon/broadband/tx/singularity/' rel='nofollow'>Human v2.0 - Will the rise in computer intelligence change humanity forever?</a> Horizon (television programme series). BBC Two (October 24, 2006). 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.computerworld.com/blogs/node/5315' rel='nofollow'>The Turing Test</a> . A Computerworld TechCast (April 5, 2007). Topics covered in this podcast include The Turing Test, consciousness, and Searle's Chinese Room.
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.theconnection.org/shows/2005/06/20050613_b_main.asp' rel='nofollow'>The Ethics of Creating Consciousness</a>. The Connection radio program hosted by Dick Gordon, with guests: Marvin Minsky, Brian Cantwell Smith, and Paul Davies. From WBUR Boston and NPR. June 13, 2005. &quot;Next month, IBM is set to activate the most ambitious simulation of a human brain yet conceived. It's a model they say is accurate down to the molecule. No one claims the 'Blue Brain' project will be self-aware. But this project, and others like it, use electrical patterns in a silicon brain to simulate the electrical patterns in the human brain -- patterns which are intimately linked to thought. But if computer programs start generating these patterns -- these electrical 'thoughts' -- then what separates us from them? Traditionally human beings have reserved words like 'reasoning,' 'self-awareness,' and 'soul' as their exclusive property. But with the stirring of something akin to electronic consciousness -- some argue that human beings need to give up the ghost, and embrace the machine in all of us.&quot; Links to the broadcast are provided.
</p>
<div class='vspace'></div><div style="border:1px solid gray;padding:20px;margin-left:20px;margin-right:20px;" >
<p>&quot;It's a three-part question. What is consciousness? Can you put it in a machine? And if you did, how could you ever know for sure?&quot;<br />- from Kenneth Chang's <a href='#chang'>Can Robots Become Conscious?</a>
</p></div>
<p class='vspace'><a target='_blank'  class='urllink' href='http://eecs.vanderbilt.edu/CIS/pubs/2005-Kawamura.et.al-CIRA.pdf' rel='nofollow'>Development of a Robot with a Sense of Self</a>, by K. Kawamura, W. Dodd, P. Ratanaswasd and R. A. Gutierrez; <a target='_blank'  class='urllink' href='http://eecs.vanderbilt.edu/CIS/cishome.shtml' rel='nofollow'>Center for Intelligent Systems</a>, Vanderbilt University. Presented at the 6th IEEE International Symposium on Computational Intelligence in Robotics and Automation (CIRA), Espoo, Finland, June 27-30, 2005.
</p>
<div class='vspace'></div><ul><li>Also see this related news item: <a target='_blank'  class='urllink' href='http://www.trnmag.com/Roundup/2005/TRN_Research_News_Roundup_12-26-05.html#roboticconsciousness' rel='nofollow'>Robotic consciousness</a>. TRN Research News Roundup (December 26, 2005).
</li></ul><p class='vspace'>Philosophical Encounter. A symposium organized by Aaron Sloman at IJCAI-95, with speakers John McCarthy and Marvin Minsky. Two papers are available online:  
</p>
<div class='vspace'></div><ul><li><a target='_blank'  class='urllink' href='http://www.cs.bham.ac.uk/~axs/cog_affect/ijcai95.text' rel='nofollow'>A Philosophical Encounter.</a> By Aaron Sloman, School of Computer Science and Cognitive Science Research Centre, University of Birmingham, UK.In Proceedings of the 14th International Joint Conference on AI, Montreal, August 1995. 
</li><li><a target='_blank'  class='urllink' href='http://www-formal.stanford.edu/jmc/aiphil.html' rel='nofollow'>Artificial Intelligence and Philosophy.</a> By John McCarthy. (&quot;The present version is somewhat improved. I would like to give better references to work by philosophers that I consider to have positively influenced AI research, but it may take some time to formulate this.  By John McCarthy, Computer Science Department, Stanford University, Stanford, CA. 
</li><li>Also see: <a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interviews#sloman'>Aaron Sloman</a> interviewed by Patrice Terrier for EACE Quarterly. August 1999; updated 11 July 2002. &quot;Those who are ignorant of philosophy are doomed to reinvent it badly.&quot;
</li></ul><p class='vspace'><a name='will' id='will'></a><a target='_blank'  class='urllink' href='http://technetcast.ddj.com/tnc_program.html?program_id=82' rel='nofollow'>Spiritual Robots Symposium: Will Spiritual Robots Replace Humanity by 2100? <em>A series in eleven parts.</em></a> Made available online by Stanford's Symbolic Systems Program andTechNetCast. &quot;In 1999, two distinguished computer scientists, Ray Kurzweil and Hans Moravec, came out independently with serious books that proclaimed that in the coming century, our own computational technology, marching to the exponential drum of Moore's Law and more general laws of bootstrapping, leapfrogging, positive-feedback progress, will outstrip us intellectually and spiritually, becoming not only deeply creative but deeply emotive, thus usurping from us humans our self-appointed position as 'the highest product of evolution'. Reasonable fact or complete fiction? Expert panel assembled by Doug Hofstadter explores the issue. With presentations by Frank Drake, Doug Hofstadter, John Holland, Bill Joy, Kevin Kelly, John Koza, Ray Kurzweil, Ralph Merkle and Hans Moravec&quot; See/hear/read what they have to say via video, audio and text. 
</p>
<div class='vspace'></div><ul><li>Also see our Ethics page for the <a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Ethics#joy'>articles</a> related to the Bill Joy - Ray Kurzweil &quot;dialogue&quot;. 
</li></ul><div class='vspace'></div><div style="border:1px solid gray;padding:20px;margin-left:20px;margin-right:20px;" >
<p>&quot;Growing impatient with me as I pressed [Cynthia Breazeal] for a definition of 'alive,' she said: 'Do you have to go to the bathroom and eat to be alive?'&quot;<br />- from <a href='#ullman'>Programming the Post-Human</a> [p.67]
</p></div>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.sciencefriday.com/pages/2002/Apr/hour2_042602.html' rel='nofollow'>Humans and their Machines</a>. NPR <a target='_blank'  class='urllink' href='http://www.npr.org/programs/scifri/' rel='nofollow'>Science Friday</a> (April 26, 2002). &quot;Researchers at the MIT Artificial Intelligence Lab are working to create robots as intelligent and sociable as humans. At the same time, medical advances are making humans more robot-like, with mechanical hearts and working artificial limbs. In this hour, we'll talk with the participants of the First Utah Symposium in Science and Literature about the relationship between humans and machines - and just what it means to be human.&quot; <a target='_blank'  class='urllink' href='http://www.npr.org/ramfiles/totn/20020426.totn.02.ram' rel='nofollow'>Listen</a> to Ira Flatow, anchor of Talk Of The Nation: Science Friday, interview Rodney Brooks, Anne Foerst, and Richard Powers. 
</p>
<div class='vspace'></div><div><span class='rfloat'><img src='http://www.aaai.org/AITopics/assets/Page%20Art/pondering.gif' alt='two men lost in thought' title='two men lost in thought' /> </span><a target='_blank'  class='urllink' href='http://news.zdnet.co.uk/story/0,,s2083942,00.html' rel='nofollow'>Sentience: The next moral dilemma</a>. By Richard Barry. ZDNet UK. (January 24, 2001). &quot;If they are right, one day man will give life to a new race of intelligent sentient beings powered by artificial means. If we can, for argument's sake, agree that this is possible we should consider how a sentient artificial being would be received by man and by society. Would it be forced to exist like its automaton predecessors who have effectively been our slaves, or would it enjoy the same rights as the humans who created it, simply because of its intellect?&quot; </div>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.cs.unm.edu/~luger/ai-final/chapter1.html' rel='nofollow'>AI and Philosophy</a>. From of Chapter One (available online) of George F. Luger's textbook, Artificial Intelligence: Structures and Strategies for Complex Problem Solving, 5th Edition (Addison-Wesley; 2005). &quot;In Section 1.1 we presented the philosophical, mathematical, and sociological roots of artificial intelligence. It is important to realize that modern AI is not just a product of this rich intellectual tradition but also contributes to it.&nbsp;For example, the questions that Turing posed about intelligent programs reflect back on our understanding of intelligence itself. What is intelligence, and how is it described? What is the nature of knowledge? Can knowledge be represented? How does knowledge in an application area relate to problem-solving skill in that domain? How does knowing what is true, Aristotle's theoria, relate to knowing how to perform, his praxis ? Answers proposed to these questions make up an important part of what AI researchers and designers do.&quot;
</p>
<div class='vspace'></div><div style="border:1px solid gray;padding:20px;margin-left:20px;margin-right:20px;" >
<p>&quot;I think many passionate researchers in artificial intelligence are fundamentally interested in the question of <em>Who am I? Who are people? What are we?</em> There's a sense of almost astonishment at the prospect that information processing or computation, if you take that perspective, could lead to this. Coupled with that is the possibility of the prospect of creating consciousnesses with computer programs, computing systems some day. ... Is it possible - - - is it possible that parts turning upon parts could generate this?&quot; - Eric Horvitz on <a href='#rose'>The Charlie Rose Show</a>
</p></div>
<p class='vspace'><a target='_blank'  class='urllink' href='http://researchchannel.org/program/displayevent.asp?rid=2305' rel='nofollow'>What is Consciousness?</a> This video program is part of the <a target='_blank'  class='urllink' href='http://researchchannel.org/program/displayseries.asp?collid=459' rel='nofollow'>USC Presents...Closer To Truth</a> series available from the <a target='_blank'  class='urllink' href='http://researchchannel.org/inside/overview/index.asp' rel='nofollow'>ResearchChannel</a> (&quot;a non-profit organization founded in 1996 by a consortium of leading research universities, institutions and corporate research centers dedicated to creating a widely accessible voice for research through video and Internet channels&quot;). Panelists for this August 8, 2004 program include &quot;David Chalmers, professor of philosophy, co-head, Center for Consciousness, University of Arizona, [and]John Searle, professor of philosophy, University of California, Berkeley.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.aisb.org.uk/publications/proceedings/aisb05/7_MachConsc_Final.pdf' rel='nofollow'>Proceedings of the Symposium on Next Generation Approaches to Machine Consciousness: Imagination, Development, Intersubjectivity,  and Embodiment</a>. AISB 2005. One of the many <a target='_blank'  class='urllink' href='http://www.aisb.org.uk/publications/proceedings.shtml' rel='nofollow'>convention proceedings</a> available from The Society for the Study of Artificial Intelligence and Simulation of Behaviour (SSAISB).
</p>
<p class='vspace'><a name='rose' id='rose'></a><a target='_blank'  class='urllink' href='http://www.charlierose.com/' rel='nofollow'>The Charlie Rose Show</a>: <em><a target='_blank'  class='urllink' href='http://www.charlierose.com/shows/2004/12/21/2/a-panel-discussion-about-artificial-intelligence' rel='nofollow'>A panel discussion about Artificial Intelligence</a></em> (December 21, 2004), with Rodney Brooks (Director, MIT Artificial Intelligence Laboratory &amp; Fujitsu Professor of Computer Science &amp; Engineering, MIT), Eric Horvitz (Senior Researcher and Group Manager, Adaptive Systems &amp; Interaction Group, Microsoft Research), and Ron Brachman (Director, Information Processing Technology Office, Defense Advanced Research Project Agency, and President, American Association for Artificial Intelligence). &quot;<strong>Rose:</strong> What do you think has been the most important advance so far? <strong>Brachman:</strong> A lot of people will vary on that and I'm sure we all have different opinions. In some respects one of the - - - I think the elemental insights that was had at the very beginning of the field still holds up very strongly which is that you can take a computing machine that normally, you know, back in the old days we think of as crunching numbers, and put inside it a set of symbols that stand in representation for things out in the world, as if we were doing sort of mental images in our own heads, and actually with computation, starting with something that s very much like formal logic, you know, if-then-else kinds of things, but ultimately getting to be softer and fuzzier kinds of rules, and actually do computation inside, if you will, the mind of the machine, that begins to allow intelligent behavior. I think that crucial insight, which is pretty old in the field, is really in some respects one of the lynch pins to where we've gotten. ... <strong>Horvitz: </strong>I think many passionate researchers in artificial intelligence are fundamentally interested in the question of <em>Who am I? Who are people? What are we?</em> There's a sense of almost astonishment at the prospect that information processing or computation, if you take that perspective, could lead to this. Coupled with that is the possibility of the prospect of creating consciousnesses with computer programs, computing systems some day. It's not talked about very much at formal AI conferences, but it's something that drives some of us in terms of our curiosity and intrigue. I know personally speaking, this has been a core question in the back of my mind, if not the foreground, not on my lips typically, since I've been very young. This is this question about who am I. <strong>Rose:</strong> ... can we create it? <strong>Horvitz:</strong> Is it possible - - - is it possible that parts turning upon parts could generate this?&quot;
</p>
<p class='vspace'><a name='readon' id='readon'></a>
</p>
<table ><tr><td width='200'  valign='top'>
<h2 class='backgrnd5'><span class='text1'>General Readings</span></h2>
</td></tr></table>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.theatlantic.com/unbound/digicult/dc981209.htm' rel='nofollow'>Daniel Dennett</a>. Interviewed by Harvey Blume. The Atlantic Unbound (December 9, 1998). &quot;As posed by Alan Turing, the question of machine intelligence has become a central theme of our time -- and here, as elsewhere, Dennett brings analytic rigor to bear. To the question of whether machines can attain high-order intelligence, Dennett makes this provocative answer: 'The best reason for believing that robots might some day become conscious is that we human beings are conscious, and we are a sort of robot ourselves.' This is part of Dennett's campaign to overcome the mind-body split bequeathed to us by Descartes, who identified his existence with his self-consciousness (his Cogito) and believed that the thinking portion of the self was attached almost accidentally to the body. Like many in cognitive science, Dennett wants to show that mind and matter are not necessarily opposed.&quot;  
</p>
<div class='vspace'></div><ul><li>Be sure to see our collection of <a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interviews'>Interviews</a> for what others have to say about this.
</li><li>Also see: <a class='urllink' href='http://www.aaai.org/AITopics/html/archvE4.html#april17a' rel='nofollow'>The semantic engineer</a> - Profile: Daniel Dennett. By Andrew Brown. The Guardian (April 17, 2004). &quot;It was at Oxford, too, that he first became interested in computers and the brain. The Oxford philosopher John Lucas had published a paper - still famous - arguing that Gödel's theorem disproved any theory that humans must be machines, and that human thought could be completely simulated on a computer. This is the position Dennett became famous for attacking. ... He's famous among philosophers as an extreme proponent of robot consciousness, who will argue that even thermostats have beliefs about the world. ... 'Conscious robot is not an oxymoron -or maybe it was, but it's not going to be for much longer. How much longer? I don' t know. Turing [50 years ago] said 50 years, and he was slightly wrong, but the popular imagination is already full with conscious robots.'&quot;
</li></ul><p class='vspace'><a class='urllink' href='http://www.aaai.org/ojs/index.php/aimagazine/article/view/1174/1091' rel='nofollow'>AI&rsquo;s Half-Century</a>. By Margaret A. Boden. AI Magazine 16(4): Winter 1995, 96-99. &quot;Part of what it means to say that something is philosophically interesting is that it is highly controversial --- and AI is. ... What of consciousness? ... As though all these philosophical disputes weren’t enough, neo-Heideggerian murmur- ings are afoot. They threaten the fundamental assumptions of AI, for they reject the sub- ject-object distinction presupposed by materialists and idealists alike, and deny the epistemological primacy of science.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.guardian.co.uk/Archive/Article/0,4273,4270209,00.html' rel='nofollow'>It's the thought that counts</a>. By Dylan Evans. Guardian (October 6, 2001). &quot;Will machines ever be able to think for themselves? &quot;There are those, however, who argue that the Turing test is, in fact, too difficult: not only does a machine have to be able to think, they say, but it also has to be able to think like a human. Unless we assume, chauvinistically, that human thought is the only kind there is, we shall have to admit that a machine might be able to think and yet still fail the test - it might simply be thinking in a non-human-like way. To illustrate this point, the philosopher Robert French tells the following story. ...&quot;
</p>
<p class='vspace'>Consciousness, Agents and the Knowledge Game. By Luciano Floridi.  Minds and Machines 15(3-4):  415-444 (2005). The full text preprint of this article can be accessed from the author's University of Oxford <a target='_blank'  class='urllink' href='http://www.wolfson.ox.ac.uk/~floridi/' rel='nofollow'>homepage</a>. Abstract: &quot;This paper has three goals. The first is to introduce the 'knowledge game', a new, simple and yet powerful tool for analysing some intriguing philosophical questions. The second is to apply the knowledge game as an informative test to discriminate between conscious (human) and conscious-less agents (zombies and robots), depending on which version of the game they can win. And the third is to use a version of the knowledge game to provide an answer to Dretske’s question 'how do you know you are not a zombie?'.&quot;
</p>
<p class='vspace'><a name='af' id='af'></a><a target='_blank'  class='urllink' href='http://www.kurzweilai.net/meme/frame.html?main=/articles/art0180.html' rel='nofollow'>Robot: Child of God</a>. By Anne Foerst. &quot;Sometimes computers act as if they are possessed -- does that mean they may have souls? Probably not right now, but Anne Foerst explores the possibility of soulful robots. Originally published March 2000 as a chapter in the book &quot;God for the 21st Century.&quot; Published on KurzweilAI.net May 9, 2001.&quot; Excerpt: &quot;In the light of this understanding of human specialness, I would have a hard time not to assign personhood to a creature possessing the appropriate degree of complexity. If a being is understood as a partner and friend, it seems hard to take this attribute of value, assigned to it by its friends, away.&quot; 
</p>
<div class='vspace'></div><ul><li>Also see: an <a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interviews#foerst'>&quot;innerview&quot; with Anne Foerst</a> and <a href='#qaaf'>Q&amp;A with Anne Foerst</a>. 
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.stanford.edu/group/SHR/4-2/text/toc.html' rel='nofollow'>Constructions of the Mind--Artificial Intelligence and the Humanities.</a> A special issue of the Stanford Humanities Review 4(2): Spring 1995. Stefano Franchi and Guven Guzeldere, editors. From the Table of Contents, you may link to several full-text articles. 
</p>
<p class='vspace'><a class='urllink' href='http://www.aaai.org/ojs/index.php/aimagazine/article/view/1048/966' rel='nofollow'>Review of The Philosophy of Artificial Intelligence</a>, edited by Margaret A. Boden (1990). Reviewed by Lee A. Gladwin. AI Magazine 14(2): Summer 1993, 67-68. 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://prelectur.stanford.edu/lecturers/hofstadter/excerpts.html#gebxx' rel='nofollow'>On what GEB is really all about (twenty years later</a>). By Douglas Hofstadter. Available as a from the resource collection for his February 2006 Stanford Presidential Lecture, <a target='_blank'  class='urllink' href='http://prelectur.stanford.edu/lecturers/hofstadter/index.html' rel='nofollow'>Analogy as Core, Core as Analogy</a>, &quot;In a word, GEB is a very personal attempt to say how it is that animate beings can come out of inanimate matter. What is a self, and how can a self come out of stuff that is as selfless as a stone or a puddle? What is an 'I' and why are such things found (at least so far) only in association with, as poet Russell Edson once wonderfully phrased it, 'teetering bulbs of dread and dream' -- that is, only in association with certain kinds of gooey lumps encased in hard protective shells mounted atop mobile pedestals that roam the world on pairs of slightly fuzzy, jointed stilts?&quot; 
</p>
<div class='vspace'></div><div style="font-size:small; margin-right:20px;" >
<ul><li>GEB = Hofstadter, Douglas R., G&ouml;del, Escher, Bach: an Eternal Golden Braid, NY: Basic Books, 1979. [Also: GEB, 20th Anniversary Edition: With a New Preface by the Author, NY: Basic Books, 1999.]
</li></ul></div>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.csmonitor.com:80/durable/2001/06/28/p14s1.htm' rel='nofollow'>Kiss me, you human</a>. Robot Kismet can walk, talk, and make logical decisions. What's the next step in the quest for artificial intelligence? By Stephen Humphries.The Christian Science Monitor. (June 28, 2001) &quot;It's the astonishing growth in real-world artificial-intelligence technology that is forcing thinkers, theologians, philosophers, and the public to reexamine some age-old fundamental philosophical questions with a new vigor and urgency. Is it possible to replicate human consciousness in machines? If so, then what does that tell us about consciousness? What does it mean to be human?&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.compapp.dcu.ie/~humphrys/Notes/AI/philosophy.html' rel='nofollow'>Philosophy of AI</a>. From 
<a target='_blank'  class='urllink' href='http://www.compapp.dcu.ie/~humphrys/' rel='nofollow'>Mark Humphrys</a>, Lecturer, School of Computing, Dublin City University. &quot;Philosophy of AI is a history of "big names". The debates are great fun to watch. Here are some big names and my take on them. You don't have to agree with me of course.&quot; 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.darwinmag.com/read/120101/hal.html' rel='nofollow'>Are You There, God? (It's Me, HAL) - Science Meets Spirituality</a>. Techies and theologians are talking about the spiritual implications of the Web, robots and virtual reality -- and they think business leaders should too. By Sari Kalin. Darwin Magazine (December 2001). 
</p>
<div class='vspace'></div><ul><li>Sidebars to the article include: 
<ul><li><a name='qaaf' id='qaaf'></a><a target='_blank'  class='urllink' href='http://www.darwinmag.com/read/120101/hal_foerst.html' rel='nofollow'>Q&amp;A with Anne Foerst</a>. Questions include: How do you start a dialogue between AI and theology? ... Are AI researchers trying to play God? ... Will humanoid robots ever be conscious, and will they ever have souls? ... What are the business implications of your research? 
</li><li><a target='_blank'  class='urllink' href='http://www.darwinmag.com/read/120101/hal_sidebar2.html' rel='nofollow'>Ray Kurzweil Speaks His Mind</a>. Questions include: Will robots ever become conscious? ... How would we ever prove that a machine is -- or isn't -- conscious? 
</li></ul></li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.wired.com/wired/archive/10.12/holytech.html' rel='nofollow'>God Is the Machine</a>. In the beginning there was 0. and then there was 1. A mind-bending meditation on the transcendent power of digital computation. By Kevin Kelly. Wired Magazine (December 2002). 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.kurzweilai.net/meme/frame.html?main=/articles/art0103.html' rel='nofollow'>Philosophical Roots</a>. By Raymond Kurzweil (1990). Chapter Two of the book: <a target='_blank'  class='urllink' href='http://www.kurzweilai.net/meme/frame.html?main=/articles/art0325.html' rel='nofollow'>The Age of the Intelligent Machine</a>, ed. Kurzweil, Raymond, 23-100. Cambridge, MA: The MIT Press. 
</p>
<div class='vspace'></div><ul><li>Also see the <a target='_blank'  class='urllink' href='http://www.kurzweilai.net/meme/memelist.html?m=4' rel='nofollow'>Will Machines Become Conscious?</a> collection of articles at KurzweilAI.net.: &quot;'Suppose we scan someone's brain and reinstate the resulting 'mind file' into a suitable computing medium,' asks Raymond Kurzweil. 'Will the entity that emerges from such an operation be conscious?' Asking that question is a good way to start an argument, which is exactly what we intend to do right here.&quot;
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.nytimes.com/2000/12/10/technology/10SMAR.html' rel='nofollow'>The Soul of the Ultimate Machine</a>. By John Markoff. The New York Times, December 10, 2000: Section 3, Page 1. "The astrophysicist Larry Smarr talks about what he calls 'the emerging planetary supercomputer.' The Internet, he explains, is evolving into a single vast computer. The big question is 'Will it become self -aware?'" 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.kurzweilai.net/meme/frame.html?main=/articles/art0320.html%20' rel='nofollow'>A Conversation between a Human Computer and a Materialist Philosopher</a>. By Blaine Mathieu. From Ray Kurzweil's book,  <a target='_blank'  class='urllink' href='http://www.kurzweilai.net/meme/frame.html?main=/articles/art0320.html?' rel='nofollow'>The Age of Intelligent Machines</a>, published in 1990. &quot;There are few questions more mysterious and thought provoking than whether a nonhuman machine could ever be considered truly human in any important sense of the word. Let us jump ahead a few decades and imagine, for a moment, that all the problems of creating a truly intelligent machine have been solved. How would two 'people,' a philosopher and a computer, handle some of the physical, emotional, and moral issues of such a creation?&quot;
</p>
<p class='vspace'>Some Philosophical Problems from the Standpoint of Artificial Intelligence. By John McCarthy and Patrick J. Hayes. 1969. In Machine Intelligence 4, ed. Meltzer, B., D. Michie and M. Swann, 463-502. Edinburgh, Scotland: Edinburgh University Press. An <a target='_blank'  class='urllink' href='http://www-formal.stanford.edu/jmc/mcchay69/mcchay69.html' rel='nofollow'>online version</a> is available at John McCarthy's web site.
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www-formal.stanford.edu/jmc/aiphil/aiphil.html' rel='nofollow'>What has AI in Common with Philosophy?</a> By John McCarthy. &quot;AI needs many ideas that have hitherto been studied only by philosophers. This is because a robot, if it is to have human level intelligence and ability to learn from its experience, needs a general world view in which to organize facts. It turns out that many philosophical problems take new forms when thought about in terms of how to design a robot. Some approaches to philosophy are helpful and others are not.&quot; 
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.sciencemag.org/cgi/content/full/304/5676/1450' rel='nofollow'>Programs of the Mind</a>. Review by Gary Marcus. Science Magazine (June 4, 2004; subscription required). &quot;Eric Baum's What Is Thought? [MIT Press, Cambridge, MA, 2004], consciously patterned after [Erwin] Schrödinger's book [What Is Life?], represents a computer scientist's look at the mind. Baum is an unrepentant physicalist. He announces from the outset that he believes that the mind can be understood as a computer program. Much as Schrödinger aimed to ground the understanding of life in well-understood principles of physics, Baum aims to ground the understanding of thought in well-understood principles of computation. In a book that is admirable as much for its candor as its ambition, Baum lays out much of what is special about the mind by taking readers on a guided tour of the successes and failures in the two fields closest to his own research: artificial intelligence and neural networks. ... Advocates of what the philosopher John Haugeland famously characterized as GOFAI (good old-fashioned artificial intelligence) create hand-crafted intricate models that are often powerful yet too brittle to be used in the real world. ... At the opposite extreme are researchers working within the field of neural networks, most of whom eschew built-in structure almost entirely and rely instead on statistical techniques that extract regularities from the world on the basis of massive experience.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://msnbc.msn.com/id/5386726' rel='nofollow'>The rise of 'Digital People'</a> - Tales about artificial beings have sparked fascination and fear for centuries; now the tales are turning into reality. Excerpt from "Digital People: From Bionic Humans to Androids" by Sidney Perkowitz, the Charles Howard Candler professor of physics at Emory University. MSNBC Science News (July 13, 2004). &quot;There is, however, considerable debate about the possibility of achieving the centerpiece of a complete artificial being, artificial intelligence arising from a humanly constructed brain that functions like a natural human one. Could such a creation operate intelligently in the real world? Could it be truly self-directed? And could it be consciously aware of its own internal state, as we are? These deep questions might never be entirely settled. We hardly know ourselves if we are creatures of free will, and consciousness remains a complex phenomenon, remarkably resistant to scientific definition and analysis. One attraction of the study of artificial creatures is the light it focuses on us: To create artificial minds and bodies, we must first better understand ourselves. While consciousness in a robot is intriguing to discuss, many researchers believe it is not a prerequisite for an effective artificial being. In his 'Behavior-Based Robotics,' roboticist Ronald Arkin of the Georgia Institute of Technology argues that 'consciousness may be overrated,' and notes that 'most roboticists are more than happy to leave these debates on consciousness to those with more philosophical leanings.' For many applications, it is enough that the being seems alive or seems human, and irrelevant whether it feels so. ... And yet ... there is the dream and the breathtaking possibility that humanity can actually develop the technology to create qualitatively new kinds of beings. These might take the form of fully artificial, yet fully living, intelligent, and conscious creatures -- perhaps humanlike, perhaps not. Or they might take the form of a race of 'new humans'; that is, bionic or cyborgian people who have been enormously augmented and extended physically, mentally, and emotionally.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://technologyreview.com/articles/05/10/wo/wo_101305hawkins.1.asp' rel='nofollow'>Jeff Hawkins: Q&amp;A</a>. Interviewed by Jason Pontin. Technology Review (October 13, 2005). &quot;Jeff Hawkins, the chief technology officer of Palm, was the founder of Palm Computing, where he invented the PalmPilot, and also the founder of HandSpring, where he invented the Treo. But Palm and creating mobile devices are only a part-time job for Hawkins. His true passion is neuroscience. Now, after many years of research and meditation, he has proposed an all-encompassing theory of the mammalian neocortex. 'Hierarchical Temporal Memory' (HTM) claims to explain how our brains discover, infer, and predict patterns in the phenomenal world.<em> JP</em>: Is the higher consciousness -- what philosophers sometimes call 'self-consciousness' -- a byproduct of HTM? <em>JH</em>: Yes. I think I understand what consciousness is now. There are two elements to consciousness. First, there is the element of consciousness where we can say, 'I am here now.' This is akin to a declarative memory where you can actively recall doing something. Riding a bike cannot be recalled by declarative memory, because I can't remember how I balanced on a bike. But if I ask, 'Am I talking to Jason?' I can answer 'Yes.' So I like to propose a thought experiment: if I erase declarative memory, what happens to consciousness? I think it vanishes. But there is another element to consciousness: what philosophers and neuroscientists call 'qualia:' the feeling of being alive. ...&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://cognet.mit.edu/MITECS/Entry/searle' rel='nofollow'>Chinese Room Argument</a>. Entry by John R. Searle in the MIT Encyclopedia of Cognitive Science. &quot;The Chinese room argument is a refutation of strong artificial intelligence. 'Strong AI' is defined as the view that an appropriately programmed digital computer with the right inputs and outputs, one that satisfies the Turing test, would necessarily have a mind.&quot; 
</p>
<div class='vspace'></div><ul><li>Also see:  
<ul><li><a target='_blank'  class='urllink' href='http://philosophy.uwaterloo.ca/MindDict/chineseroom.html' rel='nofollow'>Chinese room</a> -&nbsp;An argument forwarded by John Searle intended to show that the mind is not a computer and how the Turing Test is inadequate. By Chris Eliasmith. Dictionary of Philosophy of Mind. 
</li><li><a target='_blank'  class='urllink' href='http://www.utm.edu/research/iep/c/chineser.htm' rel='nofollow'>The Chinese Room Argument</a>. By Larry Hauser. The Internet Encyclopedia of Philosophy.
</li><li><a class='wikilink' href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Interviews#searle'>Two interviews</a> with John Searle and this <a href='#verjee'>panel discussion.</a>
</li><li><a target='_blank'  class='urllink' href='http://www.abc.net.au/rn/philosopherszone/stories/2006/1639491.htm' rel='nofollow'>The question of consciousness</a>. Philosopher's Zone, presented by Alan Saunders. ABC Radio National (May 20, 2006). <em>A transcript and audio downloads are available</em>.&quot;<em>Alan Saunders:</em> Hello, I'm Alan Saunders, welcome to The Philosopher's Zone. This week, a virtuoso public performance by one of the most important philosophers in the English-speaking world today: John Searle, Professor of the Philosophy of Mind and Language at the University of California, Berkeley. He's talking at 'Towards a Science of Consciousness', a conference put on last month by the Center for Consciousness Studies at the University of Arizona. His subject is dualism. More than 350 years ago, the great French philosopher, Rene D&eacute;scartes, declared that the mind is a thing that thinks and does not occupy space, whereas the body occupies space and does not think. The decisive argument for this, he said, is that body is by its nature divisible: you can cut it up into little pieces, but you can't do that with a mind. This appears to imply that the mind and the body have a different ontological status - in other words, you don't lump them together when you draw up your ontology, that's to say your inventory of what the universe contains. This is dualism, and John Searle's not happy with the idea. <em>John Searle:</em> I have been trying to get out of the consciousness business for a very simple reason: I think once we get it in a kind of shape where it admits of empirical study, it's essentially a problem for a neurobiologist. I mean, there are a lot of other problems for psychology and cognitive science, but the problems that most interest me are things are like, well, how exactly does it work in the brain? That, I see as a neurobiological problem. ... Now people always tell me it was very hard to define consciousness, but I think if you're just looking for the kind of commonsense definition that you get at the beginning of the investigation, and not at the hard-nosed scientific definition that comes at the end, it's not hard to give a commonsense definition of consciousness. Consciousness consists of those states of feeling or sentience or awareness....&quot;
</li></ul></li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.cs.bham.ac.uk/~axs/misc/talks/#aiandphil' rel='nofollow'>Artificial Intelligence and Philosophy</a>. From Aaron Sloman. &quot;This was a lecture to first year AI students at Birmingham, Dec 11th 2001, on AI and Philosophy, explaining how AI relates to philosophy and in some ways improves on philosophy. It was repeated December 2002, December 2003, October 2004, each time changing a little. It introduces ideas about ontology, architectures, virtual machines and how these can help transform some old philosophical debates.&quot;
</p>
<p class='vspace'><a name='crp' id='crp'></a><a target='_blank'  class='urllink' href='http://www.cs.bham.ac.uk/research/cogaff/crp/' rel='nofollow'>The Computer Revolution in Philosophy</a>. Philosophy, science and models of mind. By Aaron Sloman. [Originally published in 1978 by Harvester Press and Humanities Press. Though the book is now out of print, it has been made available online by the author.] From the <a target='_blank'  class='urllink' href='http://www.cs.bham.ac.uk/research/cogaff/crp/preface1.html' rel='nofollow'>Preface</a>: &quot;And computing is more important than computers: programming languages, computational theories and concepts these are what computing is about, not transistors, logic gates or flashing lights. Computers are pieces of machinery which permit the development of computing as pencil and paper permit the development of writing. In both cases the physical form of the medium used is not very important, provided that it can perform the required functions. Computing can change our ways of thinking about many things, mathematics, biology, engineering, administrative procedures, and many more. But my main concern is that it can change our thinking about ourselves: giving us new models, metaphors, and other thinking tools to aid our efforts to fathom the mysteries of the human mind and heart. The new discipline of Artificial Intelligence is the branch of computing most directly concerned with this revolution. By giving us new, deeper, insights into some of our inner processes, it changes our thinking about ourselves. It therefore changes some of our inner processes, and so changes what we are, like all social, technological and intellectual revolutions.&quot;
</p>
<p class='vspace'><a name='bhist42' id='bhist42'></a>
<a name='tudge' id='tudge'></a>
<a target='_blank'  class='urllink' href='http://www.theage.com.au/articles/2003/02/09/1044725672185.html' rel='nofollow'>At one with the universe</a> - Do androids dream of electric sheep? Colin Tudge in London examines definitions of consciousness and artificial intelligence. The Age (February 10, 2003). &quot;There are three points of view. The first, which can be traced back to the founder of modern computing, Alan Turing, and is embraced by the Oxford physiologist Colin Blakemore, is pragmatic. Turing pointed out that it is impossible to know whether other human beings are conscious. Because we feel conscious, we assume other people must be like us. But this can only be an inference. But suppose we made a computer - a robot - that could make whimsical jokes and pass the sandwiches without being asked.... [U]ntil now, three main views have prevailed. One is the 'dualism' of Rene Descartes, which says the universe has two components - matter and mind. The second is the modern orthodox idea - that only matter 'exists', and that mind (including consciousness) is just an 'epiphenomenon'; something that seems to emerge when matter is suitably organised. The third is reflected most starkly in the idealist philosophy of Bishop Berkeley; that only thought is real, and matter is an illusion. But the emerging modern view says that matter and consciousness are not separate entities, as Descartes supposed, but complementary aspects of the universe. Both exist, but neither is primary. Each is the obverse of the other, like two sides of a coin.&quot; (It is also this article from which the <a target='_blank'  href='#aunt'>question</a> toward the top of this page was excerpted.)
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.kurzweilai.net/meme/frame.html?main=/articles/art0163.html' rel='nofollow'>Growing Up in the Age of Intelligent Machines: Reconstructions of the Psychological and Reconsiderations of the Human.</a> By Sherry Turkl. From Ray Kurzweil's book, The Age of Intelligent Machines(1990). &quot;Thus, the presence of intelligent machines in the culture provokes a new philosophy in everyday life. Its questions are not so different than the ones posed by professionals: If the mind is (at least in some ways) a machine, who is the actor? Where is intention when there is program? Where is responsibility, spirit, soul? In my research on popular attitudes toward artificial intelligence I have found that the answers being proposed are not very different either. Faced with smart objects, both professional and lay philosophers are moved to catalog principles of human uniqueness.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.kurzweilai.net/meme/frame.html?main=/articles/art0103.html' rel='nofollow'>The Age of Intelligent Machines: Can Computers Think?</a> By Mitchell Waldrop. From Ray Kurzweil's book, The Age of Intelligent Machines (1990). &quot;The complexities of the mind mirror the challenges of Artificial Intelligence. This article discusses the nature of thought itself -- can it be replicated in a machine?&quot; Among the topics covered are: Can a Machine Be Aware?, The Chinese Room, and, Science as a Message of Hope.
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.randomhouse.com/anchor/catalog/display.pperl?isbn=9781400031580' rel='nofollow'>Edison's Eve - A Magical History of the Quest for Mechanical Life</a>. By Gaby Wood. Anchor Trade Paperback (July 2003). <a target='_blank'  class='urllink' href='http://www.randomhouse.com/anchor/catalog/display.pperl?isbn=9781400031580&amp;view=qa' rel='nofollow'>Author Q &amp; A</a>: &quot;<strong>Q:</strong> You begin your 'Magical History of the Quest for Mechanical Life' at a very specific place and time: with the story of the philosopher Rene Descartes sailing to Sweden in the mid-17th-century, in the company of an android. Why this moment? <strong>A:</strong> Although people have tried to construct mechanical simulations of human and animal life for millennia (from Plato’s contemporary, Archytas of Tarentum, to Albertus Magnus, a 13th-century Dominican monk), I wanted to show that it was only really during the Enlightenment that these attempts became more than practical enterprises: they were philosophical experiments as well. Descartes was an immediate precursor to the philosophers of the 18th century who were preoccupied with the question of whether humans were born with a soul, or were merely very complex machines. In their quest for an answer to this question, they built machines in the image of men and women, thinking: if men are just machines, then does a mechanically-constructed man amount to a human being? Rather than being a craft, in other words, the art of mechanics became, in that period, a way of thought. The objects made by the mechanicians of the Enlightenment were puzzles, riddles, concrete attempts to answer conceptual problems: Who are we? What are we made of? What makes us human? Can we be replicated artificially? These questions, which we are still trying to answer today -- at MIT’s Artificial Intelligence lab, at the cloning clinic of Severino Antinori -- were first crystallized by Descartes and his followers.&quot;
</p>
<p class='vspace'><a name='slomandance' id='slomandance'></a><a target='_blank'  class='urllink' href='http://doi.ieeecomputersociety.org/10.1109/MIS.2005.61' rel='nofollow'>AI and Philosophy: How Can You Know the Dancer from the Dance?</a> By Linda World. IEEE Intelligent Systems (July/August 2005; Vol. 20 (4): 84 - 85). Excerpt from the abstract: &quot;Aaron Sloman was teaching philosophy at the University of Sussex in 1969, when he met Max Clowes. Clowes had done pioneering work in computer image interpretation. Now, he was asking Sloman to drop the way he learned to do philosophy at Oxford and to start studying artificial intelligence instead. Nine years later, Sloman published <em>The Computer Revolution in Philosophy</em>....&quot;
</p>
<div class='vspace'></div><ul><li>The <a target='_blank'  class='urllink' href='http://www.computer.org/portal/cms_docs_intelligent/intelligent/content/promo3.pdf' rel='nofollow'>full text</a> of the article is available for a limited promotional period. Here's an excerpt: &quot;Sloman sees 'a deep continuity' between AI and very old problems in philosophy. Philosophy needs AI to progress in its study of difficult questions about the nature of mind. AI needs philosophy to clarify its requirements analyses.&quot;
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://serendip.brynmawr.edu/Mind/Table.html' rel='nofollow'>Mind and Body: Rene Descartes to William James</a>. By Robert H. Wozniak. &quot;The common sense view of mind and body is that they interact. Our perceptions, thoughts, intentions, volitions, and anxieties directly affect our bodies and our actions. States of the brain and nervous system, in turn, generate our states of mind. Unfortunately, the common sense notion appears to involve a contradiction.&quot; 
</p>
<p class='vspace'><a name='web' id='web'></a>
</p>
<table ><tr><td width='200'  valign='top'>
<h2 class='backgrnd5'><span class='text1'>Related Resources</span></h2>
</td></tr></table>
<p class='vspace'><a target='_blank'  class='urllink' href='http://aima.cs.berkeley.edu/ai.html#phil' rel='nofollow'>AI on the Web: Philosophy and the Future.</a> A resource companion to Stuart Russell and Peter Norvig's &quot;Artificial Intelligence: A Modern Approach.&quot;
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://commhum.mccneb.edu/PHILOS/techessay.htm' rel='nofollow'>Essays on the Philosophy of Technology</a>. Maintained by Dr. Frank Edler, Metropolitan Community College, Omaha, Nebraska. A well-presented and wide ranging list of links to full-text online papers and other websites.
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.iacap.org/index.php' rel='nofollow'>International Association of Computing and Philosophy</a>. According its <a target='_blank'  class='urllink' href='http://www.iacap.org/mission.php' rel='nofollow'>Mission Statement</a>: &quot;The International Association for Computing and Philosophy (IACAP) is a professional association emerging from a history of conferences that began in 1986. Adopting its mission from these conferences, the IACAP exists is to promote scholarly dialogue on all aspects of the computational turn and the use of computers in the service of philosophy. Conference topics have included:
</p><ul><li>Artificial Intelligence / Cognitive Science
</li><li>Artificial Life / Computer Modeling in Biology
</li><li>Computer Ethics ...&quot; 
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.machineconsciousness.org/overview.html#mconsciousness' rel='nofollow'>Machine Consciousness Website</a>. Maintained by Owen Holland and Magdalena Kogutowska. &quot;The last decade has been marked by a rapid increase in the number of people interested in the scientific study of consciousness. Most such activity has been directed towards the understanding of the processes underlying consciousness in humans, and most research has taken place within psychology and neuroscience. However, in the last few years a third strand has emerged: the study, mainly by engineers and computer scientists, of how it might be possible to build conscious machines. We believe that the best name for this new enterprise is 'machine consciousness', and this web site is intended to serve as a focus and information source for anyone involved in the area or wishing to find out more about it.&quot;
</p>
<div class='vspace'></div><ul><li> Also <em>listen</em> to this interview with Owen Holland from <a target='_blank'  class='urllink' href='http://lis.epfl.ch/resources/podcast/index.html' rel='nofollow'>Talking Robots</a> (January 19, 2007): <a target='_blank'  class='urllink' href='http://lis.epfl.ch/resources/podcast/mp3/TalkingRobots-OwenHolland.mp3' rel='nofollow'>Owen Holland - Robot Consciousness</a>: &quot;In this episode we interview Owen Holland about his rediscovery of the first autonomous robot ever built, his research in artificial consciousness and his life-size 'anthropomimetic' humanoid robot which closely copies human muscular and skeletal structure. Owen Holland is a professor at the University of Essex....&quot;
<ul><li>And be sure to check out <a target='_blank'  class='urllink' href='http://cswww.essex.ac.uk/staff/owen/' rel='nofollow'>Owen Holland's homepage</a>&nbsp; and the <a target='_blank'  class='urllink' href='http://www.cronosproject.net/' rel='nofollow'>CRONOS Project</a>.
</li></ul></li></ul><p class='vspace'>North American Computing and Philosophy [CAP] Conference: <a target='_blank'  class='urllink' href='http://www.cogsci.rpi.edu/conferences/cap/index.php' rel='nofollow'>2006</a> | <a target='_blank'  class='urllink' href='http://oregonstate.edu/groups/cap/2005/program.html' rel='nofollow'>2005</a> | <a target='_blank'  class='urllink' href='http://oregonstate.edu/groups/cap/2003/program.html' rel='nofollow'>2003</a> | <a target='_blank'  class='urllink' href='http://oregonstate.edu/groups/cap/2002/conference.html' rel='nofollow'>2002</a> | <a target='_blank'  class='urllink' href='http://oregonstate.edu/groups/cap/2001/conference.html' rel='nofollow'>2001</a> 
</p>
<p class='vspace'><a name='consc' id='consc'></a><a target='_blank'  class='urllink' href='http://www.u.arizona.edu/~chalmers/online.html' rel='nofollow'>Online Papers on Consciousness</a>. Compiled by David Chalmers, Professor of Philosophy and Associate Director of the Center for Consciousness Studies at the University of Arizona, this well organized site offers links to 698 online papers. WOW! 
</p><ul><li>Includes <a target='_blank'  class='urllink' href='http://www.u.arizona.edu/~chalmers/biblio/4.html' rel='nofollow'>Philosophy of Artificial Intelligence. Part of Contemporary Philosophy of Mind: An Annotated Bibliography.</a> 
</li></ul><p class='vspace'><a target='_blank'  class='urllink' href='http://www.weblab.org/blurring/intro.html' rel='nofollow'>The Blurring Test</a> [In Development]. &quot;The Blurring Test playfully explores the increasingly blurred lines between humans and machines. For decades, the Turing test for Artificial Intelligence has forced computers to mimic humans. But why let humans off the hook? This project turns the test on its head by creating various challenges for humans to prove their humanity... to computers and to themselves.&quot; Visit <a target='_blank'  class='urllink' href='http://www.weblab.org/wdf/projects/human.html' rel='nofollow'>Web Lab's site</a> and converse with the chatterbot, MR MIND. 
</p>
<div class='vspace'></div><ul><li>&quot;Can you claim that your 'human' attributes will forever be exclusively human? MR MIND asks you to take a close look at the changing boundaries between humans and machines; his cause is your understanding. The Blurring Test is about human progress: Someday it might be important to convince our computers (and each other) that we are human.&quot; -from the <a target='_blank'  class='urllink' href='http://www.weblab.org/blurring/intro.html' rel='nofollow'>Introduction</a>
</li><li>also check out the article, <a href='#donath'>Being Real</a>, by Judith Donath
</li></ul><p class='vspace'><a name='more' id='more'></a>
</p><h2>Other References Offline</h2>
<ul><li><a href='#art'><strong>Articles from Newspapers, Journals &amp; Magazines</strong></a>
</li><li><strong><a href='#rcb'>Readings &amp; Chapters from Books</a></strong>
</li><li><strong><a href='#jnls'>Journals</a></strong>
</li><li><strong><a href='#books'>Books</a></strong>
</li></ul><p class='vspace'><a name='art' id='art'></a><strong>Articles from Newspapers, Journals and Magazines</strong> 
</p>
<p class='vspace'>Abrahamson, Joseph R. 1994. <a class='urllink' href='http://www.aaai.org/ojs/index.php/aimagazine/article/view/1075/993' rel='nofollow'>Mind, Evolution and Computers</a>. AI Magazine 15(1): Spring 1994, 19-22. &quot;Science deals with knowledge of the material world based on objective reality. It is under constant attack by those who need magic, that is, concepts based on imagination and desire, with no basis in objective reality. A convenient target for such people is speculation on the machinery and method of operation of the human mind, questions that are still obscure in 1994. In The Emperor's New Mind, Roger Penrose attempts to look beyond objective reality for possible answers, using, in his argument, the theory that computers will never be able to duplicate the human experience. This article attempts to show where Penrose is in error by reviewing the evolution of men and computers and, based on this review, speculates about where computers might and might not imitate human perception. It then warns against the dangers of passive acceptance when respected scientists venture into the occult.&quot;
</p>
<p class='vspace'>Aleksander, Igor. 2003. I, computer. <a target='_blank'  class='urllink' href='http://www.newscientist.com/' rel='nofollow'>New Scientist</a> (July 19, 2003). &quot;Will there come a day when a machine declares itself to be conscious? An increasing number of laboratories around the world are trying to design such a machine. Their efforts are not only revealing how to build artificial beings, they are also illuminating how consciousness arises in living beings too. At least, that's how those of us doing this research see it. Others are not convinced. Generally speaking, people believe that consciousness has to do with life, evolution and humanity, whereas a machine is a lifeless thing designed by a limited mind and has no inherent feeling or humanity. So it is hardly surprising that the idea of a conscious machine strikes some people as an oxymoron.&quot; At the end of the article, he lists his five axioms of consciousness: a sense of place, imagination, directed attention, planning, and decision/emotion.
</p>
<p class='vspace'><a name='afnews' id='afnews'></a>Brean, Joseph. Scientist says you can be a person without being human - Sussing out a 'partner species.' <a target='_blank'  class='urllink' href='http://www.nationalpost.com/' rel='nofollow'>National Post</a> (October 11, 2002). &quot;Watching this scene on video in a conference hall at the University of Waterloo, Canada's top engineering school, it is easy to believe robots are the way of the future. It involves a far greater leap of faith to believe Anne Foerst, who is trying to convince the audience that robots are the people of the future. <a target='_blank'  href='#af'>Dr. Foerst</a>, a Lutheran minister and computer scientist who helped build Kismet, believes it is only a matter of time before robots have souls. ... In developing a theory of personhood that includes robots, Dr. Foerst is slowly reconciling her religious beliefs with her scientific theories, and teasing out the religious implications of playing God with science. She believes building robots in our image will transfer to them the gift we received by being built in God's image. They won't be human, she says, but they will be persons. After all, she says, 'God was not intending to build gods.' ... Among the computer scientists and religious scholars who came to hear Dr. Foerst's talks at the University of Waterloo, there was a clear consensus that what sets us apart from robots is the nature of our intelligence. Whereas today's robots run through their 'mental' operations with brute force, the human brain is more intuitive and adept at taking logical shortcuts. This supposed difference clouds a key similarity, Dr. Foerst says, and this similarity is at the heart of her work. She argues that intelligence depends on the body; the mind does not exist, nor did it evolve, separately from the limbs and muscles it controls. This kind of thinking puts her in a camp that broke away from the Cartesian idea that we are minds that have bodies, and replaced it with the notion that we are simply thinking bodies. The insight had a profound effect on robotics.&quot; 
</p>
<p class='vspace'><a name='chang' id='chang'></a>Chang, Kenneth. <a target='_blank'  class='urllink' href='http://www.nytimes.com/2003/11/11/science/11MACH.html' rel='nofollow'>Can Robots Become Conscious?</a> #14 of the <a target='_blank'  class='urllink' href='http://www.nytimes.com/indexes/2003/11/10/science/text/index.html' rel='nofollow'>25 of the most provocative questions facing science</a>. The New York Times (November 11, 2003; no fee reg. req'd.). &quot;It's a three-part question. What is consciousness? Can you put it in a machine? And if you did, how could you ever know for sure? ... The field of artificial intelligence started out with dreams of making thinking -- and possibly conscious -- machines, but to date, its achievements have been modest. No one has yet produced a computer program that can pass the Turing test. ... But with the continuing gains in computing power, many believe that the original goals of artificial intelligence will be attainable within a few decades. ... To Dr. [Hans] Moravec, if it acts conscious, it is. To ask more is pointless. Dr. [David] Chalmers regards consciousness as an ineffable trait, and it may be useless to try to pin it down.&quot;
</p>
<p class='vspace'>Dennett, Daniel C. 1988. When Philosophers Encounter Artificial Intelligence. Daedalus 117 (1): 283-296. *NOTE: All articles in this section listed from the journal Daedalus 117(1) are reprinted in the book The Artificial Intelligence Debate: False Starts, Real Foundations, ed. Stephen R. Graubard. Cambridge, MA: MIT Press, 1990.
</p>
<p class='vspace'>Doyle, Jon. 1983. <a class='urllink' href='http://www.aaai.org/ojs/index.php/aimagazine/article/view/404/340' rel='nofollow'>What is Rational Psychology?</a> Toward a Modern Mental Philosophy. AI Magazine 4(3): Fall 1983, 50-53. &quot;Rational psychology is the conceptual investigation of psychology by means of the most fit mathematical concepts. Several practical benefits should accrue from its recognition.&quot;
Dreifus, Claudia. 2000. A Conversation with Anne Foerst [Director of MIT's God and Computers project]. <a target='_blank'  class='urllink' href='http://query.nytimes.com/gst/abstract.html?res=F40815FE385D0C748CDDA80994D8404482' rel='nofollow'>The New York Times</a>. Science, page D3. November 7, 2000. 
</p>
<p class='vspace'>Gelernter, David. 1997. How Hard is Chess? Time Magazine (May 19, 1997): 72.
</p>
<p class='vspace'>Kirsch, D. 1991a. Foundations of AI: The Big Issues. Artificial Intelligence 47: 3-30. 
</p>
<p class='vspace'>Kirsch, D. 1991b. Today the Earwig, Tomorrow Man? Artificial Intelligence 47: 161-184
</p>
<p class='vspace'>LaForte, Geoffrey, Patrick J. Hayes, and Kenneth M. Ford. 1998. Why Godel's Theorem Cannot Refute Computationalism. Artificial Intelligence 104 (1/2): 211-264. The authors find flaws in Roger Penrose's claim that Godel's theorem implies that human thought cannot be mechanized.. 
</p>
<p class='vspace'>McCorduck, Pamela. 1988. Artificial Intelligence: An Apercu. Daedalus 117 (1): 65-84. 
</p>
<p class='vspace'>Papert, Seymour. 1988. One AI or Many? Daedalus 117 (1): 1-14.
</p>
<p class='vspace'>Putnam, Hillary. 1988. Much Ado About Not Very Much. Daedalus 117 (1): 269-282. 
</p>
<p class='vspace'>&nbsp;
Sokolowski, Robert. 1988. Natural and Artificial Intelligence. Daedalus 117 (1): 45-64.
</p>
<p class='vspace'><a name='ullman' id='ullman'></a>Ullman, Ellen. 2002. Programming the Post-Human: Computer science redefines &quot;life.&quot; <a target='_blank'  class='urllink' href='http://www.harpers.org/' rel='nofollow'>Harper's</a>, Vol. 305, No. 1829: 60-70. &quot;Growing impatient with me as I pressed [Cynthia Breazeal] for a definition of 'alive,' she said: 'Do you have to go to the bathroom and eat to be alive?'&quot; [p. 67]
</p>
<p class='vspace'><a name='rcb' id='rcb'></a>
<strong>Readings and Chapters from Books</strong> 
</p>
<p class='vspace'>Glymour, Clark, Kenneth Ford, and Patrick Hayes. 1995. The Prehistory of Android Epistemology. In Computation and Intelligence: Collected Readings, ed. Luger, George F., 3-21. Menlo Park/Cambridge/London: AAAI Press/The MIT Press. Going back to the ancient Greeks, the authors put the philosophical questions posed by AI into the context of Western philosophical tradition. 
</p>
<p class='vspace'>McCarthy, John. 1977. Epistemological Problems in Artificial Intelligence. In Readings in Artificial Intelligence, ed. Webber, Bonnie Lynn and Nils J. Nilsson, 459-465. Palo Alto, CA: Tioga Publishing Co., 1977. (Originally published in Proceedings of the Fifth International Joint Conference on Artificial Intelligence [IJCAI-77].)
</p>
<p class='vspace'>Minsky, Marvin. 1961. Steps Toward Artificial Intelligence. In Computers and Thought, ed. Feigenbaum, Edward A. and Julian Feldman, Cambridge, MA: MIT Press, 1995. 
</p>
<p class='vspace'>Russell, Stuart, and Peter Norvig. 1995. Artificial Intelligence: A Modern Approach. Upper Saddle River, NJ: Prentice Hall. Chapter 26 (pages 817-841) takes an accessible approach to the question "Can machines think?" by clearly analyzing the question, describing positions taken by various contributors to the discussion, and simply defining much of the jargon related to the philosophical issues.
</p>
<p class='vspace'>Searle, John R. 1992. The Rediscovery of the Mind. Cambridge, MA: MIT Press. 
</p>
<p class='vspace'>Waltz, David L. 1988. The Prospects for Building Truly Intelligent Machines. In The Artificial Intelligence Debate, ed. Graubard, Stephen R., Cambridge, MA: The MIT Press. 
</p>
<p class='vspace'>Winograd, Terry. 1990. Thinking Machines: Can there be? Are we? In Foundations of Artificial Intelligence: A Sourcebook, ed. Partridge, D. and Y. Wilks, 167-189. Cambridge, England: Cambridge University Press.
</p>
<p class='vspace'><a name='jnls' id='jnls'></a>
<strong>Journals</strong>
</p>
<p class='vspace'><a target='_blank'  class='urllink' href='http://www.springer.com/computer/artificial/journal/11023?detailsPage=editorialBoard' rel='nofollow'>Journal for Artificial Intelligence, Philosophy and Cognitive Science</a>.   Editor: J.H. Moor.
</p>
<p class='vspace'><a name='books' id='books'></a>
<strong>Books</strong>
</p>
<p class='vspace'>Anderson, Alan R., editor. 1964. Minds and Machines. Englewood Cliffs, NJ: Prentice-Hall. 
</p>
<p class='vspace'>Boden, Margaret, editor. 1990. The Philosophy of Artificial Intelligence. Oxford: Oxford University Press. 
</p>
<p class='vspace'>Bynum, Terrell Ward, and James H. Moor, editors. 1998. The Digital Phoenix: How Computers are Changing Philosophy. Cambridge, MA: Blackwell Publishers. A collection of readings.
</p>
<p class='vspace'>Churchland, Paul M. 1992. Matter and Consciousness. Cambridge and London: MIT Press. Written expressly for people who are not professionals in philosophy or artificial intelligence, Churchland writes about the nature of conscious intelligence with an eye toward the progress science is making in understanding it. 
</p>
<p class='vspace'>Churchland, Paul M. 1995. The Engine of Reason, the Seat of the Soul. Cambridge, MA: MIT Press/Bradford Books. Explanations of recent scientific discoveries about the mind by a philosopher who examines not only the science, but also social and ethical implications of ascribing consciousness to all but the simplest of animal life. 
</p>
<p class='vspace'>Churchland, P. S. 1986. Neurophilosophy: Toward a Unified Science of the Mind-Brain. Cambridge, MA: MIT Press. 
</p>
<p class='vspace'>Clark, Andy. 1997. Being There: Putting Brain, Body, and World Together Again. Cambridge, MA and London: The MIT Press. 
</p>
<p class='vspace'>Copeland, Jack. 1993. Artificial Intelligence: A Philosophical Introduction. Oxford: Blackwell. 
</p>
<p class='vspace'>Crane, Tim. 1991. The Mechanical Mind: A Philosophical Introduction to Minds, Machines and Mental Representation. New York and London: Penguin Books. 
</p>
<p class='vspace'>Cummins, Robert, and John Pollock, editors. 1991. Philosophy and AI: Essays at the Interface. Cambridge, MA: MIT Press. 
</p>
<p class='vspace'>Dennett, Daniel C. 1998. Brainchildren: Essays on Designing Minds. Cambridge, MA: MIT Press/Bradford Books. A multidisciplinary look at the mind -- biological, social, philosophical. Reprinted from scholarly journal articles appearing 1984-1996. 
</p>
<p class='vspace'>Dennett, Daniel. 1978. Brainstorms: Philosophical Essays on Mind and Psychology. Montgomery, VT: Bradford Books. 
</p>
<p class='vspace'>Denning, Peter, and Bob Metcalfe, editors. 1997. Beyond Calculation: The Next 50 Years of Computing. New York: Springer Verlag. Essays by Terry Winograd, Sherry Turkle, Donald Norman and many others. 
</p>
<p class='vspace'>Dreyfus, Hubert. 1992. What Computers Still Can't Do: A Critique of Artificial Reason. Cambridge, MA: MIT Press. 
</p>
<p class='vspace'>Dreyfus, Hubert. 1979. What Computers Can't Do: The Limits of Artificial Intelligence. Revised edition. New York: Harper and Row. 
</p>
<p class='vspace'>Dreyfus, H., S. Dreyfus, and T. Athanasiou. 1986. Mind Over Machine: The Power of Human Intuition and Expertise in the Era of the Computer. Oxford: Blackwell. Ford, Kenneth, Clark Glymour, and Patrick Hayes, editors. 1995. Android Epistemology. Menlo Park, CA: AAAI Press. Approaches artificial intelligence and cognitive psychology as a unified endeavor, with AI focused on possible ways of engineering intelligence and cognitive science on reverse engineering a particular intelligent system. Sixteen essays by computer scientists and philosophers. 
</p>
<p class='vspace'>Gershenfeld, Neil. 1998. When Things Start to Think. New York: Henry Holt and Co. Philosophical discussion and lots of information about new inventions at MIT's Media Lab. 
</p>
<p class='vspace'>Gelernter, David. 1994. The Muse in the Machine: Computerizing the Poetry of Human Thought. New York: Free Press of Macmillan, Inc. 
</p>
<p class='vspace'>Graubard, Stephen, editor. 1988. The Artificial Intelligence Debate: False Starts, Real Foundations. Cambridge, MA: MIT Press. Reprinted 1990. Essays that examine fundamental conceptual issues in AI. This book reprints a collection of articles from the journal Daedalus 117(1). Contributors include Dennett, Dreyfus, McCarthy, McCorduck, Papert, Waltz, and others. For individual annotations, see the "Articles" section, above.
</p>
<p class='vspace'>Haugeland, John., editor. 1997. Mind Design II: Philosophy, Psychology, Artificial Intelligence. 2nd edition. Cambridge, MA: MIT Press. With contributions from both scientists and philosophers, this book retains a few classic essays from the first edition and expands with articles on connectionism, dynamical systems, and symbolic versus nonsymbolic models
</p>
<p class='vspace'>Haugeland, John. 1985. Artificial Intelligence: The Very Idea. Cambridge, MA: MIT Press. 
</p>
<p class='vspace'>Hofstadter, Douglas R., and Daniel C. Dennett 1981. The Mind's I: Fantasies and Reflections on Self and Soul. New York: Basic Books. Philosophical essays on the self, the intellect, and consciousness. 
</p>
<p class='vspace'>Kurzweil, Ray. 1998. The Age of Spiritual Machines: When Computers Exceed Human Intelligence. New York: Viking. Speculations on how society will be influenced and affected as intelligent machines become more powerful and prevalent. "This is a book for computer enthusiasts, science fiction writers in search of cutting-edge themes and anyone who wonders where technology is going next." (New York Times Book Review, Jan. 3, 1999.) 
</p>
<p class='vspace'>Penrose, Roger. 1989. The Emperor's New Mind: Concerning Computers, Minds and the Laws of Physics. Oxford: Oxford University Press. 
</p>
<p class='vspace'>Ringle, M. 1979. Philosophical Perspectives in Artificial Intelligence. Atlantic Highlands, NJ: Humanities Press. 
</p>
<p class='vspace'>Sloman, Aaron. 1978. The Computer Revolution in Philosophy. Hassocks, Sussex, UK: Harvester Press. [Out of print, but <a href='#crp'>available online</a> from the author.] 
</p>
<p class='vspace'>Smith, Brian Cantwell. 1996. On the Origin of Objects. Cambridge, MA: MIT Press/Bradford Books. The author offers his conclusions about the philosophical and metaphysical underpinnings of artificial intelligence, cognitive science, and computation. 
</p>
<p class='vspace'>Thagard, Paul 1993. Computational Philosophy of Science. Cambridge, MA: MIT Press.
</p>
</div>

      </td>
    </tr></table>
	</div>

<!--PageFooterFmt-->
  <div id='wikifoot' class='backgrnd11'>
    <div class='footnav'>
			<a href='http://www.aaai.org/'>AAAI Home</a>&nbsp;&nbsp;
			<a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/RecentChanges' accesskey='c'>Recent Changes</a></span>&nbsp;&nbsp;
			<a rel="nofollow" href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Philosophy?action=edit'>Edit</a>&nbsp;&nbsp;
      <a rel="nofollow" href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Philosophy?action=diff'>History</a>&nbsp;&nbsp;
      <a rel="nofollow" href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/Philosophy?action=print' target='_blank'>Print</a>&nbsp;&nbsp;
<!--      <a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/AITopics/RecentChanges'>Recent Changes</a>&nbsp;&nbsp;
      <a href='http://www.aaai.org/AITopics/pmwiki/pmwiki.php/Site/Search'>Search</a> - -->
			<a href='mailto:videos08@aaai.org?subject=AI Topics Contact'>Contact Us</a></div>
    <div class='lastmod'>Page last modified on December 14, 2008, at 04:29 AM</div></div>
<!--HTMLFooter-->
</body>
</html>

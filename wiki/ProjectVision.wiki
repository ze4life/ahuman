#summary Project Vision

@@[Home] -> [ProjectVision]

[http://lh3.ggpht.com/_u_kxYvoRfww/SomOrIsNutI/AAAAAAAAACQ/uNrQPMjPMEQ/s128/vision.JPG]
----

== 1. Primary goal ==

The goal of Human project is to create software program, that will represent alive being, having a personality. It should use one or more free or commercial hostings, move from one hosting to another and provide a service for people for free or for money, at own will.

== 2. Features that are vital for Human project ==

Primary features to implement during a project are:

  * *Personality*. A major feature for a project to create alive being, not a robot or toy or calculator
  * *Consciousness*. It makes intelligence, allowing the creature to interact and live with humans
  * *Growth*. Inevitable thing to adopt to our complex and changing environment
  * *Value*. It should be motivated to bring some value, provide some service to  have a freedom from its parents, to be adult

=== Personality ===

One of the known AI research teams, COG was designed and built to emulate human thought processes and experience the world as a human. Brooks and his team further assumed that people would find it easier to interact with a robot and aid the robot in its learning process when the robot could respond in a somewhat human way.
I agree with last sentence, but I think a certain mistake is behind that.
Imagine you meet a human-like but emotionless creature - would you like to learn him? Let me guess - no. We usually don't like emotionless people.
Another case - you meet intelligent but emotional creature looking quite different from human - look to the Spielberg-made films and you will see what I mean. Most of us will try to speak to and help him.

The program do not need be like a human for all properties except personality. It means it could be slow-thinking or not wise, not have the same sensors as human, not ready to talk, or something like. Personality is the sole feature of the project. I think the major factors, contributing to this feature, are:

  * *Emotional Behavior*: every activity has an emotional side
  * *Will*: ability to initiate actions by own will, without push or request
  * *Power*: ability to change something in this world and skills to do that

=== Consciousness ===

The creature is not expected to be a great scientist or inventor though. We allow no extra skills, so our Human can be below average. What is most wanted are:

  * *Identity*: understand own identify, being able to find reference to himself in inbound data streams, to realise himself as a unique and self-important person
  * *Reasoning*: a sort of logical thinking is expected, so we can ask for explaining own actions or being able to understand some logical chain to use it or to have a meaningful conversation.
  * *Supervising*: there should be one one mind center responsible for decisions and supervising all the activity. It means we don't need a colony of ants but a single creature

=== Growth ===

This feature makes the creature able to evolve.

  * *Life Care*: thinking about continuing to live, providing internal motivations for living according to laws and common sense
  * *Self Learning*: able to learn without teacher
  * *Social Networking*: creating and expanding list of people who contribute to the creature in some way.

=== Value ===

This is to obtain a reasonable duties:

  * *Service For People*: motivation to have foundation for freedom
  * *Work For Money*: earn a money to pay for using Internet resources and to have a practical freedom
  * *Exchange For Free*: a principle helping to have friends

== 3. Implementation ==

=== Core paradigms for architecture ===

  * [NeuralParadigm] - neural networks is chosen as principal method to represent mind functions. It is complemented by non-neural methods to arrange a system from many neral networks and to connect this system to the real world
  * [VariablesParadigm] - approach to represent entities of the world in such a way that we can reference them across all modules having attached metadata available immediately, and be free to represent both simple and complex items. Items work as inputs and outputs for numerous neural networks
  * [GenomeParadigm] - explains how to build multi-network step-by-step. It introduces neural variables, and uses the ability of neural networks to adopt to new inputs added when training is already done

These paradigms are combined together in below diagram, which presents a step to practical implementation of Human project:

Human is a set of neural networks, connected to sensors and effectors by means of low-level drivers, and genome services, responsible for arranging and adjusting those networks, and generic kernel for necessary but non-intelligent functions

[http://lh6.ggpht.com/_u_kxYvoRfww/SomOrPLsENI/AAAAAAAAACU/91yJGgTZUDo/s128/architecture.JPG]

  * All blocks separate code and functions
  * Mentioned features are allocated to blocks and are covered by several ones
  * Features that exist as consequences of denoted interactions among blocks or serving to allow development and debugging, are design features and are not described here
  * Not connected blocks are in fact connected to all blocks and provide general services

=== Short architecture block explanations ===

  * *External World*: abstraction of real world just to show its place, not going to be implemented, though can be mocked for experiments
  * *Shell*: program kernel to provide generic services like logging to all blocks and to implement life functions
  * *Channels*: special functions to establish flexible and effective information flow channels information channels between blocks, make them asynchronous, convenient if complex like video-signal and and to avoid direct calls from one block to another (except to shell or channels itself)
  * *Sensors*: Items to create snapshotting specific projections of external world information and to pass corresponding streams into information processing blocks. Sensors are fixed or can be affected by effectors (e.g. we can turn head to give our eyes new view)
  * *Effectors*: Items that somehow affect external world. Process only low-level commands
  * *Command Memory*: drivers to effectors, store NNs with strategies to execute complex commands by means of low-level commands, take into account current internal (known for driver only) state of effectors and provide external (understandable by all blocks) state to operating memory
  * *Operating Memory*: current state of variables
  * *Snapshot Memory*: with a rate dependent on variable, its value is snapshotted to this block to be able to memorised
  * *Logical Memory*: a set of neural networks, representing strategies to solve tasks, comprising experience of Human creature. Uses both self-lean associative memory and knowledge plug-ins
  * *Associative Memory*: Form a binary or ternary associations to memorise snapshotted values of neural variables, based on neural networks
  * *Ready Knowledge*: knowledge plug-ins to avoid building experience from scratch
  * *Hormones*: motivations of "body", meaning here what is derived from the life form of creature
  * *Character*: a set of established internal relations, reactions, activity patterns, criteria to estimate action - like spirit
  * *Persistence*: file-based database to store the knowledge gained
  * *NN Library*: implementation of known algorithms for neural networks
  * *AI Library*: implementation of known algorithms for artificial intelligence

=== Configuration items for development ===

To simplify development, the program could be split into below parts:

  * Part A. *Neural Networking Library*: Known Algorithms
  * Part B. *Artificial Intelligence Library*: Known Algorithms
  * Part C. *Genome*: a set of components to build a system from neural networks
  * Part D. *Sensors and Effectors Drivers*: Translate input/output data from external format into variables
  * Part F. *Framework*. Generic functions, required for any application, and life  functions of the creature
  * Part G. *Generic Library*: Generic-purpose data primitives and functions

Configuration items are defined by part:

  * Part A. Neural Networking Library
    # *modnnlib*: NN Library
  * Part B. Artificial Intelligence Library
    # *modailib*: AI Library
  * Part C. Genome
    # *modheart*: Hormones, Character
    # *modmind*: Command Memory, Logical Memory, Associative Memory, Operating Memory, Snapshot Memory
    # *modknowledge*: Ready Knowledge
  * Part D. Sensors and Effectors Drivers
    # *modmedia*: Sensors, Effectors
  * Part F. Framework
    # *modengine*: Shell
    # *moddb*: Persistence
    # *modio*: Channels
  * Part G. Generic Library
    # *genrtn*

== 4. Open questions ==

  * Not clear whether Neural and Variables paradigms could be effective way to represent learned knowledge. Possibly it should be combined with HTM/MPF technology (research task is open in [ArtificialIntelligenceResearch Artificial Intelligence Research])

== 5. Comparing to existing projects ==

There are many of AI projects that are trying to create practical things leading to a commercialisation.
It is not our way, because Human project intention is to create alive being which has a personality.
We cannot sell it when succeed.

Human project is not intended to compete with similar projects.
Instead I think it will be fruitful if we use the ideas, algorithms and even working code from such projects, if available, to focus on primary goals.

The idea of the project is quite challenging, as we have examples of working AI applications and even intelligent behavior, but I don't know successful implementation of emotions and personality.
#summary Attention in Cortex
@@[Home] -> [SensorsResearch] -> [CortexAttention]
----

= Attention in the Neocortex =

see 2007 - Model of covert attention and learning

== 2.1 Mammalian Neocortex ==

=== 2.1.1 Overview of the cortex ===

  * cerebral cortex is neocortex and old structures like hippocampus
  * most intelligent animals have larger absolute and relative neocortex
  * neocortex is responsible for things such as processing sensory information, learning associations, consciousness and working memory (compare to Jeff Hawkins - neocortex is responsible for prediction)
  * after evolution it receives input from all sources and thus can build world model
  * independently of the location on the cortex, it has the same six-layered columnar structure and the same micro-connectivity

=== 2.1.2 Learning Feature Representations ===

  * exceptional feature of the motor cortex is that it has power to control the muscles
  * higher levels represent longer lasting actions that are more abstract and consist of many primitive actions
  * when motor cortex attends to some actions, the muscles actually perform those actions
  * when an animal attends to some features in its sensations, the neural representations even in the lowest cortical levels adapt mostly to those features and not to others
  * feedback connections could also help in relating the neural representations to their context and thus give meaning to the raw bottom-up data
   * if the context does not change when the inputs change, the context could teach the neuron that the different inputs are actually instantiations of the same object
   * feedback connections could act as teaching signals for the neurons

=== 2.1.3 Attention in Neocortex ===

  * sensory cortex cannot represent all objects existing in the inputs at the same time - there is selective attention
  * neocortex can think about and perceive only few different things simultaneously (covert attention)
  * possible reasons of attention limitation:
   * *neuron has much synaptic information but little activity information* - active state cannot represent all the knowledge of the neuron simultaneously
   * *binding problem* - one simple feature can take part in representing many different things; when two population codes overlap, the features between the objects can get mixed up; the right combinations of features can be found if only few objects are attended at once; the simulated reality must be kept apart from the real world, and different future plans must be kept from interfering with each other
   * invariant reference frame for pattern recognition - the same objects can appear in many different forms (weak)
  * targets of attention are selected based on bottom-up saliency and high-level intentions
  * *saliency* can be:
   * high contrast
   * good continuity
   * unexpectedness - in spatial or temporal context; dangerous or new opportunity
   * attending to salient targets can be reasonable for alive being - improves probability of having real object
  * high-level *intentions* can be:
   * search for certain objects from the visual field
   * can be controlled to target any kind of features, like spatial locations or auditory frequency bands
   * top-down control signals are thought to originate in the *frontal cortex*
  * *biased-competition model of attention* - all attention emerges from local competition between different features in the neural hierarchies; this competition can be biased with top-down signal, allowing for search of certain features
   * competition between different spatial locations works similarly to that between different features
   * if a certain object is given attentional bias, then the location of that object is searched for
   * if the bias is given to some location, then the cortex will recognise the possible object in that location

=== 2.1.4 Architecture of Neocortex ===
  
  * *connections*
   * 1st-order: thalamic -> inputs (layer 4) -> contextual (layers 1-3) -> outputs (layers 5-6) -> higher-order thalamic
   * higher-order: thalamic -> inputs -> contextual -> outputs -> ...
  * *minicolumns* form larger *columns* and *hypercolumns*
  * all neurons within one minicolumn respond roughly to similar stimuli
  * *suggestions*:
   * some layers could represent the true state of the world 
   * other layers could represent unexpected novelties
   * some layers could form laterally coherent feature aggregates between neighbouring columns
  * crucial connection type is *feedback connections*
   * more numerous than the bottom-up connections
   * cannot cause activations in the target neurons, but only modulate the activations
   * originate from the near surroundings of that area
   * important set of connections is feedback from the next hierarchical level
  * great amount of contextual input into layer 1 comes from special context mediating *matrix cells* in the thalamus
  * bottom-up circuitry from thalamus to inputs layer (4), to contextual layer (2,3), to outputs layer (5,6) and back to thalamus consists of excitatory neurons
  * *inhibitory connections* can:
   * take part in regulating the activations in the cortex
   * implement competition between excitatory neurons
   * implement contextual “explaining away” of local neural representations
  * there are more global signals, carried by *chemical neuromodulators*, that affect large parts of the cortex similarly; they can modulate both the plasticity and activations in the neurons
   * control learning and memorising
   * control the balance between bottom-up and top-down inference
   * gate the contents of working memory

=== 2.1.5 Purpose of Neocortex ===

  * lots of learning happening in the subcortical structures as well
   * *basal ganglia* are considered to do *reinforcement learning*, which means learning those motor actions that are rewarding
   * *cerebellum* learns to contract the muscles on just the right time instants, resulting in *anticipative actions* and *smooth control*
  * cortex learns invariant representations for the complex information in the raw sensory data
  * additionally to representing the world state, it performs motor actions itself and plans the future
  * cortex incorporates the goals of the animal into its world model, and can thus make good action decisions:
   * motor cortex perceives what the animal does - cortex can associate the evolutionary fixed action patterns to different situations
   * global neuromodulation signals, such as dopamine, mediate information about rewards and punishments
   * working memory in the prefrontal cortex is thought to be gated by subcortical structures, which focuses attention on the animal goals

== 2.2 Models of learning regularities in the world ==

  * cortex is often modelled as using unsupervised learning
  * real cortex does receive teaching signals: the general contextual inputs from the thalamus matrix cells and the neuromodulators

=== 2.2.1 Generative models ===

  * generative models try to infer the original causes underlying the sensations
  * generative models assume a physical model F that produces the sensory inputs x:
{{{
x = F(s) + n
s - the physical causes, vector s can include information about the history of the world
n - sensory noise
}}}
  * generative models try to learn the world model F, and then use this in inferring the causes s from the inputs
  * *Bayesian network* is example of generative model, hierarchical statistical model
   * can be used to infer the abstract causes from partial sensory inputs
   * inference is computationally demanding
  * *Helmholtz machine*
   * inference/recognition can be done with one feed-forward activation sweep if distinct recognition model is added alongside the generative model
   * recognition model is consistent as learnt at the same time with generative model
  * error function can be the Kullback-Leibler divergence between the real sensory input probability distribution and that of the learnt generative model
  * for dimensionality of real world accurate generative model would be immensely large and slow to learn
  * generative models do not take into account the importance of different real world objects, or causes
  * cortex of the animal must decide what to represent
  * optimal way to make decisions is to maximise the expected utility of the consequences of the actions, leading to *Bayesian decision theory*
   * actions could be the decisions about what objects to represent
   * utilities are the utilities of representing different objects in the case they really exist in the current world state
   * utility of representing an object should be higher for those objects that are relevant for the behaviour of the animal
  * *cortical neural networks* must use information about the utility in two different time scales
   * synaptic weights of the network should be used to represent those aspects of the world that are important (concerns learning and corresponds to the *longer time scale*)
   * faster time scale corresponds to attention - select those targets that are the *most relevant*, for example dangerous or favourable

=== 2.2.2 Learning features ===
#summary Memory Prediction Research
#labels vision
@@[Home] -> [SensorsResearch] -> [VisionResearch]
----

= Introduction =

This page is intended to collect the research information published in the field of human vision which can help to build informational model. Human vision is under great and long-term scientific attention and it gives us a lot of facts. 
We can say that it is one of most important and functionally reach sensors for human intelligence. Information model of vision can help to understand the nature of effective information processing and generalize it for other sensors.
Implementing the vision in aHuman looks to me less obvious goal, because of its complexity and computer resource demands.

= Interesting links =

  * [http://brainmind.com/images/VisualPathway2.jpg Brain Vision]

http://brainmind.com/images/VisualPathway2.jpg

  * [http://www.scholarpedia.org/wiki/images/f/f2/ITCortex_pathway.jpg IT Cortex Pathways]

http://www.scholarpedia.org/wiki/images/f/f2/ITCortex_pathway.jpg

= Details =

Currently we are looking for a model that can create a eye like structure and can be integrated with the aHuman brain.

== Biological Vision Flow ==

*Retina*
  * *flow*: photoreceptors -> bipolar cells -> ganglion cells -> brain
   * photoreceptors - total ~130M
   * ganglion fibers to brain - total ~1.3M
  * *photoreceptors*:
   * rods - peripheral colorless intensity receptors
   * cones - R or G or B receptors - in the center (fovea)
  * *ganglion cells*:
   * ganglion cells are not selective for orientation or direction
   * M cells: sensitive to depth, motion, indifferent to color, fast, large receptive field - go to LGN
   * P cells: sensitive to shape, color, insensitive to motion, slow, small receptive field - go to LGN
   * K cells, sensitive to color and indifferent to shape or depth, large receptive field - go to LGN
   * light signal for wake/sleep cycle - go to pretectal olivary nucleus (PON)
   * final population that is used for eye movements
   
*Thalamus / LGN*
  * *flow*
   * retina (eye ganglion cells) -> THA/LGN -> PCA/V1
   * PCA/V1 -> THA/LGN
  * LGN cells are not selective for orientation or direction
  * feedforward: retina -> LGN (10% of synaptic input to relay cells)
  * feedforward: LGN -> V1/L4 (6-9% of layer 4 excitatory inputs)
  * feedforward: LGN -> V1/L6
  * V1/L6 -> V1/L4/spiny stellate cells (45% of layer 4 excitatory inputs)
  * feedback: V1/L6 (sensitive to stimulus orientation and direction of motion) -> LGN (30% of synatic input to relay cells, affects distal dendrites, also contact inhibitory interneurons in LGN)

*Thalamus / PGN*
  * feedback: V1/L6 -> PGN
  * PGN (perigeniculate nucleus)/TRN (thalamic reticular nucleus)/THA -> THA/LGN

*Visual Cortex:*
  * feedforward: V1/L4 -> MT
  * feedforward: V1/L6 -> MT
  * feedback: MT/V5 -> V1/L6
  * feedback: MT -> V1/L4

*feedback: V1/L6 -> LGN*
  * if dropped, do not affect stationary objects
  * if dropped, short moving objects are signaled by LGN, while large moving objects are not
  * feedback fine-tunes local circuitry in the LGN to optimize the extraction of salient features, and in relation to the shift between burst and tonic firing might alert and focus the circuitry on stimuli requiring attention

== Primary Visual Cortex Model ==

http://topographica.org/images/Topo-arch-white.jpg

This model is used by topographica to simulate the human eye interaction with the cortex.
There are various models proposed to implement these parts of the model and currently we are researching on the implementation of working LGN module.

Primary Visual cortex will do the processing on the data it gets from the sensor (eye) and will be integrated with the aHuman brain to excite certain neurons to understand the information that it gets from the sensors. This is in accordance with the biological functionality of cortex and eye.

== LGN ==

LGN functionality can be implemented using _'Difference of Gaussian'_ algorithm for edge detection. Currently research is being done in this area to create a working model of LGN.

LGN will get input from the sensors which in this case will simulate the aHuman eye.

== How Eye is controlled ==

See [http://www.dartmouth.edu/~dons/part_1/chapter_4.html Eye in Detail]

*Control reasons*:

  * Saccades
  * Tracking moving objects
  * Adoption to moving head
  * Intentional focus change
  * Pupil change due to light intensity change
  * Reflexes
  * Eyes sunchronization

*Paths*

  * capture: eye -> LGN (thalamus) -> visual cortex
  * what/ventral: visual cortex -> temporal lobe
  * where/dorsal: visual cortex -> parietal (association) cortex -> frontal lobe
  * early control: parietal cortex -> superior colliculus (midbrain, primary integrating center for eye movements) -> pons (connects left and right cerebellum) -> eye muscles
  * late control: frontal lobe -> superior colliculus -> pons -> eye muscles

== Visual perception ==

  * light level is not transmitted by eyes - only light differences
  * eyes constantly move (saccadic movement), slight tremor and jumps over visual field
  * this produces constant changes in light level over retina
  * when eye is stabilised, e.g. by paralyzing eye muscles and stabilising head, picture disappears
  * then, moving objects can be seen, they pop out suddenly